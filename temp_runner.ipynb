{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install matplotlib numpy pandas tqdm nltk\n",
    "\n",
    "# for separating ingredients vs non-ingredients\n",
    "# NOTE: if using Windows to run this, need to download GNU Wget\n",
    "# !wget -c https://raw.githubusercontent.com/williamLyh/RecipeWithPlans/main/ingredient_set.json -O ingredient_set.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/junn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR, MultiStepLR\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "from nltk.translate import meteor\n",
    "\n",
    "from data import *\n",
    "from encoder_decoder import *\n",
    "from train import *\n",
    "from eval import *\n",
    "\n",
    "# required for bleu\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 31989101\n",
    "HIDDEN_SIZE = 256\n",
    "MAX_INGR_LEN = 150\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## ensuring reproducibility\n",
    "def reset_rng():\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "reset_rng()\n",
    "\n",
    "# to easily read ingredients and instructions\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./Cooking_Dataset\"\n",
    "\n",
    "train_df_orig = pd.read_csv(os.path.join(data_root, \"train.csv\"), usecols=['Ingredients', 'Recipe'])\n",
    "dev_df_orig = pd.read_csv(os.path.join(data_root, \"dev.csv\"), usecols=['Ingredients', 'Recipe'])\n",
    "test_df_orig = pd.read_csv(os.path.join(data_root, \"test.csv\"), usecols=['Ingredients', 'Recipe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 101340\n",
      "Number of data samples after preprocessing: 99036 (97.726%)\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df_orig, max_ingr_len=MAX_INGR_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 797\n",
      "Number of data samples after preprocessing: 775 (97.240%)\n"
     ]
    }
   ],
   "source": [
    "dev_df = preprocess_data(dev_df_orig, max_ingr_len=MAX_INGR_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 778\n",
      "Number of data samples after preprocessing: 757 (97.301%)\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df_orig, max_ingr_len=MAX_INGR_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99036/99036 [00:03<00:00, 28123.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44683"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "vocab.populate(train_df)\n",
    "vocab.n_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ds = RecipeDataset(train_df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vocab.n_unique_words, hidden_size=HIDDEN_SIZE, padding_value=vocab.word2index[PAD_WORD]).to(DEVICE)\n",
    "# in the training script, decoder is always fed a non-end token and thus never needs to generate padding\n",
    "decoder = DecoderRNN(hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 0, iter 50/774) Average loss so far: 10.236\n",
      "(Epoch 0, iter 100/774) Average loss so far: 7.983\n",
      "(Epoch 0, iter 150/774) Average loss so far: 6.610\n",
      "(Epoch 0, iter 200/774) Average loss so far: 6.115\n",
      "(Epoch 0, iter 250/774) Average loss so far: 5.831\n",
      "(Epoch 0, iter 300/774) Average loss so far: 5.618\n",
      "(Epoch 0, iter 350/774) Average loss so far: 5.426\n",
      "(Epoch 0, iter 400/774) Average loss so far: 5.288\n",
      "(Epoch 0, iter 450/774) Average loss so far: 5.173\n",
      "(Epoch 0, iter 500/774) Average loss so far: 5.055\n",
      "(Epoch 0, iter 550/774) Average loss so far: 4.963\n",
      "(Epoch 0, iter 600/774) Average loss so far: 4.900\n",
      "(Epoch 0, iter 650/774) Average loss so far: 4.822\n",
      "(Epoch 0, iter 700/774) Average loss so far: 4.777\n",
      "(Epoch 0, iter 750/774) Average loss so far: 4.715\n",
      "Average epoch loss: 5.798\n",
      "This epoch took 5.165764363606771 mins. Time remaining: 2.0 hrs 29.0 mins.\n",
      "Starting epoch 2/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 1, iter 50/774) Average loss so far: 4.662\n",
      "(Epoch 1, iter 100/774) Average loss so far: 4.590\n",
      "(Epoch 1, iter 150/774) Average loss so far: 4.555\n",
      "(Epoch 1, iter 200/774) Average loss so far: 4.522\n",
      "(Epoch 1, iter 250/774) Average loss so far: 4.490\n",
      "(Epoch 1, iter 300/774) Average loss so far: 4.440\n",
      "(Epoch 1, iter 350/774) Average loss so far: 4.441\n",
      "(Epoch 1, iter 400/774) Average loss so far: 4.378\n",
      "(Epoch 1, iter 450/774) Average loss so far: 4.358\n",
      "(Epoch 1, iter 500/774) Average loss so far: 4.363\n",
      "(Epoch 1, iter 550/774) Average loss so far: 4.297\n",
      "(Epoch 1, iter 600/774) Average loss so far: 4.297\n",
      "(Epoch 1, iter 650/774) Average loss so far: 4.266\n",
      "(Epoch 1, iter 700/774) Average loss so far: 4.244\n",
      "(Epoch 1, iter 750/774) Average loss so far: 4.208\n",
      "Average epoch loss: 4.401\n",
      "This epoch took 5.13157506386439 mins. Time remaining: 2.0 hrs 23.0 mins.\n",
      "Starting epoch 3/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 2, iter 50/774) Average loss so far: 4.193\n",
      "(Epoch 2, iter 100/774) Average loss so far: 4.151\n",
      "(Epoch 2, iter 150/774) Average loss so far: 4.152\n",
      "(Epoch 2, iter 200/774) Average loss so far: 4.133\n",
      "(Epoch 2, iter 250/774) Average loss so far: 4.127\n",
      "(Epoch 2, iter 300/774) Average loss so far: 4.107\n",
      "(Epoch 2, iter 350/774) Average loss so far: 4.089\n",
      "(Epoch 2, iter 400/774) Average loss so far: 4.071\n",
      "(Epoch 2, iter 450/774) Average loss so far: 4.062\n",
      "(Epoch 2, iter 500/774) Average loss so far: 4.045\n",
      "(Epoch 2, iter 550/774) Average loss so far: 4.030\n",
      "(Epoch 2, iter 600/774) Average loss so far: 4.045\n",
      "(Epoch 2, iter 650/774) Average loss so far: 4.008\n",
      "(Epoch 2, iter 700/774) Average loss so far: 4.011\n",
      "(Epoch 2, iter 750/774) Average loss so far: 4.002\n",
      "Average epoch loss: 4.079\n",
      "This epoch took 5.141742857297261 mins. Time remaining: 2.0 hrs 18.0 mins.\n",
      "Starting epoch 4/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 3, iter 50/774) Average loss so far: 3.983\n",
      "(Epoch 3, iter 100/774) Average loss so far: 3.951\n",
      "(Epoch 3, iter 150/774) Average loss so far: 3.946\n",
      "(Epoch 3, iter 200/774) Average loss so far: 3.926\n",
      "(Epoch 3, iter 250/774) Average loss so far: 3.937\n",
      "(Epoch 3, iter 300/774) Average loss so far: 3.929\n",
      "(Epoch 3, iter 350/774) Average loss so far: 3.905\n",
      "(Epoch 3, iter 400/774) Average loss so far: 3.905\n",
      "(Epoch 3, iter 450/774) Average loss so far: 3.894\n",
      "(Epoch 3, iter 500/774) Average loss so far: 3.884\n",
      "(Epoch 3, iter 550/774) Average loss so far: 3.878\n",
      "(Epoch 3, iter 600/774) Average loss so far: 3.874\n",
      "(Epoch 3, iter 650/774) Average loss so far: 3.870\n",
      "(Epoch 3, iter 700/774) Average loss so far: 3.863\n",
      "(Epoch 3, iter 750/774) Average loss so far: 3.848\n",
      "Average epoch loss: 3.905\n",
      "This epoch took 5.137346283594767 mins. Time remaining: 2.0 hrs 13.0 mins.\n",
      "Starting epoch 5/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 4, iter 50/774) Average loss so far: 3.833\n",
      "(Epoch 4, iter 100/774) Average loss so far: 3.833\n",
      "(Epoch 4, iter 150/774) Average loss so far: 3.816\n",
      "(Epoch 4, iter 200/774) Average loss so far: 3.816\n",
      "(Epoch 4, iter 250/774) Average loss so far: 3.803\n",
      "(Epoch 4, iter 300/774) Average loss so far: 3.793\n",
      "(Epoch 4, iter 350/774) Average loss so far: 3.792\n",
      "(Epoch 4, iter 400/774) Average loss so far: 3.788\n",
      "(Epoch 4, iter 450/774) Average loss so far: 3.792\n",
      "(Epoch 4, iter 500/774) Average loss so far: 3.761\n",
      "(Epoch 4, iter 550/774) Average loss so far: 3.767\n",
      "(Epoch 4, iter 600/774) Average loss so far: 3.755\n",
      "(Epoch 4, iter 650/774) Average loss so far: 3.785\n",
      "(Epoch 4, iter 700/774) Average loss so far: 3.752\n",
      "(Epoch 4, iter 750/774) Average loss so far: 3.758\n",
      "Average epoch loss: 3.789\n",
      "This epoch took 5.134716626008352 mins. Time remaining: 2.0 hrs 8.0 mins.\n",
      "Starting epoch 6/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 5, iter 50/774) Average loss so far: 3.740\n",
      "(Epoch 5, iter 100/774) Average loss so far: 3.716\n",
      "(Epoch 5, iter 150/774) Average loss so far: 3.712\n",
      "(Epoch 5, iter 200/774) Average loss so far: 3.726\n",
      "(Epoch 5, iter 250/774) Average loss so far: 3.717\n",
      "(Epoch 5, iter 300/774) Average loss so far: 3.714\n",
      "(Epoch 5, iter 350/774) Average loss so far: 3.714\n",
      "(Epoch 5, iter 400/774) Average loss so far: 3.706\n",
      "(Epoch 5, iter 450/774) Average loss so far: 3.695\n",
      "(Epoch 5, iter 500/774) Average loss so far: 3.704\n",
      "(Epoch 5, iter 550/774) Average loss so far: 3.680\n",
      "(Epoch 5, iter 600/774) Average loss so far: 3.684\n",
      "(Epoch 5, iter 650/774) Average loss so far: 3.689\n",
      "(Epoch 5, iter 700/774) Average loss so far: 3.683\n",
      "(Epoch 5, iter 750/774) Average loss so far: 3.668\n",
      "Average epoch loss: 3.702\n",
      "This epoch took 5.162597910563151 mins. Time remaining: 2.0 hrs 3.0 mins.\n",
      "Starting epoch 7/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 6, iter 50/774) Average loss so far: 3.659\n",
      "(Epoch 6, iter 100/774) Average loss so far: 3.656\n",
      "(Epoch 6, iter 150/774) Average loss so far: 3.658\n",
      "(Epoch 6, iter 200/774) Average loss so far: 3.637\n",
      "(Epoch 6, iter 250/774) Average loss so far: 3.627\n",
      "(Epoch 6, iter 300/774) Average loss so far: 3.627\n",
      "(Epoch 6, iter 350/774) Average loss so far: 3.633\n",
      "(Epoch 6, iter 400/774) Average loss so far: 3.637\n",
      "(Epoch 6, iter 450/774) Average loss so far: 3.649\n",
      "(Epoch 6, iter 500/774) Average loss so far: 3.639\n",
      "(Epoch 6, iter 550/774) Average loss so far: 3.626\n",
      "(Epoch 6, iter 600/774) Average loss so far: 3.624\n",
      "(Epoch 6, iter 650/774) Average loss so far: 3.615\n",
      "(Epoch 6, iter 700/774) Average loss so far: 3.611\n",
      "(Epoch 6, iter 750/774) Average loss so far: 3.610\n",
      "Average epoch loss: 3.633\n",
      "This epoch took 5.116451636950175 mins. Time remaining: 1.0 hrs 57.0 mins.\n",
      "Starting epoch 8/30, enc lr scheduler: [0.8], dec lr scheduler: [0.8]\n",
      "(Epoch 7, iter 50/774) Average loss so far: 3.620\n",
      "(Epoch 7, iter 100/774) Average loss so far: 3.606\n",
      "(Epoch 7, iter 150/774) Average loss so far: 3.604\n",
      "(Epoch 7, iter 200/774) Average loss so far: 3.587\n",
      "(Epoch 7, iter 250/774) Average loss so far: 3.599\n",
      "(Epoch 7, iter 300/774) Average loss so far: 3.596\n",
      "(Epoch 7, iter 350/774) Average loss so far: 3.579\n",
      "(Epoch 7, iter 400/774) Average loss so far: 3.572\n",
      "(Epoch 7, iter 450/774) Average loss so far: 3.576\n",
      "(Epoch 7, iter 500/774) Average loss so far: 3.580\n"
     ]
    }
   ],
   "source": [
    "initial_lr=0.8\n",
    "min_lr = 0.01\n",
    "n_epochs = 30\n",
    "batch_size=128\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=initial_lr)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=initial_lr)\n",
    "# enc_scheduler = CosineAnnealingLR(encoder_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "# dec_scheduler = CosineAnnealingLR(decoder_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "enc_scheduler = MultiStepLR(encoder_optimizer, milestones=[15, 25], gamma=0.5)\n",
    "dec_scheduler = MultiStepLR(decoder_optimizer, milestones=[15, 25], gamma=0.5)\n",
    "\n",
    "epoch_losses = train(encoder, decoder, encoder_optimizer, decoder_optimizer, recipe_ds, \n",
    "                     n_epochs=n_epochs, vocab=vocab, batch_size=batch_size, \n",
    "                     enc_lr_scheduler=enc_scheduler, dec_lr_scheduler=dec_scheduler, \n",
    "                     verbose_iter_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ings = get_all_ingredients(\"./ingredient_set.json\")\n",
    "all_ings_regex = get_ingredients_regex(all_ings)\n",
    "metric_sample_ings, metric_sample_gold_recipe, metric_sample_generated_recipe = \\\n",
    "    load_metric_sample(\"./metric_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Input ingredients in text=====\n",
      "['orange juice', 'strawberries', 'lemon juice', 'sugar', 'water']\n",
      "\n",
      "=====All ingredients in text===== \n",
      "['vanilla ice cream', 'orange juice', 'strawberries', 'cantaloupe', 'lemon juice', 'sugar', 'water']\n",
      "\n",
      "proportion of input ingredients: 1.0\n",
      "number of extra ingredients: 2\n"
     ]
    }
   ],
   "source": [
    "prop_inp_ings, n_extra_ings = get_prop_input_num_extra_ingredients(\n",
    "    metric_sample_ings, metric_sample_generated_recipe, all_ings_regex, verbose=True,\n",
    "    metric_sample=True)\n",
    "print(f\"\\nproportion of input ingredients: {prop_inp_ings}\\nnumber of extra ingredients: {n_extra_ings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.14346607531819988, METEOR score: 0.5736654804270463\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calc_bleu([metric_sample_gold_recipe], [metric_sample_generated_recipe], split_gen=True)\n",
    "meteor_score = calc_meteor([metric_sample_gold_recipe], [metric_sample_generated_recipe], split_gen=True)\n",
    "print(f\"BLEU score: {bleu_score}, METEOR score: {meteor_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Michelle Adeline\n",
    "\n",
    "**Student ID**: 31989101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download required packages\n",
    "\n",
    "Please uncomment the commands below to install the dependencies if you do not have the required packages/files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (3.8.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 60.6/60.6 kB 811.9 kB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading scikit_learn-1.5.0-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/11.0 MB 7.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 11.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.2/11.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.6/11.0 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.9/11.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/46.2 MB 20.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.6/46.2 MB 20.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.4/46.2 MB 18.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 3.2/46.2 MB 18.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.8/46.2 MB 17.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.5/46.2 MB 16.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 5.2/46.2 MB 16.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.4/46.2 MB 17.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 7.1/46.2 MB 17.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 8.2/46.2 MB 18.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 8.8/46.2 MB 17.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 9.7/46.2 MB 17.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 11.2/46.2 MB 18.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.3/46.2 MB 19.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.2/46.2 MB 19.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.2/46.2 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 16.0/46.2 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 17.0/46.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.5/46.2 MB 24.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 19.2/46.2 MB 25.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 20.1/46.2 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.9/46.2 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 21.7/46.2 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.4/46.2 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.3/46.2 MB 21.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 24.2/46.2 MB 21.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 25.1/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.0/46.2 MB 19.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.0/46.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 28.2/46.2 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 29.5/46.2 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 31.1/46.2 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 32.6/46.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 34.1/46.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 35.5/46.2 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.3/46.2 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.0/46.2 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 38.1/46.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.4/46.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.7/46.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.1/46.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.3/46.2 MB 25.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.9/46.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 19.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "nuscenes-devkit 1.1.10 requires opencv-python, which is not installed.\n",
      "nuscenes-devkit 1.1.10 requires pycocotools>=2.0.1, which is not installed.\n",
      "nuscenes-devkit 1.1.10 requires Shapely<=1.8.5, which is not installed.\n",
      "nuscenes-devkit 1.1.10 requires matplotlib<=3.5.2, but you have matplotlib 3.8.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install matplotlib numpy pandas tqdm nltk scikit-learn\n",
    "\n",
    "# for separating ingredients vs non-ingredients\n",
    "# NOTE: if using Windows to run this, need to download GNU Wget\n",
    "# !wget -c https://raw.githubusercontent.com/williamLyh/RecipeWithPlans/main/ingredient_set.json -O ingredient_set.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR, MultiStepLR, CosineAnnealingWarmRestarts\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate import meteor\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "SEED = 31989101\n",
    "HIDDEN_SIZE = 256\n",
    "MAX_INGR_LEN = 150 # fixed from assignment\n",
    "MAX_RECIPE_LEN = 600 # empirically set\n",
    "DROPOUT = 0.1\n",
    "TEACHER_FORCING_RATIO = 1.0 # fixed from assignment\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ING_START = \"<INGREDIENT_START>\"\n",
    "ING = \"<INGREDIENT>\"\n",
    "ING_END = \"<INGREDIENT_END>\"\n",
    "REC_START = \"<RECIPE_START>\"\n",
    "REC = \"<RECIPE_STEP>\"\n",
    "REC_END = \"<RECIPE_END>\"\n",
    "SPECIAL_TAGS = {\n",
    "    ING_START: 0,\n",
    "    ING_END: 1,\n",
    "    REC_START: 2,\n",
    "    REC_END: 3,\n",
    "    ING: 4,\n",
    "    REC: 5,\n",
    "}\n",
    "\n",
    "PAD_WORD = \"<PAD>\"\n",
    "UNKNOWN_WORD = \"<UNKNOWN>\"\n",
    "\n",
    "## ensuring reproducibility\n",
    "def reset_rng():\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "reset_rng()\n",
    "\n",
    "# to easily read ingredients and instructions\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./Cooking_Dataset\"\n",
    "add_intermediate_tag=False\n",
    "\n",
    "train_df_orig = pd.read_csv(os.path.join(data_root, \"train.csv\"), usecols=['Ingredients', 'Recipe'])\n",
    "dev_df_orig = pd.read_csv(os.path.join(data_root, \"dev.csv\"), usecols=['Ingredients', 'Recipe'])\n",
    "test_df_orig = pd.read_csv(os.path.join(data_root, \"test.csv\"), usecols=['Ingredients', 'Recipe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6 tb butter or margarine - softened\\t3/4 c  c and h powdered sugar\\t1 c  all-purpose flour\\t1 tb milk\\t2    eggs\\t1 c  c and h granulated sugar\\t1/2 c  cocoa\\t2 tb flour\\t1/2 ts baking powder\\t1/2 ts salt\\t1 ts vanilla\\t1/4 ts almond extract (optional)\\t1 c  chopped almonds or pecans</td>\n",
       "      <td>cream together butter and powdered sugar . blend in 1 cup flour and milk . spread evenly in bottom of ungreased 9-inch square pan . bake in 350 degree oven 10 to 12 minutes . beat eggs slightly ; combine dry ingredients and add to eggs . blend in vanilla and almond extract ; fold in almonds . spread over hot baked layer ; return to oven and bake 20 minutes longer . cool ; while warm , cut into 24 bars .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 c  vanilla wafer cookies, finely crushed\\t1 c  confectioner's sugar\\t2 tb cocoa\\t1 c  pecans, finely chopped\\t2 tb corn syrup\\t1/2 c  bourbon</td>\n",
       "      <td>combine dry ingredients and mix well . add corn syrup and bourbon and mix well . if too moist add a few cookie crumbs , if too dry add a little more bourbon . shape into small balls and roll in fruit sugar or fonely chopped pecans . store in an airtight container . also good made with dark rum .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 c  all-purpose flour\\t1/2 c  sugar\\t2 ts baking powder\\t1/2 ts salt\\t2 tb unsweetened cocoa powder\\t1 1/2 c  all-bran? cereal\\t3/4 c  skim milk\\t2    egg whites\\t1/4 c  vegetable oil\\t1 c  sliced ripe banana; (about 1\\tvegetable cooking spray</td>\n",
       "      <td>kellogg 's all-bran 1 . stir together flour , sugar , baking powder , salt , and cocoa powder . set aside . in large mixing bowl , combine all-bran cereal and milk . let stand 5 minutes or until cereal softens . add egg whites and oil . beat well . stir in bananas . add flour mixture stirring only until combined . portion batte evenly into twelve 2-1/2 inch muffin-pan cups coated with cooking spray . bake at 400 f. about 25 minutes or until lightly browned . serve warm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 1/2 c  flour\\t1    cake compressed yeast\\tor 1  cake dry yeast\\t2 c  milk, scalded and cooled\\t1/2 ts salt\\t1/2 c  cocoa\\t1/4 c  shortening\\t2    eggs, well beaten\\t1/2 c  sugar</td>\n",
       "      <td>soften yeast and dissolve 1 tablespoon sugar in lukewarm milk . add 3 cups flour and beat until smooth . cover and set aside to rise in a warm place until light . add shortening and sugar , which have been creamed together , eggs , cocoa , salt , and remainder of flour or enough to make a soft dough . knead lightly and place in well-oiled bowl . cover and set in a warm place until double in bulk about 2 hours . form into loaves . place in well-oiled bread pans , filling them 1/2 full . cover and let rise again until double in bulk . bake in hot oven -lrb- 425 f -rrb- 40 50 minutes . 2 loaves .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bread -- to fill dish 2/3\\tful\\t2 c  skim milk\\t2/3 c  sugar\\t2    eggs -- or 4 egg whites\\t2 tb cocoa\\t1 ts vanilla</td>\n",
       "      <td>into a greased casserole dish break up enough bread to fill it 2/3 full . over this pour 2/3 cup sugar , 2 heaping tbsp cocoa that have been mixed together . toss all together lightly -lrb- to coat the bread -rrb- . to 2 cups of milk add 2 well beaten eggs and 1 tsp vanilla . pour this over the bread and it should just cover the pieces . bake at 350 fo r about 45 minutes .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                    Ingredients  \\\n",
       "0  6 tb butter or margarine - softened\\t3/4 c  c and h powdered sugar\\t1 c  all-purpose flour\\t1 tb milk\\t2    eggs\\t1 c  c and h granulated sugar\\t1/2 c  cocoa\\t2 tb flour\\t1/2 ts baking powder\\t1/2 ts salt\\t1 ts vanilla\\t1/4 ts almond extract (optional)\\t1 c  chopped almonds or pecans   \n",
       "1                                                                                                                                               1 c  vanilla wafer cookies, finely crushed\\t1 c  confectioner's sugar\\t2 tb cocoa\\t1 c  pecans, finely chopped\\t2 tb corn syrup\\t1/2 c  bourbon   \n",
       "2                                          1 c  all-purpose flour\\t1/2 c  sugar\\t2 ts baking powder\\t1/2 ts salt\\t2 tb unsweetened cocoa powder\\t1 1/2 c  all-bran? cereal\\t3/4 c  skim milk\\t2    egg whites\\t1/4 c  vegetable oil\\t1 c  sliced ripe banana; (about 1\\tvegetable cooking spray   \n",
       "3                                                                                                           5 1/2 c  flour\\t1    cake compressed yeast\\tor 1  cake dry yeast\\t2 c  milk, scalded and cooled\\t1/2 ts salt\\t1/2 c  cocoa\\t1/4 c  shortening\\t2    eggs, well beaten\\t1/2 c  sugar   \n",
       "4                                                                                                                                                                          bread -- to fill dish 2/3\\tful\\t2 c  skim milk\\t2/3 c  sugar\\t2    eggs -- or 4 egg whites\\t2 tb cocoa\\t1 ts vanilla   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Recipe  \n",
       "0                                                                                                                                                                                                    cream together butter and powdered sugar . blend in 1 cup flour and milk . spread evenly in bottom of ungreased 9-inch square pan . bake in 350 degree oven 10 to 12 minutes . beat eggs slightly ; combine dry ingredients and add to eggs . blend in vanilla and almond extract ; fold in almonds . spread over hot baked layer ; return to oven and bake 20 minutes longer . cool ; while warm , cut into 24 bars .   \n",
       "1                                                                                                                                                                                                                                                                                                                  combine dry ingredients and mix well . add corn syrup and bourbon and mix well . if too moist add a few cookie crumbs , if too dry add a little more bourbon . shape into small balls and roll in fruit sugar or fonely chopped pecans . store in an airtight container . also good made with dark rum .   \n",
       "2                                                                                                                               kellogg 's all-bran 1 . stir together flour , sugar , baking powder , salt , and cocoa powder . set aside . in large mixing bowl , combine all-bran cereal and milk . let stand 5 minutes or until cereal softens . add egg whites and oil . beat well . stir in bananas . add flour mixture stirring only until combined . portion batte evenly into twelve 2-1/2 inch muffin-pan cups coated with cooking spray . bake at 400 f. about 25 minutes or until lightly browned . serve warm .   \n",
       "3  soften yeast and dissolve 1 tablespoon sugar in lukewarm milk . add 3 cups flour and beat until smooth . cover and set aside to rise in a warm place until light . add shortening and sugar , which have been creamed together , eggs , cocoa , salt , and remainder of flour or enough to make a soft dough . knead lightly and place in well-oiled bowl . cover and set in a warm place until double in bulk about 2 hours . form into loaves . place in well-oiled bread pans , filling them 1/2 full . cover and let rise again until double in bulk . bake in hot oven -lrb- 425 f -rrb- 40 50 minutes . 2 loaves .   \n",
       "4                                                                                                                                                                                                                                   into a greased casserole dish break up enough bread to fill it 2/3 full . over this pour 2/3 cup sugar , 2 heaping tbsp cocoa that have been mixed together . toss all together lightly -lrb- to coat the bread -rrb- . to 2 cups of milk add 2 well beaten eggs and 1 tsp vanilla . pour this over the bread and it should just cover the pieces . bake at 350 fo r about 45 minutes .   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dev` and `test` are all lowercase already. `train` supposedly has 2 rows containing non-lowercase letters. Let's investigate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 rows in Ingredients have non lowercase letters but upon investigation, both are invalid rows so can simply remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_lowercase(df):\n",
    "    ingrnonlower = (~df.Ingredients.dropna().str.islower()).sum()\n",
    "    recipenonlower = (~df.Recipe.dropna().str.islower()).sum()\n",
    "    print(f\"Number of rows with a non-lowercase letter:\\nIngredients: {ingrnonlower}\\nRecipe: {recipenonlower}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a non-lowercase letter:\n",
      "Ingredients: 2\n",
      "Recipe: 0\n"
     ]
    }
   ],
   "source": [
    "check_all_lowercase(train_df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a non-lowercase letter:\n",
      "Ingredients: 0\n",
      "Recipe: 0\n"
     ]
    }
   ],
   "source": [
    "check_all_lowercase(dev_df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a non-lowercase letter:\n",
      "Ingredients: 0\n",
      "Recipe: 0\n"
     ]
    }
   ],
   "source": [
    "check_all_lowercase(test_df_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only two rows with non-lowercase letters have invalid Ingredients lists so we can simply filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7415</th>\n",
       "      <td>=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\t--=-=-=-=-=-= =-=-=-=-=-=-=-=-=-=-=-=-=-=</td>\n",
       "      <td>follow these 20 `` wellness '' facts and you have a better chance of living a longer and healthier life . michaelangelo was carving the rondanini just before he died at 89 . verdi finished his opera falstaff at 80 . but among non-smokers the risk of one form of lung cancer , adenocarcinoma , increases with the amount of saturated consumed daily . according to the `` new england journal of medicine '' women who have a female physician are twice as likely to receive pap smears . air bags increase the chance of surviving a frontal collision 29 % . about half of adult pedestrians killed in traffic accidents have been drinking . and more than a third were legally drunk . even a two-inch heel increases the pressure to 57 % . half a cantaloupe contains nearly double the amount of vitamin c than an orange . wild animals normally do n't get fat , and their meat is only slightly marbled . try increased fiber and prunes for constipation . researchers believe prunes contain a substance that stimulates intestinal contractions . but if you have asthma , they 're a special hazard . but because it 's `` low-fat '' does n't mean you can eat all you want . so high in calories . growing up is optional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11772</th>\n",
       "      <td>..........................</td>\n",
       "      <td>though it 's been around a long time , there 's something almost quintessentially american about the sandwich . after all it was the gambling table that prompted the fourth earl of sandwich -lrb- 1718-1792 -rrb- to have his food served to him between two slices of bread so he would n't have to interrupt his gaming to eat . actually though people were munching on various foods stuffed between slabs of bread long before the earl came into the picture .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Ingredients  \\\n",
       "7415   =-=-=-=-=-=-=-=-=-=-=-=-=-=-\\t--=-=-=-=-=-= =-=-=-=-=-=-=-=-=-=-=-=-=-=   \n",
       "11772                                               ..........................   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Recipe  \n",
       "7415   follow these 20 `` wellness '' facts and you have a better chance of living a longer and healthier life . michaelangelo was carving the rondanini just before he died at 89 . verdi finished his opera falstaff at 80 . but among non-smokers the risk of one form of lung cancer , adenocarcinoma , increases with the amount of saturated consumed daily . according to the `` new england journal of medicine '' women who have a female physician are twice as likely to receive pap smears . air bags increase the chance of surviving a frontal collision 29 % . about half of adult pedestrians killed in traffic accidents have been drinking . and more than a third were legally drunk . even a two-inch heel increases the pressure to 57 % . half a cantaloupe contains nearly double the amount of vitamin c than an orange . wild animals normally do n't get fat , and their meat is only slightly marbled . try increased fiber and prunes for constipation . researchers believe prunes contain a substance that stimulates intestinal contractions . but if you have asthma , they 're a special hazard . but because it 's `` low-fat '' does n't mean you can eat all you want . so high in calories . growing up is optional   \n",
       "11772                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             though it 's been around a long time , there 's something almost quintessentially american about the sandwich . after all it was the gambling table that prompted the fourth earl of sandwich -lrb- 1718-1792 -rrb- to have his food served to him between two slices of bread so he would n't have to interrupt his gaming to eat . actually though people were munching on various foods stuffed between slabs of bread long before the earl came into the picture .   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_orig[~train_df_orig.Ingredients.str.islower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ingredients(fpath, reverse_sort=True):\n",
    "    # get list of valid ingredients in the dataset from RecipeWithPlans\n",
    "    with open(fpath, \"r\") as f:\n",
    "        all_ings = json.load(f)\n",
    "    if reverse_sort:\n",
    "        # sort by longest to shortest ingredients\n",
    "        all_ings = sorted(all_ings, key=lambda i: len(i.split()), reverse=True)\n",
    "    return all_ings\n",
    "\n",
    "def get_ds_statistics(df):\n",
    "    all_ingredients_list = get_all_ingredients(\"./ingredient_set.json\")\n",
    "\n",
    "    df_ings_list = df.Ingredients.tolist()\n",
    "    df_recipes_list = [r for r in df.Recipe.tolist() if not pd.isna(r)]\n",
    "\n",
    "    print(\"Tokenizing...\")\n",
    "\n",
    "    tokenized_ings = [word_tokenize(i) for i in df_ings_list]\n",
    "    tokenized_recipes = [word_tokenize(r) for r in df_recipes_list]\n",
    "\n",
    "    ings_words = [i.split() for i in df_ings_list]\n",
    "    recipes_words = [r.split() for r in df_recipes_list]\n",
    "\n",
    "    ings_lens = [len(i) for i in ings_words]\n",
    "    recipes_lens = [len(r) for r in recipes_words]\n",
    "\n",
    "    print(\"Counting word frequencies...\")\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    freqdist_all = [FreqDist() for _ in range(2)]\n",
    "    freqdist_ing = FreqDist()\n",
    "\n",
    "    for i, wordset in enumerate([tokenized_ings, tokenized_recipes]):\n",
    "        for sample in wordset:\n",
    "            for word in sample:\n",
    "                if bool(re.match(\"\\w+\", word)) and word not in stop_words:\n",
    "                    freqdist_all[i][word] += 1\n",
    "                if i == 0 and word in all_ingredients_list:\n",
    "                    freqdist_ing[word] += 1\n",
    "\n",
    "    ## count number of ingredients per sample, i.e. how many ingredients are listed for each recipe\n",
    "    num_ings_per_sample = []\n",
    "\n",
    "    for i in tokenized_ings:\n",
    "        num_ings_i = 0\n",
    "        for word in i:\n",
    "            num_ings_i += word in all_ingredients_list\n",
    "        num_ings_per_sample.append(num_ings_i)\n",
    "\n",
    "    def get_n_gram(n, l):\n",
    "        cv = CountVectorizer(ngram_range=(n, n)).fit(l)\n",
    "        bow = cv.transform(l)\n",
    "        word_sum = bow.sum(axis=0)\n",
    "        word_freqs = sorted([[word, word_sum[0, idx]] for word, idx in cv.vocabulary_.items()],\n",
    "                            key=lambda w: w[1], reverse=True)\n",
    "        return word_freqs\n",
    "    \n",
    "    print(\"Get N-grams...\")\n",
    "    ing_bigrams = get_n_gram(2, df_ings_list)\n",
    "    ing_trigrams = get_n_gram(3, df_ings_list)\n",
    "\n",
    "    rec_bigrams = get_n_gram(2, df_recipes_list)\n",
    "    rec_trigrams = get_n_gram(3, df_recipes_list)\n",
    "\n",
    "    print(f\"Number of samples: {df.shape[0]}\")\n",
    "    print(\"===== INGREDIENTS =====\\n\"\n",
    "          f\"min. length: {min(ings_lens)}, max.length: {max(ings_lens)}, avg. length: {sum(ings_lens)/len(ings_lens):.2f}, \"\n",
    "          f\"std. length: {np.std(ings_lens):.2f}\\n\"\n",
    "          f\"Max. number of ingredients: {max(num_ings_per_sample)}, min. number of ingredients: {min(num_ings_per_sample)}, \"\n",
    "          f\"avg. number of ingredients: {sum(num_ings_per_sample)/len(num_ings_per_sample)}\\n\"\n",
    "          f\"10 most common tokens (excluding punuctuation and stopwords): {freqdist_all[0].most_common(10)}\\n\"\n",
    "          f\"10 most common ingredients: {freqdist_ing.most_common(10)}\\n\"\n",
    "          f\"Top 5 bigrams: {ing_bigrams[:5]}, top 5 trigrams: {ing_trigrams[:5]}\")\n",
    "    \n",
    "    print(\"===== RECIPES =====\\n\"\n",
    "          f\"min. length: {min(recipes_lens)}, max.length: {max(recipes_lens)}, avg. length: {sum(recipes_lens)/len(recipes_lens):.2f}, \"\n",
    "          f\"std. length: {np.std(recipes_lens):.2f}\\n\"\n",
    "          f\"10 most common tokens (excluding punuctuation and stopwords): {freqdist_all[1].most_common(10)}\\n\"\n",
    "          f\"Top 5 bigrams: {rec_bigrams[:5]}, top 5 trigrams: {rec_trigrams[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Counting word frequencies...\n",
      "Get N-grams...\n",
      "Number of samples: 101340\n",
      "===== INGREDIENTS =====\n",
      "min. length: 1, max.length: 426, avg. length: 42.25, std. length: 21.04\n",
      "Max. number of ingredients: 81, min. number of ingredients: 0, avg. number of ingredients: 11.025054272745214\n",
      "10 most common tokens (excluding punuctuation and stopwords): [('1', 331593), ('c', 272937), ('ts', 167667), ('2', 165295), ('1/2', 164230), ('tb', 133253), ('1/4', 84396), ('chopped', 69067), ('salt', 59032), ('3', 56221)]\n",
      "10 most common ingredients: [('salt', 59032), ('pepper', 47871), ('sugar', 46062), ('oil', 34928), ('butter', 32738), ('flour', 31032), ('water', 30622), ('garlic', 27853), ('onion', 26057), ('juice', 22202)]\n",
      "Top 5 bigrams: [['ts salt', 32936], ['salt ts', 12378], ['to taste', 12196], ['olive oil', 12155], ['finely chopped', 11261]], top 5 trigrams: [['ts salt ts', 10473], ['all purpose flour', 6940], ['ts baking powder', 6209], ['pepper to taste', 5745], ['tb olive oil', 5733]]\n",
      "===== RECIPES =====\n",
      "min. length: 1, max.length: 881, avg. length: 106.37, std. length: 74.74\n",
      "10 most common tokens (excluding punuctuation and stopwords): [('add', 129520), ('minutes', 117659), ('heat', 83739), ('stir', 58022), ('mixture', 55287), ('water', 55111), ('cook', 50359), ('salt', 47913), ('place', 47337), ('1', 46684)]\n",
      "Top 5 bigrams: [['in the', 36146], ['add the', 33238], ['of the', 32451], ['or until', 26945], ['stir in', 26900]], top 5 trigrams: [['minutes or until', 18636], ['salt and pepper', 13030], ['bring to boil', 11137], ['over medium heat', 9145], ['preheat oven to', 7568]]\n"
     ]
    }
   ],
   "source": [
    "# This takes around 3-4 minutes\n",
    "get_ds_statistics(train_df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ds_statistics(dev_df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ds_statistics(test_df_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(df, patterns, replacements, columns, regex=False):\n",
    "    # patterns: List[str]\n",
    "    # replacements: List[str]\n",
    "    # columns: List[str]\n",
    "    if type(replacements) == str:\n",
    "        replacements = [replacements] * len(patterns)\n",
    "    if type(columns) == str:\n",
    "        columns = [columns] * len(patterns)\n",
    "\n",
    "    for pat, rep, col in zip(patterns, replacements, columns):\n",
    "        df[col] = df[col].str.replace(pat, rep, regex=regex)\n",
    "\n",
    "def add_tags(df, add_intermediate_tag=False):\n",
    "    assert 'Ingredients' in df.columns and 'Recipe' in df.columns\n",
    "\n",
    "    replace(df, ['\\t'], ' <INGREDIENT> ' if add_intermediate_tag else ' ', 'Ingredients')\n",
    "    df.Ingredients = '<INGREDIENT_START> ' + df.Ingredients + ' <INGREDIENT_END>'\n",
    "\n",
    "    replace(df, ['.', ';'], ' <RECIPE_STEP> ' if add_intermediate_tag else ' ', 'Recipe')\n",
    "    df.Recipe = '<RECIPE_START> ' + df.Recipe + ' <RECIPE_END>'\n",
    "\n",
    "def preprocess_data(orig_df, max_ingr_len=150, max_recipe_len=600, min_recipe_len=5, min_ingredients=1,\n",
    "                    add_intermediate_tag=False):\n",
    "    df = orig_df.copy() # ensure original data is not mutated (mostly for verification purposes)\n",
    "\n",
    "    ## drop NA\n",
    "    df = df.dropna()\n",
    "\n",
    "    ## keep only rows with all lowercase (Recipe column is all lowercase already)\n",
    "    df = df[df.Ingredients.str.islower()]\n",
    "\n",
    "    ## replace brackets with space\n",
    "    replace(df, ['[()]'], ' ', ['Ingredients', 'Recipe'], regex=True)\n",
    "\n",
    "    ## add spaces around non-words (exclude whitespace, apostrophe, period (treated separately below))\n",
    "    replace(df, [\"([^0-9a-zA-Z.'\\\"/ ])\"]*2, r\" \\1 \", ['Ingredients', 'Recipe'], regex=True)\n",
    "    # add spaces around periods (excluding decimal places)\n",
    "    replace(df, [r\"\\.(?!\\d)\"]*2, r\" . \", ['Ingredients', 'Recipe'], regex=True)\n",
    "    # add spaces around word/word\n",
    "    replace(df, [r\"([^0-9])\\/([^0-9])\"]*2, r\"\\1 / \\2\", ['Ingredients', 'Recipe'], regex=True)\n",
    "\n",
    "    ## add tags for ingredients and recipes\n",
    "    add_tags(df, add_intermediate_tag=add_intermediate_tag)\n",
    "\n",
    "    ## replace >1 whitespace with a single space\n",
    "    replace(df, ['[ ]{2,}']*2, \" \", ['Ingredients', 'Recipe'], regex=True)\n",
    "\n",
    "    ## remove leading and trailing whitespace\n",
    "    df.Ingredients = df.Ingredients.str.strip()\n",
    "    df.Recipe = df.Recipe.str.strip()\n",
    "\n",
    "    if add_intermediate_tag:\n",
    "        ## remove consecutive tags, for ex. <INGREDIENT>[0 or more whitespace]<INGREDIENT>\n",
    "        replace(df, [\"<INGREDIENT>[ \\t\\n]*([ \\t\\n]*<INGREDIENT>)+\", \"<RECIPE_STEP>[ \\t\\n]*([ \\t\\n]*<RECIPE_STEP>)+\"], \n",
    "        [\"<INGREDIENT>\", \"<RECIPE_STEP>\"], [\"Ingredients\", \"Recipe\"], regex=True)\n",
    "\n",
    "    ## filter out recipes and ingredients above/below limit\n",
    "    recipe_lens = df.Recipe.apply(lambda r: len(r.split()))\n",
    "    df = df[(recipe_lens > min_recipe_len) & (recipe_lens < max_recipe_len)]\n",
    "    df = df[df.Ingredients.apply(lambda i: len(i.split())) < max_ingr_len]\n",
    "\n",
    "    if add_intermediate_tag:\n",
    "        ## filter out those with <1 ingredients\n",
    "        df = df[df.Ingredients.str.count('<INGREDIENT>') >= min_ingredients]\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Number of data samples before preprocessing: {len(orig_df)}\\n\"\n",
    "          f\"Number of data samples after preprocessing: {len(df)} ({len(df) * 100/len(orig_df):.3f}%)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 101340\n",
      "Number of data samples after preprocessing: 100637 (99.306%)\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df_orig, max_ingr_len=MAX_INGR_LEN, max_recipe_len=MAX_RECIPE_LEN, add_intermediate_tag=add_intermediate_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 797\n",
      "Number of data samples after preprocessing: 793 (99.498%)\n"
     ]
    }
   ],
   "source": [
    "dev_df = preprocess_data(dev_df_orig, max_ingr_len=MAX_INGR_LEN, max_recipe_len=MAX_RECIPE_LEN, add_intermediate_tag=add_intermediate_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples before preprocessing: 778\n",
      "Number of data samples after preprocessing: 774 (99.486%)\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df_orig, max_ingr_len=MAX_INGR_LEN, max_recipe_len=MAX_RECIPE_LEN, add_intermediate_tag=add_intermediate_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, add_intermediate_tag=False):\n",
    "        \"\"\"Vocabulary class which can convert a valid word to unique index and converting the index back to word.\"\"\"\n",
    "        special_tags = dict(SPECIAL_TAGS)\n",
    "        if not add_intermediate_tag:\n",
    "            special_tags.pop(ING)\n",
    "            special_tags.pop(REC)\n",
    "        ## initialize\n",
    "        self._word2index = special_tags\n",
    "        self.word2count = {k: 0 for k in special_tags.keys()}\n",
    "        self.index2word = {v:k for k,v in special_tags.items()}\n",
    "        self.n_unique_words = len(self.index2word) # total number of words in the dictionary.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._word2index)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self._word2index:\n",
    "            self._word2index[word] = self.n_unique_words\n",
    "            self.index2word[self.n_unique_words] = word\n",
    "            self.n_unique_words += 1\n",
    "            self.word2count[word] = 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def word_exist_in_vocab(self, word):\n",
    "        return word in self._word2index\n",
    "\n",
    "    def word2index(self, word):\n",
    "        if word not in self._word2index:\n",
    "            return self._word2index[UNKNOWN_WORD]\n",
    "        return self._word2index[word]\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_padding(self):\n",
    "        # NOTE: should be called after finished with building vocab\n",
    "        self.add_word(PAD_WORD)\n",
    "\n",
    "    def add_unknown(self):\n",
    "        self.add_word(UNKNOWN_WORD)\n",
    "\n",
    "    def populate(self, df):\n",
    "        for rowid in tqdm(range(len(df))):\n",
    "            df_row = df.iloc[rowid]\n",
    "            for i in range(2):\n",
    "                self.add_sentence(df_row.iloc[i])\n",
    "        self.add_unknown() # unknown word is for words in the dev/test not present in train\n",
    "        self.add_padding() # padding should be last in the vocabulary (for convenience in decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100637/100637 [00:12<00:00, 8000.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44315"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocabulary(add_intermediate_tag=add_intermediate_tag)\n",
    "vocab.populate(train_df)\n",
    "vocab.n_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [00:00<00:00, 5427.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4787"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_vocab = Vocabulary(add_intermediate_tag=add_intermediate_tag)\n",
    "dev_vocab.populate(dev_df)\n",
    "dev_vocab.n_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:00<00:00, 7195.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4550"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vocab = Vocabulary(add_intermediate_tag=add_intermediate_tag)\n",
    "test_vocab.populate(test_df)\n",
    "test_vocab.n_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, df, vocab, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): dataframe with two columns: \"Ingredients\" and \"Recipe\"\n",
    "            vocab (Vocabulary): to convert word2index\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.ingredient_recipe_df = df\n",
    "        self.vocab = vocab\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ingredient_recipe_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.ingredient_recipe_df.iloc[index]\n",
    "        ingredient_tens = torch.tensor([self.vocab.word2index(w) for w in row.Ingredients.split(\" \")],\n",
    "                                       dtype=torch.long, device=DEVICE)\n",
    "        if self.train:\n",
    "            recipe_tens = torch.tensor([self.vocab.word2index(w) for w in row.Recipe.split(\" \")],\n",
    "                                        dtype=torch.long, device=DEVICE)\n",
    "        else:\n",
    "            recipe_tens = row.Recipe.split(\" \") # List[str]\n",
    "        return (ingredient_tens, recipe_tens)\n",
    "    \n",
    "# inspired by https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "def pad_collate(vocab, train=True):\n",
    "\n",
    "    def _pad_collate(batch):\n",
    "        # print(len(batch))\n",
    "        # print(batch[0])\n",
    "        # ingredients: tuple of len batch_size with Tensor elements containing all ingredients in batch\n",
    "        # recipes: tuple of len batch_size with Tensor elements containing all recipes in batch\n",
    "        #           (or in eval:) tuple of len batch_size with elements List[str]\n",
    "        # print(batch)\n",
    "        ingredients, recipes = zip(*batch)\n",
    "        # print(ingredients)\n",
    "        # print(recipes)\n",
    "        ingr_lens = torch.tensor([len(x) for x in ingredients], dtype=torch.long, device=DEVICE)\n",
    "        ingredients_padded = pad_sequence(ingredients, batch_first=True, padding_value=vocab.word2index(PAD_WORD))\n",
    "\n",
    "        if train:\n",
    "            recipe_lens = torch.tensor([len(r) for r in recipes], dtype=torch.long, device=DEVICE)\n",
    "            recipes_padded = pad_sequence(recipes, batch_first=True, padding_value=vocab.word2index(PAD_WORD))\n",
    "        else:\n",
    "            recipe_lens = None\n",
    "            recipes_padded = list(recipes)\n",
    "\n",
    "        return ingredients_padded, recipes_padded, ingr_lens, recipe_lens\n",
    "    \n",
    "    return _pad_collate\n",
    "\n",
    "def pack(x_embed, x_lens):\n",
    "    # convert tensor with padding to a PackedSequence, this allows rnns to ignore paddings\n",
    "    return pack_padded_sequence(x_embed, x_lens.cpu().int(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "def unpack(out_packed, padding_val):\n",
    "    out_padded, out_lens = pad_packed_sequence(out_packed, batch_first=True, padding_value=padding_val)\n",
    "    return out_padded, out_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RecipeDataset(train_df, vocab)\n",
    "# used for getting validation loss\n",
    "dev_ds_val_loss = RecipeDataset(dev_df, vocab, train=True) \n",
    "# used for getting validation BLEU, and other metrics\n",
    "dev_ds_val_met = RecipeDataset(dev_df, vocab, train=False) \n",
    "test_ds = RecipeDataset(test_df, vocab, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training, Validation, and Testing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_regex(ingredients_lst):\n",
    "    return r'\\b(?:' + '|'.join(re.escape(i) for i in ingredients_lst) + r')\\b'\n",
    "\n",
    "def get_invalid_ingredients_regex(ingredients_lst):\n",
    "    # return r'(^|\\.\\s|,\\s)(\\b(?:' + '|'.join(re.escape(ingredient) for ingredient in ingredients_lst) + r')\\b)'\n",
    "    return r'(^|\\.\\s)(\\b(?:' + '|'.join(re.escape(ingredient) for ingredient in ingredients_lst) + r')\\b)'\n",
    "\n",
    "def get_all_ingredients(fpath, reverse_sort=True):\n",
    "    # get list of valid ingredients in the dataset from RecipeWithPlans\n",
    "    with open(fpath, \"r\") as f:\n",
    "        all_ings = json.load(f)\n",
    "    if reverse_sort:\n",
    "        # sort by longest to shortest ingredients\n",
    "        all_ings = sorted(all_ings, key=lambda i: len(i.split()), reverse=True)\n",
    "    return all_ings\n",
    "\n",
    "def find_ingredients_in_text(txt, regex, enforce_unique=True):\n",
    "    res = re.findall(regex, txt)\n",
    "    if enforce_unique:\n",
    "        res = set(res)\n",
    "    return res\n",
    "\n",
    "def calc_bleu(gt_recipes, gen_recipes, split_gt=False, split_gen=False):\n",
    "    \"\"\"Calculate corpus BLEU-4 score.\n",
    "\n",
    "    Args:\n",
    "        gt_recipes (List): len N\n",
    "        gen_recipes (List[List] or List): \n",
    "    \"\"\"\n",
    "    gt_recipes_lst2 = [[word_tokenize(gt)] if split_gt else [gt] for gt in gt_recipes]\n",
    "    if split_gen:\n",
    "        gen_recipes = [word_tokenize(r) for r in gen_recipes]\n",
    "    return corpus_bleu(gt_recipes_lst2, gen_recipes)\n",
    "\n",
    "def calc_meteor(gt_recipes, gen_recipes, split_gt=False, split_gen=False):\n",
    "    if split_gt:\n",
    "        gt_recipes_lst2 = [word_tokenize(gt) for gt in gt_recipes]\n",
    "    else:\n",
    "        gt_recipes_lst2 = gt_recipes\n",
    "\n",
    "    meteor_score = 0\n",
    "    for i in tqdm(range(len(gen_recipes))):\n",
    "        generated_recipe = word_tokenize(gen_recipes[i]) if split_gen else gen_recipes[i]\n",
    "        gt_recipes_i = gt_recipes_lst2[i]\n",
    "        meteor_score += meteor([gt_recipes_i], generated_recipe)\n",
    "    return meteor_score / len(gen_recipes)\n",
    "\n",
    "def eval_decoder_iter(decoder, decoder_hidden, decoder_cell, encoder_houts,\n",
    "                      ingredients, max_recipe_len, vocab, decoder_mode=\"basic\"):\n",
    "    assert decoder_mode in [\"basic\", \"attention\"]\n",
    "    \n",
    "    N = ingredients.size(0)\n",
    "    all_decoder_outs = [[REC_START] for _ in range(N)] # stores the decoder outputs for each batch sample\n",
    "\n",
    "    valid = torch.ones([N], device=DEVICE).bool() # Tensor[N] \n",
    "    decoder_input = torch.full([N], SPECIAL_TAGS[REC_START], dtype=torch.long, device=DEVICE)\n",
    "    \n",
    "    for _ in range(max_recipe_len-1): # generations are bounded by max length (-1 because of EOS)\n",
    "        decoder_hidden_i = decoder_hidden[:, valid] # [1, N_valid, H]\n",
    "        decoder_cell_i = decoder_cell[:, valid]\n",
    "\n",
    "        if decoder_mode == \"basic\":\n",
    "            # decoder_out: log probabilities over vocab; [N_valid, |Vocab|-1]\n",
    "            # decoder_hfinal: final hidden state; [num_layers=1, N_valid, H]\n",
    "            decoder_out, decoder_hidden_i, decoder_cell_i = decoder(decoder_input, decoder_hidden_i, decoder_cell_i)\n",
    "        elif decoder_mode == \"attention\":\n",
    "            encoder_houts_i = encoder_houts[valid] # [N_valid, L_i, H]\n",
    "            decoder_out, decoder_hidden_i, decoder_cell_i, attn_weights_i = decoder(\n",
    "                decoder_input, decoder_hidden_i, decoder_cell_i, encoder_houts_i, ingredients[valid])\n",
    "            \n",
    "        # decoder_tok_preds: token with highest log probability\n",
    "        decoder_topk_preds = decoder_out.topk(1)[1].reshape(-1) # [N_valid]\n",
    "\n",
    "        ## store generated output\n",
    "        for dec_idx, valid_n in zip(range(len(decoder_topk_preds)), valid.nonzero()):\n",
    "            valid_idx = valid_n.item()\n",
    "            all_decoder_outs[valid_idx].append(\n",
    "                vocab.index2word[decoder_topk_preds[dec_idx].item()]) # str\n",
    "\n",
    "        ## check for end of recipe\n",
    "        not_eor= decoder_topk_preds != SPECIAL_TAGS[REC_END] # [N_valid]\n",
    "        # update valid\n",
    "        valid_temp = valid.clone() # to avoid single mem location error\n",
    "        valid_temp[valid] = not_eor\n",
    "        valid = valid_temp\n",
    "        del valid_temp\n",
    "        # valid = torch.logical_and(valid, not_eor)\n",
    "\n",
    "        # update decoder input for next iteration\n",
    "        decoder_input = decoder_topk_preds[not_eor] # [N_valid_next]\n",
    "\n",
    "        # update only valid decoder_hidden\n",
    "        decoder_hidden[:, valid] = decoder_hidden_i[:, not_eor]\n",
    "        decoder_cell[:, valid] = decoder_cell_i[:, not_eor]\n",
    "\n",
    "        if valid.sum() < 1:\n",
    "            break\n",
    "    else: # if did not break meaning 1 or more exceeded max generation limit\n",
    "        # forcably insert recipe stop tok at the end\n",
    "        for valid_n in valid.nonzero():\n",
    "            valid_idx = valid_n.item()\n",
    "            all_decoder_outs[valid_idx].append(REC_END)\n",
    "\n",
    "    return all_decoder_outs\n",
    "\n",
    "def get_predictions_iter(ingredients, ing_lens, encoder, decoder, vocab, max_recipe_len=600, \n",
    "                         decoder_mode=\"basic\"):\n",
    "    \"\"\"Get predictions from trained model for a single iteration. Processes batched data.\n",
    "    NOTE: ensure that this function is wrapped in `with torch.no_grad():`\n",
    "\n",
    "    Args:\n",
    "        ingredients (torch.Tensor): padded ingredients tensor in idx form; \n",
    "                                    shape [N, L_i], where L_i = max ingredients length in batch\n",
    "        ing_lens (torch.Tensor): unpadded length of ingredients; shape [N]\n",
    "        rec_lens (torch.Tensor): unpadded length of recipes; shape [N]\n",
    "        encoder (EncoderRNN): encoder RNN module\n",
    "        decoder (DecoderRNN): decoder RNN module\n",
    "    \"\"\"\n",
    "    assert encoder.training is False and decoder.training is False\n",
    "\n",
    "    N = ingredients.size(0)\n",
    "\n",
    "    ## feed ingredients through encoder\n",
    "    # enc_out: padded encoder output tensor with shape [N, L, H]\n",
    "    # enc_out_lens: unpadded sequence lengths; tensor with shape [N]\n",
    "    # enc_h_final: final hidden state: [num_layers=1, N, H]\n",
    "    # enc_c_final: final cell state: [num_layers=1, N, H]\n",
    "    enc_out, enc_out_lens, enc_h_final, enc_c_final = encoder(ingredients, ing_lens)\n",
    "    \n",
    "    # initialize decoder hidden state as final encoder hidden state\n",
    "    decoder_hidden = enc_h_final\n",
    "    decoder_cell = enc_c_final\n",
    "\n",
    "    # List[List[str]]\n",
    "    \n",
    "    all_decoder_outs = eval_decoder_iter(decoder, decoder_hidden, decoder_cell,\n",
    "                                         enc_out, ingredients, max_recipe_len,\n",
    "                                         vocab, decoder_mode=decoder_mode)\n",
    "\n",
    "    return all_decoder_outs\n",
    "\n",
    "def eval(encoder, decoder, dataset, vocab, batch_size=4, max_recipe_len=600, decoder_mode=\"basic\"):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate(vocab, train=False))\n",
    "\n",
    "    all_decoder_outs = [] # (List[List[str]]): List of len `N`, each element is the generated sequence for that sample\n",
    "    all_gt_recipes = [] # (List[List[str]])\n",
    "    all_gt_ingredients = []\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ingredients, recipes, ing_lens, _ in tqdm(dataloader):\n",
    "            # ingredients: Tensor[N, L_i] padded ingredients\n",
    "            # recipes (List[List[str]]): list of len N, each element is a\n",
    "            #                               list of len `|gt_i|`, which is the length of the i-th ground-truth sequence\n",
    "\n",
    "            # dec_outs (List[List[str]]): list of len `batch_size`, each element is a \n",
    "            #                               list of len `gen_size`, which is the size of the generated sequence, and each element is a \n",
    "            #                                   str representing a single word in the generated recipe\n",
    "            dec_outs = get_predictions_iter(ingredients, ing_lens, encoder, decoder, vocab, \n",
    "                                            max_recipe_len=max_recipe_len, decoder_mode=decoder_mode)\n",
    "            \n",
    "            all_decoder_outs += dec_outs\n",
    "            all_gt_recipes += recipes\n",
    "            all_gt_ingredients += ingredients.tolist()\n",
    "\n",
    "    return all_decoder_outs, all_gt_recipes, all_gt_ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decoder_iter(decoder, decoder_hidden, decoder_cell, encoder_houts, \n",
    "                       ingredients, recipes, padded_rec_len, rec_lens,\n",
    "                       pad_word_idx, decoder_mode=\"basic\"):\n",
    "    assert decoder_mode in [\"basic\", \"attention\"]\n",
    "\n",
    "    all_decoder_outs = [] # List of [N, |Vocab|-1]\n",
    "    all_gt = [] # List of [N]\n",
    "    ## NOTE: recipes already contain start token no need to add manually\n",
    "    # encoder_houts_i = encoder_houts # [N, L_i, H]\n",
    "    for di in range(padded_rec_len-1):\n",
    "        # get batches which have valid (non-padding and non ending) tokens as input\n",
    "        valid = (rec_lens - 1) > di\n",
    "        decoder_input_i = recipes[valid, di] # [N_valid]\n",
    "        decoder_hidden_i = decoder_hidden[:,valid] # [n_layers=1, N_valid, H]\n",
    "        decoder_cell_i = decoder_cell[:, valid] # [n_layers=1, N_valid, H]\n",
    "\n",
    "        if decoder_mode == \"basic\":\n",
    "            # decoder_out: log probabilities over vocab; [N_valid, |Vocab|-1]\n",
    "            # decoder_hfinal: final hidden state; [num_layers=1, N_valid, H]\n",
    "            decoder_out, decoder_hidden_i, decoder_cell_i = decoder(\n",
    "                decoder_input_i, decoder_hidden_i, decoder_cell_i)\n",
    "            attn_weights = None\n",
    "        elif decoder_mode == \"attention\":\n",
    "            encoder_houts_i = encoder_houts[valid] # [N_valid, L_i, H]\n",
    "            decoder_out, decoder_hidden_i, decoder_cell_i, attn_weights_i = decoder(\n",
    "                decoder_input_i, decoder_hidden_i, decoder_cell_i, encoder_houts_i, ingredients[valid])\n",
    "\n",
    "        all_decoder_outs.append(decoder_out)\n",
    "\n",
    "        # because we ensured that input cannot be end token, there is a guaranteed non-padding token\n",
    "        # for each valid batch sample\n",
    "        gt_i = recipes[valid, di+1] # [N_valid]\n",
    "        assert (gt_i != pad_word_idx).all(), f\"gt_i should not have padding but got: {gt_i}\"\n",
    "        all_gt.append(gt_i)\n",
    "\n",
    "        # update only valid decoder_hidden and decoder_cell\n",
    "        decoder_hidden[:, valid] = decoder_hidden_i\n",
    "        decoder_cell[:, valid] = decoder_cell_i\n",
    "\n",
    "    return all_decoder_outs, all_gt\n",
    "\n",
    "def get_validation_loss_iter(encoder, decoder, ingredients, recipes, ing_lens, rec_lens, vocab, criterion,\n",
    "                             decoder_mode=\"basic\"):\n",
    "    assert not encoder.training and not decoder.training\n",
    "    padded_rec_len = recipes.size(1) # L_r\n",
    "\n",
    "    ## feed ingredients through encoder\n",
    "    # enc_out: padded encoder output tensor with shape [N, L, H]\n",
    "    # enc_out_lens: unpadded sequence lengths; tensor with shape [N]\n",
    "    # enc_h_final: final hidden state: [num_layers=1, N, H]\n",
    "    # enc_c_final: final cell state: [num_layers=1, N, H]\n",
    "    enc_out, enc_out_lens, enc_h_final, enc_c_final = encoder(ingredients, ing_lens)\n",
    "\n",
    "    # initialize decoder hidden state and cell state as final encoder hidden and cell state\n",
    "    decoder_hidden = enc_h_final\n",
    "    decoder_cell = enc_c_final\n",
    "\n",
    "    if TEACHER_FORCING_RATIO < 1:\n",
    "        raise ValueError(\"Non-teacher forcing is not implemented\")\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    all_decoder_outs, all_gt = train_decoder_iter(decoder, decoder_hidden, decoder_cell, enc_out, \n",
    "                                                  ingredients, recipes, padded_rec_len, rec_lens, \n",
    "                                                  vocab.word2index(PAD_WORD), decoder_mode=decoder_mode)\n",
    "    \n",
    "    all_decoder_outs = torch.cat(all_decoder_outs, dim=0)\n",
    "    all_gt = torch.cat(all_gt, dim=0)\n",
    "\n",
    "    # mean Negative Log Likelihood Loss\n",
    "    loss = criterion(all_decoder_outs, all_gt)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def get_validation_loss(encoder, decoder, dataset, vocab, batch_size=4, decoder_mode=\"basic\"):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate(vocab))\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (ingredients, recipes, ing_lens, rec_lens) in tqdm(enumerate(dataloader)):\n",
    "            loss = get_validation_loss_iter(encoder, decoder, ingredients, recipes, ing_lens, rec_lens,\n",
    "                                            vocab, criterion, decoder_mode=decoder_mode)\n",
    "            total_loss += loss\n",
    "\n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(encoder, decoder, identifier):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        encoder (_type_): _description_\n",
    "        decoder (_type_): _description_\n",
    "        identifier (str): suffix of the filename should not include \"encoder\" or \"decoder\" and does not inclue file extension, .pth\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(\"./saved_models\"):\n",
    "        os.makedirs(\"saved_models\")\n",
    "    \n",
    "    encpath = os.path.join(\"saved_models\", f\"encoder_{identifier}.pth\")\n",
    "    decpath = os.path.join(\"saved_models\", f\"decoder_{identifier}.pth\")\n",
    "\n",
    "    torch.save(encoder.state_dict(), encpath)\n",
    "    torch.save(decoder.state_dict(), decpath)\n",
    "\n",
    "def load_model(encoder, decoder, identifier):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        encoder (_type_): _description_\n",
    "        decoder (_type_): _description_\n",
    "        identifier (str): suffix of the filename should not include \"encoder\" or \"decoder\" and does not inclue file extension, .pth\n",
    "    \"\"\"\n",
    "    encpath = os.path.join(\"saved_models\", f\"encoder_{identifier}.pth\")\n",
    "    decpath = os.path.join(\"saved_models\", f\"decoder_{identifier}.pth\")\n",
    "\n",
    "    encoder.load_state_dict(torch.load(encpath))\n",
    "    decoder.load_state_dict(torch.load(decpath))\n",
    "\n",
    "def save_log(identifier, train_out, enc_optim, dec_optim, enc_sched, dec_sched):\n",
    "    if not os.path.isdir(\"./logs\"):\n",
    "        os.makedirs(\"logs\") \n",
    "    savepath = os.path.join(\"logs\",f\"log_{identifier}.txt\") \n",
    "    with open(savepath, \"w\") as f:\n",
    "        f.write(str(enc_optim) + \"\\n\")\n",
    "        f.write(str(dec_optim) + \"\\n\")\n",
    "        f.write(str(enc_sched) + \"\\n\")\n",
    "        f.write(str(dec_sched) + \"\\n\")\n",
    "        f.write(\"========================\\n\")\n",
    "        f.write(train_out)\n",
    "\n",
    "def train_iter(ingredients, recipes, ing_lens, rec_lens, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "               decoder_mode=\"basic\", prevent_pretrained_grad_update=True, vocab=None # !remove later\n",
    "               ):\n",
    "    \"\"\"Single training iteration. Processes batched data.\n",
    "\n",
    "    Args:\n",
    "        ingredients (torch.Tensor): padded ingredients tensor in idx form; \n",
    "                                    shape [N, L_i], where L_i = max ingredients length in batch\n",
    "        recipes (torch.Tensor): padded recipes tensor in idx form;\n",
    "                                shape [N, L_r], where L_r = max recipes length in batch\n",
    "        ing_lens (torch.Tensor): unpadded length of ingredients; shape [N]\n",
    "        rec_lens (torch.Tensor): unpadded length of recipes; shape [N]\n",
    "        encoder (EncoderRNN): encoder RNN module\n",
    "        decoder (DecoderRNN): decoder RNN module\n",
    "        encoder_optimizer (torch.optim)\n",
    "        decoder_optimizer (torch.optim)\n",
    "        criterion (torch.nn.NLLLoss): loss function\n",
    "    \"\"\"\n",
    "\n",
    "    ## reset gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    N = ingredients.size(0)\n",
    "    padded_ing_len = ingredients.size(1) # L_i\n",
    "    padded_rec_len = recipes.size(1) # L_r\n",
    "\n",
    "\n",
    "    ## feed ingredients through encoder\n",
    "    # enc_out: padded encoder output tensor with shape [N, L, H]\n",
    "    # enc_out_lens: unpadded sequence lengths; tensor with shape [N]\n",
    "    # enc_h_final: final hidden state: [num_layers=1, N, H]\n",
    "    # enc_c_final: final cell state: [num_layers=1, N, H]\n",
    "    enc_out, enc_out_lens, enc_h_final, enc_c_final = encoder(ingredients, ing_lens)\n",
    "\n",
    "    # initialize decoder hidden state and cell state as final encoder hidden and cell state\n",
    "    decoder_hidden = enc_h_final\n",
    "    decoder_cell = enc_c_final\n",
    "\n",
    "    if TEACHER_FORCING_RATIO < 1:\n",
    "        raise ValueError(\"Non-teacher forcing is not implemented\")\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    all_decoder_outs, all_gt = train_decoder_iter(decoder, decoder_hidden, decoder_cell, enc_out, \n",
    "                                                  ingredients, recipes, padded_rec_len, rec_lens, \n",
    "                                                  vocab.word2index(PAD_WORD), decoder_mode=decoder_mode)\n",
    "    \n",
    "    all_decoder_outs = torch.cat(all_decoder_outs, dim=0)\n",
    "    all_gt = torch.cat(all_gt, dim=0)\n",
    "\n",
    "    # mean Negative Log Likelihood Loss\n",
    "    loss = criterion(all_decoder_outs, all_gt)\n",
    "\n",
    "    ## backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # print(\"=====BEFORE MASKING=====\")\n",
    "    # print(\"ENCODER EMBEDDING WEIGHT GRADS of shape:\", encoder.embedding.weight.grad.shape)\n",
    "    # print(encoder.embedding.weight.grad[:10, :10])\n",
    "\n",
    "    # print(\"DECODER EMBEDDING WEIGHT GRADS of shape:\", decoder.embedding.weight.grad.shape)\n",
    "    # print(decoder.embedding.weight.grad[:10, :10])\n",
    "\n",
    "    # print(\"=====AFTER MASKING=====\")\n",
    "    if prevent_pretrained_grad_update:\n",
    "        encoder.update_embedding_grad(encoder.embedding.weight.grad)\n",
    "        decoder.update_embedding_grad(decoder.embedding.weight.grad)\n",
    "    # print(\"ENCODER EMBEDDING WEIGHT GRADS of shape:\", encoder.embedding.weight.grad.shape)\n",
    "    # print(encoder.embedding.weight.grad[:10, :10])\n",
    "\n",
    "    # print(\"DECODER EMBEDDING WEIGHT GRADS of shape:\", decoder.embedding.weight.grad.shape)\n",
    "    # print(decoder.embedding.weight.grad[:10, :10])\n",
    "\n",
    "\n",
    "    ## update params\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, dataset, n_epochs, vocab,\n",
    "          decoder_mode=\"basic\", batch_size=4, enc_lr_scheduler=None, dec_lr_scheduler=None, \n",
    "          dev_ds_val_loss=None, dev_ds_val_met=None, identifier=\"\", min_bleu_to_save=0.01,\n",
    "          verbose=True, verbose_iter_interval=10):\n",
    "    assert (enc_lr_scheduler is None and dec_lr_scheduler is None) or (enc_lr_scheduler is not None and dec_lr_scheduler is not None)\n",
    "    \n",
    "    evaluate = dev_ds_val_loss is not None and dev_ds_val_met is not None\n",
    "    assert (not evaluate) or (evaluate and len(identifier) > 0)\n",
    "    \n",
    "    use_scheduler =  enc_lr_scheduler is not None and dec_lr_scheduler is not None\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate(vocab))\n",
    "    total_iters = len(dataloader)\n",
    "    \n",
    "    \n",
    "    epoch_losses = torch.zeros(size=[n_epochs], dtype=torch.double, device=DEVICE, requires_grad=False)\n",
    "    val_epoch_losses = torch.zeros(size=[n_epochs], dtype=torch.double, device=DEVICE, requires_grad=False)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    log = \"\"\n",
    "    \n",
    "    highest_bleu = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if verbose: print(f\"Starting epoch {epoch+1}/{n_epochs}, \"\n",
    "                          f\"enc lr scheduler: {enc_lr_scheduler.get_last_lr()}, dec lr scheduler: {dec_lr_scheduler.get_last_lr()}\" \\\n",
    "                            if use_scheduler else \"\")\n",
    "        epoch_loss = 0 # accumulate total loss during epoch\n",
    "        print_epoch_loss = 0 # accumulate losses for printing\n",
    "\n",
    "        start_epoch_time = time.time()\n",
    "        for iter_idx, (ingredients, recipes, ing_lens, rec_lens) in enumerate(dataloader):\n",
    "            if verbose and iter_idx > 0  and iter_idx % verbose_iter_interval == 0:\n",
    "                msg = f\"(Epoch {epoch}, iter {iter_idx}/{total_iters}) Average loss so far: {print_epoch_loss/verbose_iter_interval:.3f}\"\n",
    "                log += msg + \"\\n\"\n",
    "                print(msg)\n",
    "                print_epoch_loss = 0\n",
    "            loss = train_iter(ingredients, recipes, ing_lens, rec_lens, encoder, decoder, \n",
    "                                   encoder_optimizer, decoder_optimizer, criterion, \n",
    "                                   decoder_mode=decoder_mode,\n",
    "                                   vocab=vocab # remove later\n",
    "                                   )\n",
    "            epoch_loss += loss\n",
    "            print_epoch_loss += loss\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_loss /= total_iters # get average epoch loss\n",
    "        if verbose: \n",
    "            one_epoch_time_sec = end_epoch_time - start_epoch_time\n",
    "            remaining_epochs = n_epochs - epoch - 1\n",
    "            remaining_time = one_epoch_time_sec * remaining_epochs\n",
    "            remaining_time_hours = remaining_time //3600\n",
    "            remaining_time_mins = remaining_time % 3600 // 60\n",
    "            msg = f\"Average epoch loss: {epoch_loss:.3f}\\n\"\\\n",
    "                  f\"This epoch took {one_epoch_time_sec / 60} mins. Time remaining: {remaining_time_hours} hrs {remaining_time_mins} mins.\"\n",
    "            log += msg + \"\\n\"\n",
    "            print(msg)\n",
    "\n",
    "        epoch_losses[epoch]=epoch_loss\n",
    "        if use_scheduler:\n",
    "            enc_lr_scheduler.step()\n",
    "            dec_lr_scheduler.step()\n",
    "\n",
    "        if evaluate:\n",
    "            ## get validation loss\n",
    "            val_loss = get_validation_loss(encoder, decoder, dev_ds_val_loss, vocab, batch_size=batch_size,\n",
    "                                           decoder_mode=decoder_mode)\n",
    "            val_epoch_losses[epoch] = val_loss\n",
    "            \n",
    "            if verbose:\n",
    "                msg = f\"validation loss: {val_loss}\"\n",
    "                log += msg + \"\\n\"\n",
    "                print(msg)\n",
    "\n",
    "            ## get validation metrics\n",
    "            all_decoder_outs, all_gt_recipes, _ = eval(encoder, decoder, dev_ds_val_met, vocab,\n",
    "                                                    batch_size=batch_size, max_recipe_len=MAX_RECIPE_LEN,\n",
    "                                                    decoder_mode=decoder_mode)\n",
    "            bleu = calc_bleu(all_gt_recipes, all_decoder_outs)\n",
    "            meteor = calc_meteor(all_gt_recipes, all_decoder_outs, split_gt=False)\n",
    "\n",
    "            if verbose:\n",
    "                msg = f\"BLEU score: {bleu}, METEOR score: {meteor}\"\n",
    "                log += msg + \"\\n\"\n",
    "                print(msg)\n",
    "            if bleu > highest_bleu:\n",
    "                highest_bleu = bleu\n",
    "                if bleu > min_bleu_to_save:\n",
    "                    save_model(encoder, decoder, f\"{identifier}_ep_{epoch}\")\n",
    "            \n",
    "            # set back to train mode because in eval they are set to eval mode\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "\n",
    "\n",
    "    return epoch_losses, val_epoch_losses, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Baseline 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Base Encoder-Decoder Sequence-to-Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the following two functions are for Extension 1 but are placed here so that we can reuse\n",
    "# NOTE: this encoder and decoder class\n",
    "\n",
    "def create_pretrained_embeddings(pretrained_embedding_dict, input_size, embedding_size, vocab, verbose=True):\n",
    "    \"\"\"\n",
    "    NOTE: input_size is typically len(vocab) although in decoder you don't need to generate\n",
    "    unknown and pad.\n",
    "    \"\"\"\n",
    "    emb = torch.randn([input_size, embedding_size])\n",
    "\n",
    "    vocab_idxs_in_pretrained = []\n",
    "    vocab_words = list(vocab._word2index.keys())\n",
    "    for i in tqdm(range(input_size)):\n",
    "        word = vocab_words[i]\n",
    "        if word in pretrained_embedding_dict:\n",
    "            vocab_idxs_in_pretrained.append(i)\n",
    "            emb[i] = pretrained_embedding_dict[word]\n",
    "    \n",
    "    if verbose: \n",
    "        print(f\"{len(vocab_idxs_in_pretrained)}/{input_size} ({len(vocab_idxs_in_pretrained)/input_size:.3f}%) words have pretrained embeddings\")\n",
    "\n",
    "    return emb, vocab_idxs_in_pretrained\n",
    "\n",
    "def create_embeddings(input_size, embedding_size, pretrained_embedding_dict, vocab):\n",
    "    if pretrained_embedding_dict is None:\n",
    "        return nn.Embedding(input_size, embedding_size), None\n",
    "    else:\n",
    "        assert vocab is not None\n",
    "        embeddings_w_pretrained, vocab_idxs_in_pretrained = create_pretrained_embeddings(\n",
    "            pretrained_embedding_dict, input_size, embedding_size, vocab\n",
    "        )\n",
    "        # ! For now not freezing embeddings because ~40% don't exist in pretrained embeddings\n",
    "        # plus allows for finetuning\n",
    "        return nn.Embedding.from_pretrained(embeddings_w_pretrained, freeze=False), vocab_idxs_in_pretrained\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 embedding_size,\n",
    "                 hidden_size,\n",
    "                 padding_value,\n",
    "                 pretrained_embedding_dict=None,\n",
    "                 vocab=None,\n",
    "                 num_lstm_layers=1\n",
    "                 ):\n",
    "        \"\"\"Encoder LSTM to encode input sequence.\n",
    "\n",
    "        input_size (int): size of vocabulary\n",
    "        hidden_size (int): size of hidden dimension, referred to as H\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding, self.pretrained_emb_idxs = create_embeddings(input_size, embedding_size, pretrained_embedding_dict, vocab)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True, num_layers=num_lstm_layers)\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def update_embedding_grad(self, grads):\n",
    "        if not hasattr(self, \"pretrained_emb_idxs\"):\n",
    "            return\n",
    "        \n",
    "        grads[self.pretrained_emb_idxs] = 0 # zero-out gradients for pretrained embeddings\n",
    "\n",
    "    def forward(self, ingredients, ing_lens):\n",
    "        \"\"\"Embed ingredients and feed through LSTM. \n",
    "        Batch process all words in sequence at once for efficiency rather than one word one batch at a time.\n",
    "\n",
    "        Args:\n",
    "            ingredients (torch.Tensor): padded ingredients of shape [N, L], where N=batch size and L=longest sequence length in batch\n",
    "        \"\"\"\n",
    "        ## embed ingredients\n",
    "        ingredients_embed = self.embedding(ingredients) # [N, L, E]\n",
    "\n",
    "        ## pack padded ingredients tensor before feeding through LSTM (this allows the lstm to optimize operations, ignoring padding)\n",
    "        ingredients_packed = pack(ingredients_embed, ing_lens)\n",
    "\n",
    "        ## feed through LSTM\n",
    "        # by default, initial hidden state and initial cell state are zeros\n",
    "        # output: PackedSequence containing hidden state for each token in sequence\n",
    "        # final hidden state: Tensor [num_layers=1, N, H] NOTE: this is the last non-padded hidden state for each input sequence\n",
    "        # c_final: last cell state Tensor [num_layers=1, N, H]\n",
    "        output, (h_final, c_final) = self.lstm(ingredients_packed)\n",
    "\n",
    "        ## unpack PackedSequence to get back our padded tensor\n",
    "        # output_padded: padded output tensor which masks out encoder outputs for padding to 0; shape [N, L, H] NOTE: output_padded[:, -1] != h_final because of padding\n",
    "        # output_lens: unpadded sequence lengths; tensor of shape [N]\n",
    "        output_padded, output_lens = unpack(output, padding_val=self.padding_value)\n",
    "\n",
    "        return output_padded, output_lens, h_final, c_final\n",
    "    \n",
    "#! IMPORTANT: MAKE SURE DECODER'S OUTPUT SIZE IS VOCAB SIZE - 1\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 pretrained_embedding_dict=None,\n",
    "                 vocab=None,\n",
    "                 ):\n",
    "        \"\"\"Decoder to generate recipes based on encoder output (hidden state(s)).\n",
    "\n",
    "        Args:\n",
    "            hidden_size (int): size of hidden dimension\n",
    "            output_size (int): size of target language vocabulary - 1 (doesn't need to encode padding), |Vocab| - 1\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding, self.pretrained_emb_idxs = create_embeddings(output_size, embedding_size, pretrained_embedding_dict, vocab)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=False)\n",
    "        self.nonlinear_activation = nn.Tanh()\n",
    "        self.out_fc = nn.Linear(hidden_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def update_embedding_grad(self, grads):\n",
    "        if not hasattr(self, \"pretrained_emb_idxs\"):\n",
    "            return\n",
    "        \n",
    "        grads[self.pretrained_emb_idxs] = 0 # zero-out gradients for pretrained embeddings\n",
    "\n",
    "    def forward(self, inp, hidden, cell):\n",
    "        \"\"\"Decode one word at a time. Batch processed.\n",
    "\n",
    "        Args:\n",
    "            inp (torch.Tensor): start token or previous generation (non teacher-forcing) or \n",
    "                                previous ground truth token (teacher-forcing);\n",
    "                                shape [N]\n",
    "            hidden (torch.Tensor): encoder/decoder last hidden state; shape [1, N, H]\n",
    "            cell (torch.Tensor): encoder/decoder last hidden state; shape [1, N, H]\n",
    "        \"\"\"\n",
    "\n",
    "        inp_embedded = self.embedding(inp)[None] # [L=1, N, E]\n",
    "\n",
    "        ## apply non-linear activation\n",
    "        inp_embedded = self.nonlinear_activation(inp_embedded)\n",
    "        \n",
    "        ## feed embedded input and hidden state through LSTM\n",
    "        # out: output features; shape [L=1, N, H]\n",
    "        # h_final: final updated hidden state; shape [num_layers=1, N, H]\n",
    "        # c_final: last cell state Tensor [num_layers=1, N, H]\n",
    "        out, (h_final, c_final) = self.lstm(inp_embedded, (hidden, cell))\n",
    "\n",
    "        ## linear projection\n",
    "        out = self.out_fc(out[0]) # [N, H] -> [N, |Vocab|]\n",
    "\n",
    "        ## log softmax to get log probability distribution over vocabulary words\n",
    "        out = self.logsoftmax(out) # [N, |Vocab|]\n",
    "\n",
    "        return out, h_final, c_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=300\n",
    "encoder = EncoderRNN(vocab.n_unique_words, embedding_size=embedding_size, hidden_size=HIDDEN_SIZE, padding_value=vocab.word2index(PAD_WORD)).to(DEVICE)\n",
    "# in the training script, decoder is always fed a non-end token and thus never needs to generate padding\n",
    "# also it should never generate \"<UNKNOWN>\"\n",
    "decoder = DecoderRNN(embedding_size=embedding_size,hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30, enc lr scheduler: [0.001], dec lr scheduler: [0.001]\n",
      "(Epoch 0, iter 50/787) Average loss so far: 7.144\n",
      "(Epoch 0, iter 100/787) Average loss so far: 5.967\n",
      "(Epoch 0, iter 150/787) Average loss so far: 5.730\n",
      "(Epoch 0, iter 200/787) Average loss so far: 5.470\n",
      "(Epoch 0, iter 250/787) Average loss so far: 5.212\n",
      "(Epoch 0, iter 300/787) Average loss so far: 5.019\n",
      "(Epoch 0, iter 350/787) Average loss so far: 4.865\n",
      "(Epoch 0, iter 400/787) Average loss so far: 4.737\n",
      "(Epoch 0, iter 450/787) Average loss so far: 4.632\n",
      "(Epoch 0, iter 500/787) Average loss so far: 4.540\n",
      "(Epoch 0, iter 550/787) Average loss so far: 4.449\n",
      "(Epoch 0, iter 600/787) Average loss so far: 4.382\n",
      "(Epoch 0, iter 650/787) Average loss so far: 4.317\n",
      "(Epoch 0, iter 700/787) Average loss so far: 4.246\n",
      "(Epoch 0, iter 750/787) Average loss so far: 4.207\n",
      "Average epoch loss: 4.956\n",
      "This epoch took 5.9502798040707905 mins. Time remaining: 2.0 hrs 52.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 4.188371658325195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.02s/it]\n",
      "100%|██████████| 793/793 [00:09<00:00, 87.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0040273883646875595, METEOR score: 0.09091902403865486\n",
      "Starting epoch 2/30, enc lr scheduler: [0.0009972883382072953], dec lr scheduler: [0.0009972883382072953]\n",
      "(Epoch 1, iter 50/787) Average loss so far: 4.108\n",
      "(Epoch 1, iter 100/787) Average loss so far: 4.071\n",
      "(Epoch 1, iter 150/787) Average loss so far: 4.044\n",
      "(Epoch 1, iter 200/787) Average loss so far: 4.004\n",
      "(Epoch 1, iter 250/787) Average loss so far: 3.953\n",
      "(Epoch 1, iter 300/787) Average loss so far: 3.925\n",
      "(Epoch 1, iter 350/787) Average loss so far: 3.904\n",
      "(Epoch 1, iter 400/787) Average loss so far: 3.880\n",
      "(Epoch 1, iter 450/787) Average loss so far: 3.846\n",
      "(Epoch 1, iter 500/787) Average loss so far: 3.816\n",
      "(Epoch 1, iter 550/787) Average loss so far: 3.792\n",
      "(Epoch 1, iter 600/787) Average loss so far: 3.775\n",
      "(Epoch 1, iter 650/787) Average loss so far: 3.753\n",
      "(Epoch 1, iter 700/787) Average loss so far: 3.747\n",
      "(Epoch 1, iter 750/787) Average loss so far: 3.701\n",
      "Average epoch loss: 3.878\n",
      "This epoch took 5.9652024269104 mins. Time remaining: 2.0 hrs 47.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.762834276471819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.76it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 253.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.014792012153973902, METEOR score: 0.17129374579676301\n",
      "Starting epoch 3/30, enc lr scheduler: [0.0009891830623632338], dec lr scheduler: [0.0009891830623632338]\n",
      "(Epoch 2, iter 50/787) Average loss so far: 3.655\n",
      "(Epoch 2, iter 100/787) Average loss so far: 3.650\n",
      "(Epoch 2, iter 150/787) Average loss so far: 3.604\n",
      "(Epoch 2, iter 200/787) Average loss so far: 3.606\n",
      "(Epoch 2, iter 250/787) Average loss so far: 3.587\n",
      "(Epoch 2, iter 300/787) Average loss so far: 3.586\n",
      "(Epoch 2, iter 350/787) Average loss so far: 3.569\n",
      "(Epoch 2, iter 400/787) Average loss so far: 3.535\n",
      "(Epoch 2, iter 450/787) Average loss so far: 3.553\n",
      "(Epoch 2, iter 500/787) Average loss so far: 3.543\n",
      "(Epoch 2, iter 550/787) Average loss so far: 3.522\n",
      "(Epoch 2, iter 600/787) Average loss so far: 3.509\n",
      "(Epoch 2, iter 650/787) Average loss so far: 3.499\n",
      "(Epoch 2, iter 700/787) Average loss so far: 3.479\n",
      "(Epoch 2, iter 750/787) Average loss so far: 3.466\n",
      "Average epoch loss: 3.553\n",
      "This epoch took 5.964460162321727 mins. Time remaining: 2.0 hrs 41.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.558991943086897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.70it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 208.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.013738925056068545, METEOR score: 0.1597429689849473\n",
      "Starting epoch 4/30, enc lr scheduler: [0.0009757729755661011], dec lr scheduler: [0.0009757729755661011]\n",
      "(Epoch 3, iter 50/787) Average loss so far: 3.436\n",
      "(Epoch 3, iter 100/787) Average loss so far: 3.407\n",
      "(Epoch 3, iter 150/787) Average loss so far: 3.395\n",
      "(Epoch 3, iter 200/787) Average loss so far: 3.389\n",
      "(Epoch 3, iter 250/787) Average loss so far: 3.381\n",
      "(Epoch 3, iter 300/787) Average loss so far: 3.382\n",
      "(Epoch 3, iter 350/787) Average loss so far: 3.371\n",
      "(Epoch 3, iter 400/787) Average loss so far: 3.364\n",
      "(Epoch 3, iter 450/787) Average loss so far: 3.346\n",
      "(Epoch 3, iter 500/787) Average loss so far: 3.333\n",
      "(Epoch 3, iter 550/787) Average loss so far: 3.330\n",
      "(Epoch 3, iter 600/787) Average loss so far: 3.347\n",
      "(Epoch 3, iter 650/787) Average loss so far: 3.328\n",
      "(Epoch 3, iter 700/787) Average loss so far: 3.305\n",
      "(Epoch 3, iter 750/787) Average loss so far: 3.300\n",
      "Average epoch loss: 3.359\n",
      "This epoch took 5.93084941705068 mins. Time remaining: 2.0 hrs 34.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.4334449768066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.01it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 284.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.01996062579533466, METEOR score: 0.17012901848915718\n",
      "Starting epoch 5/30, enc lr scheduler: [0.0009572050015330874], dec lr scheduler: [0.0009572050015330874]\n",
      "(Epoch 4, iter 50/787) Average loss so far: 3.272\n",
      "(Epoch 4, iter 100/787) Average loss so far: 3.258\n",
      "(Epoch 4, iter 150/787) Average loss so far: 3.250\n",
      "(Epoch 4, iter 200/787) Average loss so far: 3.243\n",
      "(Epoch 4, iter 250/787) Average loss so far: 3.239\n",
      "(Epoch 4, iter 300/787) Average loss so far: 3.247\n",
      "(Epoch 4, iter 350/787) Average loss so far: 3.219\n",
      "(Epoch 4, iter 400/787) Average loss so far: 3.228\n",
      "(Epoch 4, iter 450/787) Average loss so far: 3.223\n",
      "(Epoch 4, iter 500/787) Average loss so far: 3.212\n",
      "(Epoch 4, iter 550/787) Average loss so far: 3.211\n",
      "(Epoch 4, iter 600/787) Average loss so far: 3.203\n",
      "(Epoch 4, iter 650/787) Average loss so far: 3.205\n",
      "(Epoch 4, iter 700/787) Average loss so far: 3.205\n",
      "(Epoch 4, iter 750/787) Average loss so far: 3.193\n",
      "Average epoch loss: 3.227\n",
      "This epoch took 5.959438494841257 mins. Time remaining: 2.0 hrs 28.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.358621767589024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.36it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 380.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.027415656741189266, METEOR score: 0.1823641169217577\n",
      "Starting epoch 6/30, enc lr scheduler: [0.0009336825748732973], dec lr scheduler: [0.0009336825748732973]\n",
      "(Epoch 5, iter 50/787) Average loss so far: 3.157\n",
      "(Epoch 5, iter 100/787) Average loss so far: 3.144\n",
      "(Epoch 5, iter 150/787) Average loss so far: 3.140\n",
      "(Epoch 5, iter 200/787) Average loss so far: 3.148\n",
      "(Epoch 5, iter 250/787) Average loss so far: 3.115\n",
      "(Epoch 5, iter 300/787) Average loss so far: 3.129\n",
      "(Epoch 5, iter 350/787) Average loss so far: 3.146\n",
      "(Epoch 5, iter 400/787) Average loss so far: 3.139\n",
      "(Epoch 5, iter 450/787) Average loss so far: 3.141\n",
      "(Epoch 5, iter 500/787) Average loss so far: 3.121\n",
      "(Epoch 5, iter 550/787) Average loss so far: 3.120\n",
      "(Epoch 5, iter 600/787) Average loss so far: 3.127\n",
      "(Epoch 5, iter 650/787) Average loss so far: 3.111\n",
      "(Epoch 5, iter 700/787) Average loss so far: 3.113\n",
      "(Epoch 5, iter 750/787) Average loss so far: 3.111\n",
      "Average epoch loss: 3.129\n",
      "This epoch took 5.956571054458618 mins. Time remaining: 2.0 hrs 22.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.3043336187090193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.46it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 401.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.029595775761603153, METEOR score: 0.1858161071099046\n",
      "Starting epoch 7/30, enc lr scheduler: [0.0009054634122155991], dec lr scheduler: [0.0009054634122155991]\n",
      "(Epoch 6, iter 50/787) Average loss so far: 3.067\n",
      "(Epoch 6, iter 100/787) Average loss so far: 3.064\n",
      "(Epoch 6, iter 150/787) Average loss so far: 3.049\n",
      "(Epoch 6, iter 200/787) Average loss so far: 3.051\n",
      "(Epoch 6, iter 250/787) Average loss so far: 3.078\n",
      "(Epoch 6, iter 300/787) Average loss so far: 3.066\n",
      "(Epoch 6, iter 350/787) Average loss so far: 3.067\n",
      "(Epoch 6, iter 400/787) Average loss so far: 3.046\n",
      "(Epoch 6, iter 450/787) Average loss so far: 3.054\n",
      "(Epoch 6, iter 500/787) Average loss so far: 3.038\n",
      "(Epoch 6, iter 550/787) Average loss so far: 3.039\n",
      "(Epoch 6, iter 600/787) Average loss so far: 3.050\n",
      "(Epoch 6, iter 650/787) Average loss so far: 3.060\n",
      "(Epoch 6, iter 700/787) Average loss so far: 3.054\n",
      "(Epoch 6, iter 750/787) Average loss so far: 3.032\n",
      "Average epoch loss: 3.054\n",
      "This epoch took 5.976559368769328 mins. Time remaining: 2.0 hrs 17.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.268099410193307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.20it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 323.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.024870246390936355, METEOR score: 0.1775517379842907\n",
      "Starting epoch 8/30, enc lr scheduler: [0.0008728566886113102], dec lr scheduler: [0.0008728566886113102]\n",
      "(Epoch 7, iter 50/787) Average loss so far: 3.002\n",
      "(Epoch 7, iter 100/787) Average loss so far: 2.993\n",
      "(Epoch 7, iter 150/787) Average loss so far: 2.997\n",
      "(Epoch 7, iter 200/787) Average loss so far: 2.996\n",
      "(Epoch 7, iter 250/787) Average loss so far: 2.998\n",
      "(Epoch 7, iter 300/787) Average loss so far: 2.999\n",
      "(Epoch 7, iter 350/787) Average loss so far: 2.998\n",
      "(Epoch 7, iter 400/787) Average loss so far: 2.988\n",
      "(Epoch 7, iter 450/787) Average loss so far: 2.995\n",
      "(Epoch 7, iter 500/787) Average loss so far: 2.992\n",
      "(Epoch 7, iter 550/787) Average loss so far: 2.994\n",
      "(Epoch 7, iter 600/787) Average loss so far: 3.009\n",
      "(Epoch 7, iter 650/787) Average loss so far: 2.974\n",
      "(Epoch 7, iter 700/787) Average loss so far: 2.990\n",
      "(Epoch 7, iter 750/787) Average loss so far: 2.992\n",
      "Average epoch loss: 2.994\n",
      "This epoch took 5.975848956902822 mins. Time remaining: 2.0 hrs 11.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2407847813197543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.18it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 335.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.024665420986828435, METEOR score: 0.18374070954399746\n",
      "Starting epoch 9/30, enc lr scheduler: [0.0008362196501476349], dec lr scheduler: [0.0008362196501476349]\n",
      "(Epoch 8, iter 50/787) Average loss so far: 2.956\n",
      "(Epoch 8, iter 100/787) Average loss so far: 2.948\n",
      "(Epoch 8, iter 150/787) Average loss so far: 2.961\n",
      "(Epoch 8, iter 200/787) Average loss so far: 2.941\n",
      "(Epoch 8, iter 250/787) Average loss so far: 2.955\n",
      "(Epoch 8, iter 300/787) Average loss so far: 2.945\n",
      "(Epoch 8, iter 350/787) Average loss so far: 2.959\n",
      "(Epoch 8, iter 400/787) Average loss so far: 2.946\n",
      "(Epoch 8, iter 450/787) Average loss so far: 2.938\n",
      "(Epoch 8, iter 500/787) Average loss so far: 2.930\n",
      "(Epoch 8, iter 550/787) Average loss so far: 2.946\n",
      "(Epoch 8, iter 600/787) Average loss so far: 2.937\n",
      "(Epoch 8, iter 650/787) Average loss so far: 2.956\n",
      "(Epoch 8, iter 700/787) Average loss so far: 2.938\n",
      "(Epoch 8, iter 750/787) Average loss so far: 2.926\n",
      "Average epoch loss: 2.945\n",
      "This epoch took 5.916466542085012 mins. Time remaining: 2.0 hrs 4.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2253596442086354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.75it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 526.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0382104543038602, METEOR score: 0.19038100657935783\n",
      "Starting epoch 10/30, enc lr scheduler: [0.0007959536998847742], dec lr scheduler: [0.0007959536998847742]\n",
      "(Epoch 9, iter 50/787) Average loss so far: 2.894\n",
      "(Epoch 9, iter 100/787) Average loss so far: 2.909\n",
      "(Epoch 9, iter 150/787) Average loss so far: 2.912\n",
      "(Epoch 9, iter 200/787) Average loss so far: 2.911\n",
      "(Epoch 9, iter 250/787) Average loss so far: 2.901\n",
      "(Epoch 9, iter 300/787) Average loss so far: 2.888\n",
      "(Epoch 9, iter 350/787) Average loss so far: 2.905\n",
      "(Epoch 9, iter 400/787) Average loss so far: 2.903\n",
      "(Epoch 9, iter 450/787) Average loss so far: 2.915\n",
      "(Epoch 9, iter 500/787) Average loss so far: 2.916\n",
      "(Epoch 9, iter 550/787) Average loss so far: 2.901\n",
      "(Epoch 9, iter 600/787) Average loss so far: 2.902\n",
      "(Epoch 9, iter 650/787) Average loss so far: 2.888\n",
      "(Epoch 9, iter 700/787) Average loss so far: 2.900\n",
      "(Epoch 9, iter 750/787) Average loss so far: 2.907\n",
      "Average epoch loss: 2.904\n",
      "This epoch took 5.962946979204814 mins. Time remaining: 1.0 hrs 59.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2130907603672574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.67it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 569.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04252454242984992, METEOR score: 0.19856427989507028\n",
      "Starting epoch 11/30, enc lr scheduler: [0.0007525], dec lr scheduler: [0.0007525]\n",
      "(Epoch 10, iter 50/787) Average loss so far: 2.861\n",
      "(Epoch 10, iter 100/787) Average loss so far: 2.868\n",
      "(Epoch 10, iter 150/787) Average loss so far: 2.872\n",
      "(Epoch 10, iter 200/787) Average loss so far: 2.868\n",
      "(Epoch 10, iter 250/787) Average loss so far: 2.862\n",
      "(Epoch 10, iter 300/787) Average loss so far: 2.882\n",
      "(Epoch 10, iter 350/787) Average loss so far: 2.873\n",
      "(Epoch 10, iter 400/787) Average loss so far: 2.874\n",
      "(Epoch 10, iter 450/787) Average loss so far: 2.877\n",
      "(Epoch 10, iter 500/787) Average loss so far: 2.884\n",
      "(Epoch 10, iter 550/787) Average loss so far: 2.858\n",
      "(Epoch 10, iter 600/787) Average loss so far: 2.864\n",
      "(Epoch 10, iter 650/787) Average loss so far: 2.873\n",
      "(Epoch 10, iter 700/787) Average loss so far: 2.876\n",
      "(Epoch 10, iter 750/787) Average loss so far: 2.870\n",
      "Average epoch loss: 2.870\n",
      "This epoch took 5.9633493542671205 mins. Time remaining: 1.0 hrs 53.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.20478309903826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.00it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 693.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04374173844572283, METEOR score: 0.19134044687967858\n",
      "Starting epoch 12/30, enc lr scheduler: [0.0007063346383225212], dec lr scheduler: [0.0007063346383225212]\n",
      "(Epoch 11, iter 50/787) Average loss so far: 2.849\n",
      "(Epoch 11, iter 100/787) Average loss so far: 2.842\n",
      "(Epoch 11, iter 150/787) Average loss so far: 2.845\n",
      "(Epoch 11, iter 200/787) Average loss so far: 2.840\n",
      "(Epoch 11, iter 250/787) Average loss so far: 2.825\n",
      "(Epoch 11, iter 300/787) Average loss so far: 2.858\n",
      "(Epoch 11, iter 350/787) Average loss so far: 2.837\n",
      "(Epoch 11, iter 400/787) Average loss so far: 2.829\n",
      "(Epoch 11, iter 450/787) Average loss so far: 2.836\n",
      "(Epoch 11, iter 500/787) Average loss so far: 2.840\n",
      "(Epoch 11, iter 550/787) Average loss so far: 2.844\n",
      "(Epoch 11, iter 600/787) Average loss so far: 2.850\n",
      "(Epoch 11, iter 650/787) Average loss so far: 2.833\n",
      "(Epoch 11, iter 700/787) Average loss so far: 2.848\n",
      "(Epoch 11, iter 750/787) Average loss so far: 2.844\n",
      "Average epoch loss: 2.842\n",
      "This epoch took 5.965496921539307 mins. Time remaining: 1.0 hrs 47.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.197985989706857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 654.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04589529895972353, METEOR score: 0.1966180841918361\n",
      "Starting epoch 13/30, enc lr scheduler: [0.000657963412215599], dec lr scheduler: [0.000657963412215599]\n",
      "(Epoch 12, iter 50/787) Average loss so far: 2.813\n",
      "(Epoch 12, iter 100/787) Average loss so far: 2.823\n",
      "(Epoch 12, iter 150/787) Average loss so far: 2.817\n",
      "(Epoch 12, iter 200/787) Average loss so far: 2.818\n",
      "(Epoch 12, iter 250/787) Average loss so far: 2.804\n",
      "(Epoch 12, iter 300/787) Average loss so far: 2.821\n",
      "(Epoch 12, iter 350/787) Average loss so far: 2.820\n",
      "(Epoch 12, iter 400/787) Average loss so far: 2.824\n",
      "(Epoch 12, iter 450/787) Average loss so far: 2.837\n",
      "(Epoch 12, iter 500/787) Average loss so far: 2.799\n",
      "(Epoch 12, iter 550/787) Average loss so far: 2.822\n",
      "(Epoch 12, iter 600/787) Average loss so far: 2.821\n",
      "(Epoch 12, iter 650/787) Average loss so far: 2.810\n",
      "(Epoch 12, iter 700/787) Average loss so far: 2.827\n",
      "(Epoch 12, iter 750/787) Average loss so far: 2.812\n",
      "Average epoch loss: 2.817\n",
      "This epoch took 5.939353549480439 mins. Time remaining: 1.0 hrs 40.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1950793266296387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.84it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 566.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.042610497365320306, METEOR score: 0.19640161197240455\n",
      "Starting epoch 14/30, enc lr scheduler: [0.0006079162869547909], dec lr scheduler: [0.0006079162869547909]\n",
      "(Epoch 13, iter 50/787) Average loss so far: 2.796\n",
      "(Epoch 13, iter 100/787) Average loss so far: 2.800\n",
      "(Epoch 13, iter 150/787) Average loss so far: 2.797\n",
      "(Epoch 13, iter 200/787) Average loss so far: 2.792\n",
      "(Epoch 13, iter 250/787) Average loss so far: 2.801\n",
      "(Epoch 13, iter 300/787) Average loss so far: 2.789\n",
      "(Epoch 13, iter 350/787) Average loss so far: 2.798\n",
      "(Epoch 13, iter 400/787) Average loss so far: 2.793\n",
      "(Epoch 13, iter 450/787) Average loss so far: 2.792\n",
      "(Epoch 13, iter 500/787) Average loss so far: 2.802\n",
      "(Epoch 13, iter 550/787) Average loss so far: 2.808\n",
      "(Epoch 13, iter 600/787) Average loss so far: 2.802\n",
      "(Epoch 13, iter 650/787) Average loss so far: 2.785\n",
      "(Epoch 13, iter 700/787) Average loss so far: 2.791\n",
      "(Epoch 13, iter 750/787) Average loss so far: 2.772\n",
      "Average epoch loss: 2.795\n",
      "This epoch took 5.942754459381104 mins. Time remaining: 1.0 hrs 35.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.190805230821882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.54it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 774.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04117386932250176, METEOR score: 0.1918381125873577\n",
      "Starting epoch 15/30, enc lr scheduler: [0.0005567415893174886], dec lr scheduler: [0.0005567415893174886]\n",
      "(Epoch 14, iter 50/787) Average loss so far: 2.771\n",
      "(Epoch 14, iter 100/787) Average loss so far: 2.772\n",
      "(Epoch 14, iter 150/787) Average loss so far: 2.768\n",
      "(Epoch 14, iter 200/787) Average loss so far: 2.766\n",
      "(Epoch 14, iter 250/787) Average loss so far: 2.776\n",
      "(Epoch 14, iter 300/787) Average loss so far: 2.773\n",
      "(Epoch 14, iter 350/787) Average loss so far: 2.768\n",
      "(Epoch 14, iter 400/787) Average loss so far: 2.789\n",
      "(Epoch 14, iter 450/787) Average loss so far: 2.763\n",
      "(Epoch 14, iter 500/787) Average loss so far: 2.781\n",
      "(Epoch 14, iter 550/787) Average loss so far: 2.784\n",
      "(Epoch 14, iter 600/787) Average loss so far: 2.787\n",
      "(Epoch 14, iter 650/787) Average loss so far: 2.773\n",
      "(Epoch 14, iter 700/787) Average loss so far: 2.782\n",
      "(Epoch 14, iter 750/787) Average loss so far: 2.792\n",
      "Average epoch loss: 2.776\n",
      "This epoch took 5.934814552466075 mins. Time remaining: 1.0 hrs 29.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.191071476255144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.97it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 619.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.045987255785282295, METEOR score: 0.19803943527851992\n",
      "Starting epoch 16/30, enc lr scheduler: [0.0005050000000000002], dec lr scheduler: [0.0005050000000000002]\n",
      "(Epoch 15, iter 50/787) Average loss so far: 2.756\n",
      "(Epoch 15, iter 100/787) Average loss so far: 2.755\n",
      "(Epoch 15, iter 150/787) Average loss so far: 2.756\n",
      "(Epoch 15, iter 200/787) Average loss so far: 2.764\n",
      "(Epoch 15, iter 250/787) Average loss so far: 2.748\n",
      "(Epoch 15, iter 300/787) Average loss so far: 2.737\n",
      "(Epoch 15, iter 350/787) Average loss so far: 2.749\n",
      "(Epoch 15, iter 400/787) Average loss so far: 2.763\n",
      "(Epoch 15, iter 450/787) Average loss so far: 2.753\n",
      "(Epoch 15, iter 500/787) Average loss so far: 2.776\n",
      "(Epoch 15, iter 550/787) Average loss so far: 2.766\n",
      "(Epoch 15, iter 600/787) Average loss so far: 2.768\n",
      "(Epoch 15, iter 650/787) Average loss so far: 2.773\n",
      "(Epoch 15, iter 700/787) Average loss so far: 2.767\n",
      "(Epoch 15, iter 750/787) Average loss so far: 2.761\n",
      "Average epoch loss: 2.760\n",
      "This epoch took 5.958962686856588 mins. Time remaining: 1.0 hrs 23.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1885389941079274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.75it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 763.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.039472464139260074, METEOR score: 0.1900444808031801\n",
      "Starting epoch 17/30, enc lr scheduler: [0.0004532584106825117], dec lr scheduler: [0.0004532584106825117]\n",
      "(Epoch 16, iter 50/787) Average loss so far: 2.728\n",
      "(Epoch 16, iter 100/787) Average loss so far: 2.737\n",
      "(Epoch 16, iter 150/787) Average loss so far: 2.737\n",
      "(Epoch 16, iter 200/787) Average loss so far: 2.738\n",
      "(Epoch 16, iter 250/787) Average loss so far: 2.746\n",
      "(Epoch 16, iter 300/787) Average loss so far: 2.736\n",
      "(Epoch 16, iter 350/787) Average loss so far: 2.753\n",
      "(Epoch 16, iter 400/787) Average loss so far: 2.752\n",
      "(Epoch 16, iter 450/787) Average loss so far: 2.745\n",
      "(Epoch 16, iter 500/787) Average loss so far: 2.738\n",
      "(Epoch 16, iter 550/787) Average loss so far: 2.760\n",
      "(Epoch 16, iter 600/787) Average loss so far: 2.751\n",
      "(Epoch 16, iter 650/787) Average loss so far: 2.750\n",
      "(Epoch 16, iter 700/787) Average loss so far: 2.748\n",
      "(Epoch 16, iter 750/787) Average loss so far: 2.753\n",
      "Average epoch loss: 2.745\n",
      "This epoch took 6.020829896132152 mins. Time remaining: 1.0 hrs 18.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.190322296960013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.03it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 657.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04504238384476892, METEOR score: 0.19752496817224274\n",
      "Starting epoch 18/30, enc lr scheduler: [0.00040208371304520916], dec lr scheduler: [0.00040208371304520916]\n",
      "(Epoch 17, iter 50/787) Average loss so far: 2.726\n",
      "(Epoch 17, iter 100/787) Average loss so far: 2.726\n",
      "(Epoch 17, iter 150/787) Average loss so far: 2.718\n",
      "(Epoch 17, iter 200/787) Average loss so far: 2.724\n",
      "(Epoch 17, iter 250/787) Average loss so far: 2.715\n",
      "(Epoch 17, iter 300/787) Average loss so far: 2.739\n",
      "(Epoch 17, iter 350/787) Average loss so far: 2.729\n",
      "(Epoch 17, iter 400/787) Average loss so far: 2.737\n",
      "(Epoch 17, iter 450/787) Average loss so far: 2.733\n",
      "(Epoch 17, iter 500/787) Average loss so far: 2.740\n",
      "(Epoch 17, iter 550/787) Average loss so far: 2.755\n",
      "(Epoch 17, iter 600/787) Average loss so far: 2.744\n",
      "(Epoch 17, iter 650/787) Average loss so far: 2.728\n",
      "(Epoch 17, iter 700/787) Average loss so far: 2.723\n",
      "(Epoch 17, iter 750/787) Average loss so far: 2.736\n",
      "Average epoch loss: 2.732\n",
      "This epoch took 6.014154775937398 mins. Time remaining: 1.0 hrs 12.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1880320140293668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.22it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 660.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.045373700729723125, METEOR score: 0.19635808499055457\n",
      "Starting epoch 19/30, enc lr scheduler: [0.00035203658778440114], dec lr scheduler: [0.00035203658778440114]\n",
      "(Epoch 18, iter 50/787) Average loss so far: 2.717\n",
      "(Epoch 18, iter 100/787) Average loss so far: 2.697\n",
      "(Epoch 18, iter 150/787) Average loss so far: 2.725\n",
      "(Epoch 18, iter 200/787) Average loss so far: 2.716\n",
      "(Epoch 18, iter 250/787) Average loss so far: 2.707\n",
      "(Epoch 18, iter 300/787) Average loss so far: 2.734\n",
      "(Epoch 18, iter 350/787) Average loss so far: 2.719\n",
      "(Epoch 18, iter 400/787) Average loss so far: 2.715\n",
      "(Epoch 18, iter 450/787) Average loss so far: 2.727\n",
      "(Epoch 18, iter 500/787) Average loss so far: 2.713\n",
      "(Epoch 18, iter 550/787) Average loss so far: 2.742\n",
      "(Epoch 18, iter 600/787) Average loss so far: 2.717\n",
      "(Epoch 18, iter 650/787) Average loss so far: 2.716\n",
      "(Epoch 18, iter 700/787) Average loss so far: 2.738\n",
      "(Epoch 18, iter 750/787) Average loss so far: 2.728\n",
      "Average epoch loss: 2.721\n",
      "This epoch took 6.0332143902778625 mins. Time remaining: 1.0 hrs 6.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1870854582105363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.22it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 733.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04436411201089971, METEOR score: 0.19867751657974117\n",
      "Starting epoch 20/30, enc lr scheduler: [0.00030366536167747904], dec lr scheduler: [0.00030366536167747904]\n",
      "(Epoch 19, iter 50/787) Average loss so far: 2.706\n",
      "(Epoch 19, iter 100/787) Average loss so far: 2.711\n",
      "(Epoch 19, iter 150/787) Average loss so far: 2.708\n",
      "(Epoch 19, iter 200/787) Average loss so far: 2.707\n",
      "(Epoch 19, iter 250/787) Average loss so far: 2.707\n",
      "(Epoch 19, iter 300/787) Average loss so far: 2.711\n",
      "(Epoch 19, iter 350/787) Average loss so far: 2.696\n",
      "(Epoch 19, iter 400/787) Average loss so far: 2.702\n",
      "(Epoch 19, iter 450/787) Average loss so far: 2.721\n",
      "(Epoch 19, iter 500/787) Average loss so far: 2.712\n",
      "(Epoch 19, iter 550/787) Average loss so far: 2.713\n",
      "(Epoch 19, iter 600/787) Average loss so far: 2.713\n",
      "(Epoch 19, iter 650/787) Average loss so far: 2.717\n",
      "(Epoch 19, iter 700/787) Average loss so far: 2.725\n",
      "(Epoch 19, iter 750/787) Average loss so far: 2.714\n",
      "Average epoch loss: 2.711\n",
      "This epoch took 6.069462593396505 mins. Time remaining: 1.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1880082402910506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.81it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 632.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0472837279646999, METEOR score: 0.2002107631916008\n",
      "Starting epoch 21/30, enc lr scheduler: [0.00025750000000000013], dec lr scheduler: [0.00025750000000000013]\n",
      "(Epoch 20, iter 50/787) Average loss so far: 2.690\n",
      "(Epoch 20, iter 100/787) Average loss so far: 2.689\n",
      "(Epoch 20, iter 150/787) Average loss so far: 2.699\n",
      "(Epoch 20, iter 200/787) Average loss so far: 2.695\n",
      "(Epoch 20, iter 250/787) Average loss so far: 2.702\n",
      "(Epoch 20, iter 300/787) Average loss so far: 2.697\n",
      "(Epoch 20, iter 350/787) Average loss so far: 2.718\n",
      "(Epoch 20, iter 400/787) Average loss so far: 2.697\n",
      "(Epoch 20, iter 450/787) Average loss so far: 2.714\n",
      "(Epoch 20, iter 500/787) Average loss so far: 2.712\n",
      "(Epoch 20, iter 550/787) Average loss so far: 2.702\n",
      "(Epoch 20, iter 600/787) Average loss so far: 2.698\n",
      "(Epoch 20, iter 650/787) Average loss so far: 2.717\n",
      "(Epoch 20, iter 700/787) Average loss so far: 2.711\n",
      "(Epoch 20, iter 750/787) Average loss so far: 2.709\n",
      "Average epoch loss: 2.703\n",
      "This epoch took 6.04076402982076 mins. Time remaining: 0.0 hrs 54.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.188002722603934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.97it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 700.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.046293812487382985, METEOR score: 0.19752825008718805\n",
      "Starting epoch 22/30, enc lr scheduler: [0.00021404630011522585], dec lr scheduler: [0.00021404630011522585]\n",
      "(Epoch 21, iter 50/787) Average loss so far: 2.694\n",
      "(Epoch 21, iter 100/787) Average loss so far: 2.706\n",
      "(Epoch 21, iter 150/787) Average loss so far: 2.679\n",
      "(Epoch 21, iter 200/787) Average loss so far: 2.691\n",
      "(Epoch 21, iter 250/787) Average loss so far: 2.688\n",
      "(Epoch 21, iter 300/787) Average loss so far: 2.695\n",
      "(Epoch 21, iter 350/787) Average loss so far: 2.691\n",
      "(Epoch 21, iter 400/787) Average loss so far: 2.712\n",
      "(Epoch 21, iter 450/787) Average loss so far: 2.682\n",
      "(Epoch 21, iter 500/787) Average loss so far: 2.702\n",
      "(Epoch 21, iter 550/787) Average loss so far: 2.687\n",
      "(Epoch 21, iter 600/787) Average loss so far: 2.695\n",
      "(Epoch 21, iter 650/787) Average loss so far: 2.695\n",
      "(Epoch 21, iter 700/787) Average loss so far: 2.698\n",
      "(Epoch 21, iter 750/787) Average loss so far: 2.708\n",
      "Average epoch loss: 2.695\n",
      "This epoch took 6.00150508483251 mins. Time remaining: 0.0 hrs 48.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.190535000392369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.29it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 751.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04469983055676468, METEOR score: 0.19735370122639811\n",
      "Starting epoch 23/30, enc lr scheduler: [0.00017378034985236535], dec lr scheduler: [0.00017378034985236535]\n",
      "(Epoch 22, iter 50/787) Average loss so far: 2.677\n",
      "(Epoch 22, iter 100/787) Average loss so far: 2.690\n",
      "(Epoch 22, iter 150/787) Average loss so far: 2.684\n",
      "(Epoch 22, iter 200/787) Average loss so far: 2.692\n",
      "(Epoch 22, iter 250/787) Average loss so far: 2.683\n",
      "(Epoch 22, iter 300/787) Average loss so far: 2.682\n",
      "(Epoch 22, iter 350/787) Average loss so far: 2.693\n",
      "(Epoch 22, iter 400/787) Average loss so far: 2.699\n",
      "(Epoch 22, iter 450/787) Average loss so far: 2.694\n",
      "(Epoch 22, iter 500/787) Average loss so far: 2.678\n",
      "(Epoch 22, iter 550/787) Average loss so far: 2.692\n",
      "(Epoch 22, iter 600/787) Average loss so far: 2.682\n",
      "(Epoch 22, iter 650/787) Average loss so far: 2.681\n",
      "(Epoch 22, iter 700/787) Average loss so far: 2.692\n",
      "(Epoch 22, iter 750/787) Average loss so far: 2.701\n",
      "Average epoch loss: 2.689\n",
      "This epoch took 5.974960108598073 mins. Time remaining: 0.0 hrs 41.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1892076901027133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.18it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 695.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.044842831330928805, METEOR score: 0.19575345815276526\n",
      "Starting epoch 24/30, enc lr scheduler: [0.00013714331138868998], dec lr scheduler: [0.00013714331138868998]\n",
      "(Epoch 23, iter 50/787) Average loss so far: 2.671\n",
      "(Epoch 23, iter 100/787) Average loss so far: 2.682\n",
      "(Epoch 23, iter 150/787) Average loss so far: 2.683\n",
      "(Epoch 23, iter 200/787) Average loss so far: 2.668\n",
      "(Epoch 23, iter 250/787) Average loss so far: 2.684\n",
      "(Epoch 23, iter 300/787) Average loss so far: 2.681\n",
      "(Epoch 23, iter 350/787) Average loss so far: 2.674\n",
      "(Epoch 23, iter 400/787) Average loss so far: 2.688\n",
      "(Epoch 23, iter 450/787) Average loss so far: 2.690\n",
      "(Epoch 23, iter 500/787) Average loss so far: 2.687\n",
      "(Epoch 23, iter 550/787) Average loss so far: 2.682\n",
      "(Epoch 23, iter 600/787) Average loss so far: 2.701\n",
      "(Epoch 23, iter 650/787) Average loss so far: 2.692\n",
      "(Epoch 23, iter 700/787) Average loss so far: 2.691\n",
      "(Epoch 23, iter 750/787) Average loss so far: 2.677\n",
      "Average epoch loss: 2.683\n",
      "This epoch took 5.9614043712615965 mins. Time remaining: 0.0 hrs 35.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1896793161119734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.23it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 697.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04446433657061311, METEOR score: 0.19553098270527547\n",
      "Starting epoch 25/30, enc lr scheduler: [0.00010453658778440108], dec lr scheduler: [0.00010453658778440108]\n",
      "(Epoch 24, iter 50/787) Average loss so far: 2.673\n",
      "(Epoch 24, iter 100/787) Average loss so far: 2.677\n",
      "(Epoch 24, iter 150/787) Average loss so far: 2.681\n",
      "(Epoch 24, iter 200/787) Average loss so far: 2.669\n",
      "(Epoch 24, iter 250/787) Average loss so far: 2.675\n",
      "(Epoch 24, iter 300/787) Average loss so far: 2.675\n",
      "(Epoch 24, iter 350/787) Average loss so far: 2.677\n",
      "(Epoch 24, iter 400/787) Average loss so far: 2.678\n",
      "(Epoch 24, iter 450/787) Average loss so far: 2.683\n",
      "(Epoch 24, iter 500/787) Average loss so far: 2.677\n",
      "(Epoch 24, iter 550/787) Average loss so far: 2.681\n",
      "(Epoch 24, iter 600/787) Average loss so far: 2.674\n",
      "(Epoch 24, iter 650/787) Average loss so far: 2.688\n",
      "(Epoch 24, iter 700/787) Average loss so far: 2.680\n",
      "(Epoch 24, iter 750/787) Average loss so far: 2.682\n",
      "Average epoch loss: 2.679\n",
      "This epoch took 5.857432734966278 mins. Time remaining: 0.0 hrs 29.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1895811557769775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.10it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 672.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.047831302586897266, METEOR score: 0.1988243943422679\n",
      "Starting epoch 26/30, enc lr scheduler: [7.631742512670285e-05], dec lr scheduler: [7.631742512670285e-05]\n",
      "(Epoch 25, iter 50/787) Average loss so far: 2.664\n",
      "(Epoch 25, iter 100/787) Average loss so far: 2.655\n",
      "(Epoch 25, iter 150/787) Average loss so far: 2.672\n",
      "(Epoch 25, iter 200/787) Average loss so far: 2.664\n",
      "(Epoch 25, iter 250/787) Average loss so far: 2.686\n",
      "(Epoch 25, iter 300/787) Average loss so far: 2.691\n",
      "(Epoch 25, iter 350/787) Average loss so far: 2.671\n",
      "(Epoch 25, iter 400/787) Average loss so far: 2.693\n",
      "(Epoch 25, iter 450/787) Average loss so far: 2.666\n",
      "(Epoch 25, iter 500/787) Average loss so far: 2.676\n",
      "(Epoch 25, iter 550/787) Average loss so far: 2.679\n",
      "(Epoch 25, iter 600/787) Average loss so far: 2.676\n",
      "(Epoch 25, iter 650/787) Average loss so far: 2.688\n",
      "(Epoch 25, iter 700/787) Average loss so far: 2.677\n",
      "(Epoch 25, iter 750/787) Average loss so far: 2.676\n",
      "Average epoch loss: 2.676\n",
      "This epoch took 5.903524959087372 mins. Time remaining: 0.0 hrs 23.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.191049098968506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.08it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 717.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.045387576782303124, METEOR score: 0.19554948188506097\n",
      "Starting epoch 27/30, enc lr scheduler: [5.279499846691252e-05], dec lr scheduler: [5.279499846691252e-05]\n",
      "(Epoch 26, iter 50/787) Average loss so far: 2.678\n",
      "(Epoch 26, iter 100/787) Average loss so far: 2.663\n",
      "(Epoch 26, iter 150/787) Average loss so far: 2.672\n",
      "(Epoch 26, iter 200/787) Average loss so far: 2.686\n",
      "(Epoch 26, iter 250/787) Average loss so far: 2.678\n",
      "(Epoch 26, iter 300/787) Average loss so far: 2.668\n",
      "(Epoch 26, iter 350/787) Average loss so far: 2.687\n",
      "(Epoch 26, iter 400/787) Average loss so far: 2.667\n",
      "(Epoch 26, iter 450/787) Average loss so far: 2.661\n",
      "(Epoch 26, iter 500/787) Average loss so far: 2.681\n",
      "(Epoch 26, iter 550/787) Average loss so far: 2.689\n",
      "(Epoch 26, iter 600/787) Average loss so far: 2.655\n",
      "(Epoch 26, iter 650/787) Average loss so far: 2.680\n",
      "(Epoch 26, iter 700/787) Average loss so far: 2.657\n",
      "(Epoch 26, iter 750/787) Average loss so far: 2.667\n",
      "Average epoch loss: 2.672\n",
      "This epoch took 5.971899783611297 mins. Time remaining: 0.0 hrs 17.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.190984317234584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.10it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 678.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04477507155847262, METEOR score: 0.19652649610987258\n",
      "Starting epoch 28/30, enc lr scheduler: [3.4227024433899005e-05], dec lr scheduler: [3.4227024433899005e-05]\n",
      "(Epoch 27, iter 50/787) Average loss so far: 2.688\n",
      "(Epoch 27, iter 100/787) Average loss so far: 2.668\n",
      "(Epoch 27, iter 150/787) Average loss so far: 2.669\n",
      "(Epoch 27, iter 200/787) Average loss so far: 2.668\n",
      "(Epoch 27, iter 250/787) Average loss so far: 2.677\n",
      "(Epoch 27, iter 300/787) Average loss so far: 2.678\n",
      "(Epoch 27, iter 350/787) Average loss so far: 2.672\n",
      "(Epoch 27, iter 400/787) Average loss so far: 2.675\n",
      "(Epoch 27, iter 450/787) Average loss so far: 2.645\n",
      "(Epoch 27, iter 500/787) Average loss so far: 2.663\n",
      "(Epoch 27, iter 550/787) Average loss so far: 2.667\n",
      "(Epoch 27, iter 600/787) Average loss so far: 2.666\n",
      "(Epoch 27, iter 650/787) Average loss so far: 2.684\n",
      "(Epoch 27, iter 700/787) Average loss so far: 2.673\n",
      "(Epoch 27, iter 750/787) Average loss so far: 2.664\n",
      "Average epoch loss: 2.670\n",
      "This epoch took 5.924192730585734 mins. Time remaining: 0.0 hrs 11.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.191187177385603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.29it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 711.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04755797880330766, METEOR score: 0.20054605031876846\n",
      "Starting epoch 29/30, enc lr scheduler: [2.0816937636766188e-05], dec lr scheduler: [2.0816937636766188e-05]\n",
      "(Epoch 28, iter 50/787) Average loss so far: 2.658\n",
      "(Epoch 28, iter 100/787) Average loss so far: 2.680\n",
      "(Epoch 28, iter 150/787) Average loss so far: 2.687\n",
      "(Epoch 28, iter 200/787) Average loss so far: 2.667\n",
      "(Epoch 28, iter 250/787) Average loss so far: 2.670\n",
      "(Epoch 28, iter 300/787) Average loss so far: 2.676\n",
      "(Epoch 28, iter 350/787) Average loss so far: 2.678\n",
      "(Epoch 28, iter 400/787) Average loss so far: 2.680\n",
      "(Epoch 28, iter 450/787) Average loss so far: 2.667\n",
      "(Epoch 28, iter 500/787) Average loss so far: 2.670\n",
      "(Epoch 28, iter 550/787) Average loss so far: 2.669\n",
      "(Epoch 28, iter 600/787) Average loss so far: 2.635\n",
      "(Epoch 28, iter 650/787) Average loss so far: 2.672\n",
      "(Epoch 28, iter 700/787) Average loss so far: 2.669\n",
      "(Epoch 28, iter 750/787) Average loss so far: 2.660\n",
      "Average epoch loss: 2.669\n",
      "This epoch took 5.942501409848531 mins. Time remaining: 0.0 hrs 5.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1912351676395962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.14it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 689.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04576639965453813, METEOR score: 0.19814575935905007\n",
      "Starting epoch 30/30, enc lr scheduler: [1.2711661792704668e-05], dec lr scheduler: [1.2711661792704668e-05]\n",
      "(Epoch 29, iter 50/787) Average loss so far: 2.674\n",
      "(Epoch 29, iter 100/787) Average loss so far: 2.674\n",
      "(Epoch 29, iter 150/787) Average loss so far: 2.675\n",
      "(Epoch 29, iter 200/787) Average loss so far: 2.647\n",
      "(Epoch 29, iter 250/787) Average loss so far: 2.673\n",
      "(Epoch 29, iter 300/787) Average loss so far: 2.653\n",
      "(Epoch 29, iter 350/787) Average loss so far: 2.662\n",
      "(Epoch 29, iter 400/787) Average loss so far: 2.661\n",
      "(Epoch 29, iter 450/787) Average loss so far: 2.664\n",
      "(Epoch 29, iter 500/787) Average loss so far: 2.695\n",
      "(Epoch 29, iter 550/787) Average loss so far: 2.670\n",
      "(Epoch 29, iter 600/787) Average loss so far: 2.660\n",
      "(Epoch 29, iter 650/787) Average loss so far: 2.679\n",
      "(Epoch 29, iter 700/787) Average loss so far: 2.666\n",
      "(Epoch 29, iter 750/787) Average loss so far: 2.656\n",
      "Average epoch loss: 2.668\n",
      "This epoch took 5.976911421616872 mins. Time remaining: 0.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.191310610089983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.16it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 697.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.045667970073548995, METEOR score: 0.19664536921554326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_lr=1e-3\n",
    "min_lr = 1e-5\n",
    "n_epochs = 30\n",
    "batch_size=128\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=initial_lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=initial_lr)\n",
    "enc_scheduler = CosineAnnealingLR(encoder_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "dec_scheduler = CosineAnnealingLR(decoder_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "# enc_scheduler = MultiStepLR(encoder_optimizer, milestones=[15], gamma=0.1)\n",
    "# dec_scheduler = MultiStepLR(decoder_optimizer, milestones=[15], gamma=0.1)\n",
    "identifier=\"adam_without_intermediate_tags_with_val_wd0_lr1e-3\"\n",
    "epoch_losses, val_epoch_losses, log = train(encoder, decoder, encoder_optimizer, decoder_optimizer, train_ds, \n",
    "                     n_epochs=n_epochs, vocab=vocab, decoder_mode=\"basic\", batch_size=batch_size, \n",
    "                     enc_lr_scheduler=enc_scheduler, dec_lr_scheduler=dec_scheduler, \n",
    "                     dev_ds_val_loss = dev_ds_val_loss, dev_ds_val_met=dev_ds_val_met, identifier=identifier,\n",
    "                     verbose_iter_interval=50)\n",
    "\n",
    "save_log(identifier, log, encoder_optimizer, decoder_optimizer, enc_scheduler, dec_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Baseline 2\n",
    "\n",
    "Note that the Encoder is reused from Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, padding_val,\n",
    "                 dropout=0.1, global_max_ing_len=MAX_INGR_LEN,\n",
    "                 pretrained_embedding_dict=None,\n",
    "                 vocab=None, num_lstm_layers=1,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.padding_val = padding_val\n",
    "        self.global_max_ing_len = global_max_ing_len\n",
    "\n",
    "        self.embedding, self.pretrained_emb_idxs = create_embeddings(\n",
    "            output_size, embedding_size, pretrained_embedding_dict, vocab)\n",
    "        self.attn = nn.Linear(hidden_size + embedding_size, global_max_ing_len)\n",
    "        self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=False, num_layers=num_lstm_layers)\n",
    "        self.nonlinear_activation = nn.ReLU() # TODO: TRY TANH\n",
    "        self.out_fc = nn.Linear(hidden_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def update_embedding_grad(self, grads):\n",
    "        if not hasattr(self, \"pretrained_emb_idxs\"):\n",
    "            return\n",
    "        \n",
    "        grads[self.pretrained_emb_idxs] = 0 # zero-out gradients for pretrained embeddings\n",
    "\n",
    "    def mask_attn_weights(self, ingredients, attn_weights):\n",
    "        \"\"\"\n",
    "        ingredients: [N, L_i]\n",
    "        \"\"\"\n",
    "        # ing_len = ingredients.size(1)\n",
    "        # pad ingredients on the right with `padding_val` to maximum len\n",
    "        # [N, max_len]\n",
    "        # padd_maxlen_ingredients = F.pad(\n",
    "        #     ingredients, (0, self.global_max_ing_len-ing_len), value=0)\n",
    "        # [N, L_i] where 1 is masked value, 0 is valid value\n",
    "        attn_mask = ingredients == self.padding_val\n",
    "        assert list(attn_weights.shape) == list(attn_mask.shape)\n",
    "        attn_weights[attn_mask] = -torch.inf # set as -inf because when softmax-ed will turn to 0\n",
    "        return attn_weights\n",
    "\n",
    "    def forward(self, inp, hidden, cell, encoder_houts, ingredients):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inp (torch.Tensor): start token or previous generation (non teacher-forcing) or \n",
    "                                previous ground truth token (teacher-forcing);\n",
    "                                shape [N]\n",
    "            hidden (torch.Tensor): encoder last hidden state; shape [1, N, H]\n",
    "            cell (torch.Tensor): encoder last cell state; shape [1, N, H]\n",
    "            encoder_houts (torch.Tensor): encoder all hidden states for all elements in sequence;\n",
    "                                          padded tensor [N, L_i, H], where L_i is the max sequence len\n",
    "        \"\"\"\n",
    "        L_i = encoder_houts.size(1) # max seq len in this batch\n",
    "        ## embed token input\n",
    "        inp_embedded = self.embedding(inp) # [N, E]\n",
    "\n",
    "        inp_embedded = self.dropout(inp_embedded)\n",
    "\n",
    "        attn_weights = self.attn(\n",
    "            torch.cat((inp_embedded, hidden[-1]), dim=1) # [N, E+H]\n",
    "        )[:, :L_i] # [N, max_ing_len] -> [N, L_i]\n",
    "        # [N, L_i]\n",
    "        attn_weights = F.softmax(\n",
    "            self.mask_attn_weights(ingredients, attn_weights),\n",
    "            dim=-1)\n",
    "        # [N, 1, L_i] bmm [N, L_i, H] = [N, 1, H] -> [N, H]\n",
    "        attn_res = torch.bmm(attn_weights[:, None], encoder_houts)[:, 0]\n",
    "\n",
    "        # [N, E+H]\n",
    "        output = torch.cat((inp_embedded, attn_res), dim=-1)\n",
    "        # [N, E+H] -> [N, H] -> [L=1, N, H]\n",
    "        output = self.attn_combine(output)[None]\n",
    "        output = self.nonlinear_activation(output)\n",
    "\n",
    "        ## feed embedded input and hidden state through LSTM\n",
    "        # out: output features; shape [L=1, N, H]\n",
    "        # h_final: final updated hidden state; shape [num_layers=1, N, H]\n",
    "        # c_final: last cell state Tensor [num_layers=1, N, H]\n",
    "        out, (h_final, c_final) = self.lstm(output, (hidden, cell))\n",
    "\n",
    "        out = self.out_fc(out) # [L=1, N, H] -> [L=1, N, |Vocab|]\n",
    "\n",
    "        ## log softmax to get log probability distribution over vocabulary words\n",
    "        out = self.logsoftmax(out[0])\n",
    "\n",
    "        return out, h_final, c_final, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rng()\n",
    "embedding_size=300\n",
    "encoder_attn = EncoderRNN(vocab.n_unique_words, embedding_size=embedding_size, hidden_size=HIDDEN_SIZE, padding_value=vocab.word2index(PAD_WORD)).to(DEVICE)\n",
    "# in the training script, decoder is always fed a non-end token and thus never needs to generate padding\n",
    "# also it should never generate \"<UNKNOWN>\"\n",
    "# decoder = DecoderRNN(embedding_size=embedding_size,hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-2).to(DEVICE)\n",
    "decoder_attn = AttnDecoderRNN(embedding_size, hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-1, padding_val=vocab.word2index(PAD_WORD), \n",
    "                              dropout=DROPOUT).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30, enc lr scheduler: [0.001], dec lr scheduler: [0.001]\n",
      "(Epoch 0, iter 50/787) Average loss so far: 6.972\n",
      "(Epoch 0, iter 100/787) Average loss so far: 6.023\n",
      "(Epoch 0, iter 150/787) Average loss so far: 5.968\n",
      "(Epoch 0, iter 200/787) Average loss so far: 5.927\n",
      "(Epoch 0, iter 250/787) Average loss so far: 5.877\n",
      "(Epoch 0, iter 300/787) Average loss so far: 5.818\n",
      "(Epoch 0, iter 350/787) Average loss so far: 5.785\n",
      "(Epoch 0, iter 400/787) Average loss so far: 5.725\n",
      "(Epoch 0, iter 450/787) Average loss so far: 5.683\n",
      "(Epoch 0, iter 500/787) Average loss so far: 5.621\n",
      "(Epoch 0, iter 550/787) Average loss so far: 5.551\n",
      "(Epoch 0, iter 600/787) Average loss so far: 5.440\n",
      "(Epoch 0, iter 650/787) Average loss so far: 5.360\n",
      "(Epoch 0, iter 700/787) Average loss so far: 5.215\n",
      "(Epoch 0, iter 750/787) Average loss so far: 5.093\n",
      "Average epoch loss: 5.701\n",
      "This epoch took 8.194433637460072 mins. Time remaining: 3.0 hrs 57.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 4.93167952128819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.13s/it]\n",
      "100%|██████████| 793/793 [00:08<00:00, 95.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.002800126985071343, METEOR score: 0.08576382563509898\n",
      "Starting epoch 2/30, enc lr scheduler: [0.0009972883382072953], dec lr scheduler: [0.0009972883382072953]\n",
      "(Epoch 1, iter 50/787) Average loss so far: 4.863\n",
      "(Epoch 1, iter 100/787) Average loss so far: 4.706\n",
      "(Epoch 1, iter 150/787) Average loss so far: 4.641\n",
      "(Epoch 1, iter 200/787) Average loss so far: 4.523\n",
      "(Epoch 1, iter 250/787) Average loss so far: 4.437\n",
      "(Epoch 1, iter 300/787) Average loss so far: 4.366\n",
      "(Epoch 1, iter 350/787) Average loss so far: 4.295\n",
      "(Epoch 1, iter 400/787) Average loss so far: 4.248\n",
      "(Epoch 1, iter 450/787) Average loss so far: 4.186\n",
      "(Epoch 1, iter 500/787) Average loss so far: 4.133\n",
      "(Epoch 1, iter 550/787) Average loss so far: 4.082\n",
      "(Epoch 1, iter 600/787) Average loss so far: 4.041\n",
      "(Epoch 1, iter 650/787) Average loss so far: 4.004\n",
      "(Epoch 1, iter 700/787) Average loss so far: 3.956\n",
      "(Epoch 1, iter 750/787) Average loss so far: 3.932\n",
      "Average epoch loss: 4.277\n",
      "This epoch took 8.073306282361349 mins. Time remaining: 3.0 hrs 46.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.926896367754255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n",
      "100%|██████████| 793/793 [00:07<00:00, 112.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.005528415216107959, METEOR score: 0.1087509998355728\n",
      "Starting epoch 3/30, enc lr scheduler: [0.0009891830623632338], dec lr scheduler: [0.0009891830623632338]\n",
      "(Epoch 2, iter 50/787) Average loss so far: 3.866\n",
      "(Epoch 2, iter 100/787) Average loss so far: 3.844\n",
      "(Epoch 2, iter 150/787) Average loss so far: 3.818\n",
      "(Epoch 2, iter 200/787) Average loss so far: 3.778\n",
      "(Epoch 2, iter 250/787) Average loss so far: 3.752\n",
      "(Epoch 2, iter 300/787) Average loss so far: 3.761\n",
      "(Epoch 2, iter 350/787) Average loss so far: 3.706\n",
      "(Epoch 2, iter 400/787) Average loss so far: 3.690\n",
      "(Epoch 2, iter 450/787) Average loss so far: 3.667\n",
      "(Epoch 2, iter 500/787) Average loss so far: 3.662\n",
      "(Epoch 2, iter 550/787) Average loss so far: 3.666\n",
      "(Epoch 2, iter 600/787) Average loss so far: 3.646\n",
      "(Epoch 2, iter 650/787) Average loss so far: 3.610\n",
      "(Epoch 2, iter 700/787) Average loss so far: 3.615\n",
      "(Epoch 2, iter 750/787) Average loss so far: 3.572\n",
      "Average epoch loss: 3.704\n",
      "This epoch took 8.144790331522623 mins. Time remaining: 3.0 hrs 39.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.6217985493796214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.51it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 240.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.015059414822228353, METEOR score: 0.1608885573065793\n",
      "Starting epoch 4/30, enc lr scheduler: [0.0009757729755661011], dec lr scheduler: [0.0009757729755661011]\n",
      "(Epoch 3, iter 50/787) Average loss so far: 3.552\n",
      "(Epoch 3, iter 100/787) Average loss so far: 3.533\n",
      "(Epoch 3, iter 150/787) Average loss so far: 3.512\n",
      "(Epoch 3, iter 200/787) Average loss so far: 3.499\n",
      "(Epoch 3, iter 250/787) Average loss so far: 3.503\n",
      "(Epoch 3, iter 300/787) Average loss so far: 3.494\n",
      "(Epoch 3, iter 350/787) Average loss so far: 3.480\n",
      "(Epoch 3, iter 400/787) Average loss so far: 3.455\n",
      "(Epoch 3, iter 450/787) Average loss so far: 3.445\n",
      "(Epoch 3, iter 500/787) Average loss so far: 3.436\n",
      "(Epoch 3, iter 550/787) Average loss so far: 3.436\n",
      "(Epoch 3, iter 600/787) Average loss so far: 3.424\n",
      "(Epoch 3, iter 650/787) Average loss so far: 3.410\n",
      "(Epoch 3, iter 700/787) Average loss so far: 3.401\n",
      "(Epoch 3, iter 750/787) Average loss so far: 3.412\n",
      "Average epoch loss: 3.463\n",
      "This epoch took 8.090149772167205 mins. Time remaining: 3.0 hrs 30.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.4686967645372664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.87it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 350.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.02478974721483497, METEOR score: 0.18132902088830255\n",
      "Starting epoch 5/30, enc lr scheduler: [0.0009572050015330874], dec lr scheduler: [0.0009572050015330874]\n",
      "(Epoch 4, iter 50/787) Average loss so far: 3.370\n",
      "(Epoch 4, iter 100/787) Average loss so far: 3.354\n",
      "(Epoch 4, iter 150/787) Average loss so far: 3.346\n",
      "(Epoch 4, iter 200/787) Average loss so far: 3.360\n",
      "(Epoch 4, iter 250/787) Average loss so far: 3.335\n",
      "(Epoch 4, iter 300/787) Average loss so far: 3.325\n",
      "(Epoch 4, iter 350/787) Average loss so far: 3.323\n",
      "(Epoch 4, iter 400/787) Average loss so far: 3.308\n",
      "(Epoch 4, iter 450/787) Average loss so far: 3.320\n",
      "(Epoch 4, iter 500/787) Average loss so far: 3.303\n",
      "(Epoch 4, iter 550/787) Average loss so far: 3.310\n",
      "(Epoch 4, iter 600/787) Average loss so far: 3.296\n",
      "(Epoch 4, iter 650/787) Average loss so far: 3.290\n",
      "(Epoch 4, iter 700/787) Average loss so far: 3.293\n",
      "(Epoch 4, iter 750/787) Average loss so far: 3.283\n",
      "Average epoch loss: 3.318\n",
      "This epoch took 8.103163651625316 mins. Time remaining: 3.0 hrs 22.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.376786708831787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.44it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 216.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.016797911257019238, METEOR score: 0.17466288946573208\n",
      "Starting epoch 6/30, enc lr scheduler: [0.0009336825748732973], dec lr scheduler: [0.0009336825748732973]\n",
      "(Epoch 5, iter 50/787) Average loss so far: 3.233\n",
      "(Epoch 5, iter 100/787) Average loss so far: 3.250\n",
      "(Epoch 5, iter 150/787) Average loss so far: 3.227\n",
      "(Epoch 5, iter 200/787) Average loss so far: 3.236\n",
      "(Epoch 5, iter 250/787) Average loss so far: 3.215\n",
      "(Epoch 5, iter 300/787) Average loss so far: 3.229\n",
      "(Epoch 5, iter 350/787) Average loss so far: 3.227\n",
      "(Epoch 5, iter 400/787) Average loss so far: 3.229\n",
      "(Epoch 5, iter 450/787) Average loss so far: 3.212\n",
      "(Epoch 5, iter 500/787) Average loss so far: 3.217\n",
      "(Epoch 5, iter 550/787) Average loss so far: 3.221\n",
      "(Epoch 5, iter 600/787) Average loss so far: 3.205\n",
      "(Epoch 5, iter 650/787) Average loss so far: 3.199\n",
      "(Epoch 5, iter 700/787) Average loss so far: 3.194\n",
      "(Epoch 5, iter 750/787) Average loss so far: 3.184\n",
      "Average epoch loss: 3.217\n",
      "This epoch took 8.09989018837611 mins. Time remaining: 3.0 hrs 14.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.3135062967027937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.87it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 322.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.026052313701649024, METEOR score: 0.1865945117369642\n",
      "Starting epoch 7/30, enc lr scheduler: [0.0009054634122155991], dec lr scheduler: [0.0009054634122155991]\n",
      "(Epoch 6, iter 50/787) Average loss so far: 3.171\n",
      "(Epoch 6, iter 100/787) Average loss so far: 3.163\n",
      "(Epoch 6, iter 150/787) Average loss so far: 3.161\n",
      "(Epoch 6, iter 200/787) Average loss so far: 3.149\n",
      "(Epoch 6, iter 250/787) Average loss so far: 3.141\n",
      "(Epoch 6, iter 300/787) Average loss so far: 3.143\n",
      "(Epoch 6, iter 350/787) Average loss so far: 3.139\n",
      "(Epoch 6, iter 400/787) Average loss so far: 3.145\n",
      "(Epoch 6, iter 450/787) Average loss so far: 3.148\n",
      "(Epoch 6, iter 500/787) Average loss so far: 3.133\n",
      "(Epoch 6, iter 550/787) Average loss so far: 3.126\n",
      "(Epoch 6, iter 600/787) Average loss so far: 3.146\n",
      "(Epoch 6, iter 650/787) Average loss so far: 3.121\n",
      "(Epoch 6, iter 700/787) Average loss so far: 3.131\n",
      "(Epoch 6, iter 750/787) Average loss so far: 3.117\n",
      "Average epoch loss: 3.141\n",
      "This epoch took 8.1756121357282 mins. Time remaining: 3.0 hrs 8.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.277291910988944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.86it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 339.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0272790639424669, METEOR score: 0.1936208372227744\n",
      "Starting epoch 8/30, enc lr scheduler: [0.0008728566886113102], dec lr scheduler: [0.0008728566886113102]\n",
      "(Epoch 7, iter 50/787) Average loss so far: 3.102\n",
      "(Epoch 7, iter 100/787) Average loss so far: 3.099\n",
      "(Epoch 7, iter 150/787) Average loss so far: 3.106\n",
      "(Epoch 7, iter 200/787) Average loss so far: 3.087\n",
      "(Epoch 7, iter 250/787) Average loss so far: 3.083\n",
      "(Epoch 7, iter 300/787) Average loss so far: 3.089\n",
      "(Epoch 7, iter 350/787) Average loss so far: 3.085\n",
      "(Epoch 7, iter 400/787) Average loss so far: 3.076\n",
      "(Epoch 7, iter 450/787) Average loss so far: 3.084\n",
      "(Epoch 7, iter 500/787) Average loss so far: 3.067\n",
      "(Epoch 7, iter 550/787) Average loss so far: 3.081\n",
      "(Epoch 7, iter 600/787) Average loss so far: 3.054\n",
      "(Epoch 7, iter 650/787) Average loss so far: 3.071\n",
      "(Epoch 7, iter 700/787) Average loss so far: 3.076\n",
      "(Epoch 7, iter 750/787) Average loss so far: 3.075\n",
      "Average epoch loss: 3.081\n",
      "This epoch took 8.089503169059753 mins. Time remaining: 2.0 hrs 57.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2438402516501292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.02it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 431.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.038146458721083895, METEOR score: 0.1998428588672739\n",
      "Starting epoch 9/30, enc lr scheduler: [0.0008362196501476349], dec lr scheduler: [0.0008362196501476349]\n",
      "(Epoch 8, iter 50/787) Average loss so far: 3.045\n",
      "(Epoch 8, iter 100/787) Average loss so far: 3.044\n",
      "(Epoch 8, iter 150/787) Average loss so far: 3.046\n",
      "(Epoch 8, iter 200/787) Average loss so far: 3.050\n",
      "(Epoch 8, iter 250/787) Average loss so far: 3.025\n",
      "(Epoch 8, iter 300/787) Average loss so far: 3.033\n",
      "(Epoch 8, iter 350/787) Average loss so far: 3.038\n",
      "(Epoch 8, iter 400/787) Average loss so far: 3.021\n",
      "(Epoch 8, iter 450/787) Average loss so far: 3.028\n",
      "(Epoch 8, iter 500/787) Average loss so far: 3.025\n",
      "(Epoch 8, iter 550/787) Average loss so far: 3.041\n",
      "(Epoch 8, iter 600/787) Average loss so far: 3.017\n",
      "(Epoch 8, iter 650/787) Average loss so far: 3.017\n",
      "(Epoch 8, iter 700/787) Average loss so far: 3.039\n",
      "(Epoch 8, iter 750/787) Average loss so far: 3.022\n",
      "Average epoch loss: 3.031\n",
      "This epoch took 8.09464071591695 mins. Time remaining: 2.0 hrs 49.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2192379406520297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.01it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 409.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.036190345080440604, METEOR score: 0.19858925888566942\n",
      "Starting epoch 10/30, enc lr scheduler: [0.0007959536998847742], dec lr scheduler: [0.0007959536998847742]\n",
      "(Epoch 9, iter 50/787) Average loss so far: 3.012\n",
      "(Epoch 9, iter 100/787) Average loss so far: 2.984\n",
      "(Epoch 9, iter 150/787) Average loss so far: 2.981\n",
      "(Epoch 9, iter 200/787) Average loss so far: 2.988\n",
      "(Epoch 9, iter 250/787) Average loss so far: 2.998\n",
      "(Epoch 9, iter 300/787) Average loss so far: 2.991\n",
      "(Epoch 9, iter 350/787) Average loss so far: 3.002\n",
      "(Epoch 9, iter 400/787) Average loss so far: 2.992\n",
      "(Epoch 9, iter 450/787) Average loss so far: 3.007\n",
      "(Epoch 9, iter 500/787) Average loss so far: 2.980\n",
      "(Epoch 9, iter 550/787) Average loss so far: 2.987\n",
      "(Epoch 9, iter 600/787) Average loss so far: 2.970\n",
      "(Epoch 9, iter 650/787) Average loss so far: 2.989\n",
      "(Epoch 9, iter 700/787) Average loss so far: 2.997\n",
      "(Epoch 9, iter 750/787) Average loss so far: 2.971\n",
      "Average epoch loss: 2.990\n",
      "This epoch took 8.119804537296295 mins. Time remaining: 2.0 hrs 42.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2011922086988176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.08it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 448.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.03947045191983198, METEOR score: 0.19917691253253444\n",
      "Starting epoch 11/30, enc lr scheduler: [0.0007525], dec lr scheduler: [0.0007525]\n",
      "(Epoch 10, iter 50/787) Average loss so far: 2.958\n",
      "(Epoch 10, iter 100/787) Average loss so far: 2.957\n",
      "(Epoch 10, iter 150/787) Average loss so far: 2.941\n",
      "(Epoch 10, iter 200/787) Average loss so far: 2.959\n",
      "(Epoch 10, iter 250/787) Average loss so far: 2.947\n",
      "(Epoch 10, iter 300/787) Average loss so far: 2.957\n",
      "(Epoch 10, iter 350/787) Average loss so far: 2.952\n",
      "(Epoch 10, iter 400/787) Average loss so far: 2.966\n",
      "(Epoch 10, iter 450/787) Average loss so far: 2.948\n",
      "(Epoch 10, iter 500/787) Average loss so far: 2.961\n",
      "(Epoch 10, iter 550/787) Average loss so far: 2.954\n",
      "(Epoch 10, iter 600/787) Average loss so far: 2.947\n",
      "(Epoch 10, iter 650/787) Average loss so far: 2.955\n",
      "(Epoch 10, iter 700/787) Average loss so far: 2.952\n",
      "(Epoch 10, iter 750/787) Average loss so far: 2.965\n",
      "Average epoch loss: 2.955\n",
      "This epoch took 8.114036385218302 mins. Time remaining: 2.0 hrs 34.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1880315371922086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.01it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 432.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.03707379676793246, METEOR score: 0.20066902120742106\n",
      "Starting epoch 12/30, enc lr scheduler: [0.0007063346383225212], dec lr scheduler: [0.0007063346383225212]\n",
      "(Epoch 11, iter 50/787) Average loss so far: 2.919\n",
      "(Epoch 11, iter 100/787) Average loss so far: 2.936\n",
      "(Epoch 11, iter 150/787) Average loss so far: 2.912\n",
      "(Epoch 11, iter 200/787) Average loss so far: 2.926\n",
      "(Epoch 11, iter 250/787) Average loss so far: 2.933\n",
      "(Epoch 11, iter 300/787) Average loss so far: 2.918\n",
      "(Epoch 11, iter 350/787) Average loss so far: 2.928\n",
      "(Epoch 11, iter 400/787) Average loss so far: 2.931\n",
      "(Epoch 11, iter 450/787) Average loss so far: 2.915\n",
      "(Epoch 11, iter 500/787) Average loss so far: 2.925\n",
      "(Epoch 11, iter 550/787) Average loss so far: 2.922\n",
      "(Epoch 11, iter 600/787) Average loss so far: 2.912\n",
      "(Epoch 11, iter 650/787) Average loss so far: 2.919\n",
      "(Epoch 11, iter 700/787) Average loss so far: 2.929\n",
      "(Epoch 11, iter 750/787) Average loss so far: 2.939\n",
      "Average epoch loss: 2.924\n",
      "This epoch took 8.10150664250056 mins. Time remaining: 2.0 hrs 25.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1738901478903636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.97it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 420.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.03867613565428751, METEOR score: 0.2017267310038669\n",
      "Starting epoch 13/30, enc lr scheduler: [0.000657963412215599], dec lr scheduler: [0.000657963412215599]\n",
      "(Epoch 12, iter 50/787) Average loss so far: 2.889\n",
      "(Epoch 12, iter 100/787) Average loss so far: 2.888\n",
      "(Epoch 12, iter 150/787) Average loss so far: 2.880\n",
      "(Epoch 12, iter 200/787) Average loss so far: 2.896\n",
      "(Epoch 12, iter 250/787) Average loss so far: 2.896\n",
      "(Epoch 12, iter 300/787) Average loss so far: 2.903\n",
      "(Epoch 12, iter 350/787) Average loss so far: 2.885\n",
      "(Epoch 12, iter 400/787) Average loss so far: 2.904\n",
      "(Epoch 12, iter 450/787) Average loss so far: 2.898\n",
      "(Epoch 12, iter 500/787) Average loss so far: 2.898\n",
      "(Epoch 12, iter 550/787) Average loss so far: 2.892\n",
      "(Epoch 12, iter 600/787) Average loss so far: 2.911\n",
      "(Epoch 12, iter 650/787) Average loss so far: 2.916\n",
      "(Epoch 12, iter 700/787) Average loss so far: 2.894\n",
      "(Epoch 12, iter 750/787) Average loss so far: 2.902\n",
      "Average epoch loss: 2.896\n",
      "This epoch took 8.079897010326386 mins. Time remaining: 2.0 hrs 17.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1668037346431186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.94it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 390.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.035783646119029455, METEOR score: 0.19836152461714607\n",
      "Starting epoch 14/30, enc lr scheduler: [0.0006079162869547909], dec lr scheduler: [0.0006079162869547909]\n",
      "(Epoch 13, iter 50/787) Average loss so far: 2.883\n",
      "(Epoch 13, iter 100/787) Average loss so far: 2.870\n",
      "(Epoch 13, iter 150/787) Average loss so far: 2.875\n",
      "(Epoch 13, iter 200/787) Average loss so far: 2.870\n",
      "(Epoch 13, iter 250/787) Average loss so far: 2.899\n",
      "(Epoch 13, iter 300/787) Average loss so far: 2.864\n",
      "(Epoch 13, iter 350/787) Average loss so far: 2.870\n",
      "(Epoch 13, iter 400/787) Average loss so far: 2.875\n",
      "(Epoch 13, iter 450/787) Average loss so far: 2.873\n",
      "(Epoch 13, iter 500/787) Average loss so far: 2.873\n",
      "(Epoch 13, iter 550/787) Average loss so far: 2.860\n",
      "(Epoch 13, iter 600/787) Average loss so far: 2.863\n",
      "(Epoch 13, iter 650/787) Average loss so far: 2.887\n",
      "(Epoch 13, iter 700/787) Average loss so far: 2.874\n",
      "(Epoch 13, iter 750/787) Average loss so far: 2.867\n",
      "Average epoch loss: 2.873\n",
      "This epoch took 8.058853403727214 mins. Time remaining: 2.0 hrs 8.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1585819721221924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.98it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 447.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04004954169047118, METEOR score: 0.20343329001800056\n",
      "Starting epoch 15/30, enc lr scheduler: [0.0005567415893174886], dec lr scheduler: [0.0005567415893174886]\n",
      "(Epoch 14, iter 50/787) Average loss so far: 2.854\n",
      "(Epoch 14, iter 100/787) Average loss so far: 2.848\n",
      "(Epoch 14, iter 150/787) Average loss so far: 2.840\n",
      "(Epoch 14, iter 200/787) Average loss so far: 2.846\n",
      "(Epoch 14, iter 250/787) Average loss so far: 2.842\n",
      "(Epoch 14, iter 300/787) Average loss so far: 2.861\n",
      "(Epoch 14, iter 350/787) Average loss so far: 2.832\n",
      "(Epoch 14, iter 400/787) Average loss so far: 2.864\n",
      "(Epoch 14, iter 450/787) Average loss so far: 2.858\n",
      "(Epoch 14, iter 500/787) Average loss so far: 2.865\n",
      "(Epoch 14, iter 550/787) Average loss so far: 2.849\n",
      "(Epoch 14, iter 600/787) Average loss so far: 2.854\n",
      "(Epoch 14, iter 650/787) Average loss so far: 2.849\n",
      "(Epoch 14, iter 700/787) Average loss so far: 2.852\n",
      "(Epoch 14, iter 750/787) Average loss so far: 2.866\n",
      "Average epoch loss: 2.852\n",
      "This epoch took 8.125524540742239 mins. Time remaining: 2.0 hrs 1.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.157423734664917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.14it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 505.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04606436720940942, METEOR score: 0.2026929298648693\n",
      "Starting epoch 16/30, enc lr scheduler: [0.0005050000000000002], dec lr scheduler: [0.0005050000000000002]\n",
      "(Epoch 15, iter 50/787) Average loss so far: 2.824\n",
      "(Epoch 15, iter 100/787) Average loss so far: 2.823\n",
      "(Epoch 15, iter 150/787) Average loss so far: 2.835\n",
      "(Epoch 15, iter 200/787) Average loss so far: 2.824\n",
      "(Epoch 15, iter 250/787) Average loss so far: 2.828\n",
      "(Epoch 15, iter 300/787) Average loss so far: 2.832\n",
      "(Epoch 15, iter 350/787) Average loss so far: 2.837\n",
      "(Epoch 15, iter 400/787) Average loss so far: 2.820\n",
      "(Epoch 15, iter 450/787) Average loss so far: 2.829\n",
      "(Epoch 15, iter 500/787) Average loss so far: 2.846\n",
      "(Epoch 15, iter 550/787) Average loss so far: 2.845\n",
      "(Epoch 15, iter 600/787) Average loss so far: 2.843\n",
      "(Epoch 15, iter 650/787) Average loss so far: 2.838\n",
      "(Epoch 15, iter 700/787) Average loss so far: 2.838\n",
      "(Epoch 15, iter 750/787) Average loss so far: 2.839\n",
      "Average epoch loss: 2.833\n",
      "This epoch took 8.089334380626678 mins. Time remaining: 1.0 hrs 53.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1507908276149204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.12it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 486.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04347215230255102, METEOR score: 0.20329518542651354\n",
      "Starting epoch 17/30, enc lr scheduler: [0.0004532584106825117], dec lr scheduler: [0.0004532584106825117]\n",
      "(Epoch 16, iter 50/787) Average loss so far: 2.810\n",
      "(Epoch 16, iter 100/787) Average loss so far: 2.807\n",
      "(Epoch 16, iter 150/787) Average loss so far: 2.817\n",
      "(Epoch 16, iter 200/787) Average loss so far: 2.800\n",
      "(Epoch 16, iter 250/787) Average loss so far: 2.812\n",
      "(Epoch 16, iter 300/787) Average loss so far: 2.820\n",
      "(Epoch 16, iter 350/787) Average loss so far: 2.824\n",
      "(Epoch 16, iter 400/787) Average loss so far: 2.830\n",
      "(Epoch 16, iter 450/787) Average loss so far: 2.818\n",
      "(Epoch 16, iter 500/787) Average loss so far: 2.829\n",
      "(Epoch 16, iter 550/787) Average loss so far: 2.807\n",
      "(Epoch 16, iter 600/787) Average loss so far: 2.812\n",
      "(Epoch 16, iter 650/787) Average loss so far: 2.816\n",
      "(Epoch 16, iter 700/787) Average loss so far: 2.799\n",
      "(Epoch 16, iter 750/787) Average loss so far: 2.830\n",
      "Average epoch loss: 2.816\n",
      "This epoch took 8.11363825003306 mins. Time remaining: 1.0 hrs 45.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.146672351019723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.15it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 494.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04394619733107649, METEOR score: 0.2021709564532238\n",
      "Starting epoch 18/30, enc lr scheduler: [0.00040208371304520916], dec lr scheduler: [0.00040208371304520916]\n",
      "(Epoch 17, iter 50/787) Average loss so far: 2.801\n",
      "(Epoch 17, iter 100/787) Average loss so far: 2.796\n",
      "(Epoch 17, iter 150/787) Average loss so far: 2.805\n",
      "(Epoch 17, iter 200/787) Average loss so far: 2.794\n",
      "(Epoch 17, iter 250/787) Average loss so far: 2.784\n",
      "(Epoch 17, iter 300/787) Average loss so far: 2.814\n",
      "(Epoch 17, iter 350/787) Average loss so far: 2.790\n",
      "(Epoch 17, iter 400/787) Average loss so far: 2.786\n",
      "(Epoch 17, iter 450/787) Average loss so far: 2.808\n",
      "(Epoch 17, iter 500/787) Average loss so far: 2.801\n",
      "(Epoch 17, iter 550/787) Average loss so far: 2.797\n",
      "(Epoch 17, iter 600/787) Average loss so far: 2.811\n",
      "(Epoch 17, iter 650/787) Average loss so far: 2.809\n",
      "(Epoch 17, iter 700/787) Average loss so far: 2.813\n",
      "(Epoch 17, iter 750/787) Average loss so far: 2.814\n",
      "Average epoch loss: 2.802\n",
      "This epoch took 8.12422217130661 mins. Time remaining: 1.0 hrs 37.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.144554853439331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.18it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 539.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.050306488687707214, METEOR score: 0.2085596593048818\n",
      "Starting epoch 19/30, enc lr scheduler: [0.00035203658778440114], dec lr scheduler: [0.00035203658778440114]\n",
      "(Epoch 18, iter 50/787) Average loss so far: 2.776\n",
      "(Epoch 18, iter 100/787) Average loss so far: 2.779\n",
      "(Epoch 18, iter 150/787) Average loss so far: 2.778\n",
      "(Epoch 18, iter 200/787) Average loss so far: 2.786\n",
      "(Epoch 18, iter 250/787) Average loss so far: 2.788\n",
      "(Epoch 18, iter 300/787) Average loss so far: 2.771\n",
      "(Epoch 18, iter 350/787) Average loss so far: 2.792\n",
      "(Epoch 18, iter 400/787) Average loss so far: 2.808\n",
      "(Epoch 18, iter 450/787) Average loss so far: 2.795\n",
      "(Epoch 18, iter 500/787) Average loss so far: 2.784\n",
      "(Epoch 18, iter 550/787) Average loss so far: 2.794\n",
      "(Epoch 18, iter 600/787) Average loss so far: 2.780\n",
      "(Epoch 18, iter 650/787) Average loss so far: 2.786\n",
      "(Epoch 18, iter 700/787) Average loss so far: 2.799\n",
      "(Epoch 18, iter 750/787) Average loss so far: 2.798\n",
      "Average epoch loss: 2.788\n",
      "This epoch took 8.187793207168578 mins. Time remaining: 1.0 hrs 30.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.139380386897496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.20it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 524.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05073499908229344, METEOR score: 0.20909495784132945\n",
      "Starting epoch 20/30, enc lr scheduler: [0.00030366536167747904], dec lr scheduler: [0.00030366536167747904]\n",
      "(Epoch 19, iter 50/787) Average loss so far: 2.776\n",
      "(Epoch 19, iter 100/787) Average loss so far: 2.776\n",
      "(Epoch 19, iter 150/787) Average loss so far: 2.768\n",
      "(Epoch 19, iter 200/787) Average loss so far: 2.764\n",
      "(Epoch 19, iter 250/787) Average loss so far: 2.763\n",
      "(Epoch 19, iter 300/787) Average loss so far: 2.781\n",
      "(Epoch 19, iter 350/787) Average loss so far: 2.774\n",
      "(Epoch 19, iter 400/787) Average loss so far: 2.779\n",
      "(Epoch 19, iter 450/787) Average loss so far: 2.769\n",
      "(Epoch 19, iter 500/787) Average loss so far: 2.786\n",
      "(Epoch 19, iter 550/787) Average loss so far: 2.772\n",
      "(Epoch 19, iter 600/787) Average loss so far: 2.777\n",
      "(Epoch 19, iter 650/787) Average loss so far: 2.790\n",
      "(Epoch 19, iter 700/787) Average loss so far: 2.769\n",
      "(Epoch 19, iter 750/787) Average loss so far: 2.797\n",
      "Average epoch loss: 2.777\n",
      "This epoch took 8.119319772720337 mins. Time remaining: 1.0 hrs 21.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1408518382481168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 574.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05228166600737611, METEOR score: 0.20709094525810967\n",
      "Starting epoch 21/30, enc lr scheduler: [0.00025750000000000013], dec lr scheduler: [0.00025750000000000013]\n",
      "(Epoch 20, iter 50/787) Average loss so far: 2.769\n",
      "(Epoch 20, iter 100/787) Average loss so far: 2.758\n",
      "(Epoch 20, iter 150/787) Average loss so far: 2.767\n",
      "(Epoch 20, iter 200/787) Average loss so far: 2.772\n",
      "(Epoch 20, iter 250/787) Average loss so far: 2.776\n",
      "(Epoch 20, iter 300/787) Average loss so far: 2.772\n",
      "(Epoch 20, iter 350/787) Average loss so far: 2.749\n",
      "(Epoch 20, iter 400/787) Average loss so far: 2.774\n",
      "(Epoch 20, iter 450/787) Average loss so far: 2.760\n",
      "(Epoch 20, iter 500/787) Average loss so far: 2.759\n",
      "(Epoch 20, iter 550/787) Average loss so far: 2.761\n",
      "(Epoch 20, iter 600/787) Average loss so far: 2.778\n",
      "(Epoch 20, iter 650/787) Average loss so far: 2.762\n",
      "(Epoch 20, iter 700/787) Average loss so far: 2.777\n",
      "(Epoch 20, iter 750/787) Average loss so far: 2.765\n",
      "Average epoch loss: 2.767\n",
      "This epoch took 8.181585311889648 mins. Time remaining: 1.0 hrs 13.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1391042300633023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.38it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 609.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05379213235939195, METEOR score: 0.2088759308593728\n",
      "Starting epoch 22/30, enc lr scheduler: [0.00021404630011522585], dec lr scheduler: [0.00021404630011522585]\n",
      "(Epoch 21, iter 50/787) Average loss so far: 2.759\n",
      "(Epoch 21, iter 100/787) Average loss so far: 2.741\n",
      "(Epoch 21, iter 150/787) Average loss so far: 2.746\n",
      "(Epoch 21, iter 200/787) Average loss so far: 2.776\n",
      "(Epoch 21, iter 250/787) Average loss so far: 2.746\n",
      "(Epoch 21, iter 300/787) Average loss so far: 2.761\n",
      "(Epoch 21, iter 350/787) Average loss so far: 2.762\n",
      "(Epoch 21, iter 400/787) Average loss so far: 2.763\n",
      "(Epoch 21, iter 450/787) Average loss so far: 2.759\n",
      "(Epoch 21, iter 500/787) Average loss so far: 2.751\n",
      "(Epoch 21, iter 550/787) Average loss so far: 2.757\n",
      "(Epoch 21, iter 600/787) Average loss so far: 2.773\n",
      "(Epoch 21, iter 650/787) Average loss so far: 2.748\n",
      "(Epoch 21, iter 700/787) Average loss so far: 2.769\n",
      "(Epoch 21, iter 750/787) Average loss so far: 2.743\n",
      "Average epoch loss: 2.758\n",
      "This epoch took 8.174315893650055 mins. Time remaining: 1.0 hrs 5.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1356898035321916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.20it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 558.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0521244945980193, METEOR score: 0.20665171059130683\n",
      "Starting epoch 23/30, enc lr scheduler: [0.00017378034985236535], dec lr scheduler: [0.00017378034985236535]\n",
      "(Epoch 22, iter 50/787) Average loss so far: 2.743\n",
      "(Epoch 22, iter 100/787) Average loss so far: 2.736\n",
      "(Epoch 22, iter 150/787) Average loss so far: 2.749\n",
      "(Epoch 22, iter 200/787) Average loss so far: 2.755\n",
      "(Epoch 22, iter 250/787) Average loss so far: 2.747\n",
      "(Epoch 22, iter 300/787) Average loss so far: 2.757\n",
      "(Epoch 22, iter 350/787) Average loss so far: 2.755\n",
      "(Epoch 22, iter 400/787) Average loss so far: 2.744\n",
      "(Epoch 22, iter 450/787) Average loss so far: 2.758\n",
      "(Epoch 22, iter 500/787) Average loss so far: 2.746\n",
      "(Epoch 22, iter 550/787) Average loss so far: 2.760\n",
      "(Epoch 22, iter 600/787) Average loss so far: 2.766\n",
      "(Epoch 22, iter 650/787) Average loss so far: 2.742\n",
      "(Epoch 22, iter 700/787) Average loss so far: 2.747\n",
      "(Epoch 22, iter 750/787) Average loss so far: 2.749\n",
      "Average epoch loss: 2.750\n",
      "This epoch took 7.989608466625214 mins. Time remaining: 0.0 hrs 55.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1357997144971574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.43it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 591.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05242640382134315, METEOR score: 0.20686833056692383\n",
      "Starting epoch 24/30, enc lr scheduler: [0.00013714331138868998], dec lr scheduler: [0.00013714331138868998]\n",
      "(Epoch 23, iter 50/787) Average loss so far: 2.736\n",
      "(Epoch 23, iter 100/787) Average loss so far: 2.744\n",
      "(Epoch 23, iter 150/787) Average loss so far: 2.725\n",
      "(Epoch 23, iter 200/787) Average loss so far: 2.741\n",
      "(Epoch 23, iter 250/787) Average loss so far: 2.745\n",
      "(Epoch 23, iter 300/787) Average loss so far: 2.746\n",
      "(Epoch 23, iter 350/787) Average loss so far: 2.734\n",
      "(Epoch 23, iter 400/787) Average loss so far: 2.747\n",
      "(Epoch 23, iter 450/787) Average loss so far: 2.741\n",
      "(Epoch 23, iter 500/787) Average loss so far: 2.734\n",
      "(Epoch 23, iter 550/787) Average loss so far: 2.739\n",
      "(Epoch 23, iter 600/787) Average loss so far: 2.744\n",
      "(Epoch 23, iter 650/787) Average loss so far: 2.765\n",
      "(Epoch 23, iter 700/787) Average loss so far: 2.758\n",
      "(Epoch 23, iter 750/787) Average loss so far: 2.746\n",
      "Average epoch loss: 2.744\n",
      "This epoch took 8.09567631483078 mins. Time remaining: 0.0 hrs 48.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.135296242577689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 603.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.051097938950738914, METEOR score: 0.20545257704474157\n",
      "Starting epoch 25/30, enc lr scheduler: [0.00010453658778440108], dec lr scheduler: [0.00010453658778440108]\n",
      "(Epoch 24, iter 50/787) Average loss so far: 2.748\n",
      "(Epoch 24, iter 100/787) Average loss so far: 2.726\n",
      "(Epoch 24, iter 150/787) Average loss so far: 2.731\n",
      "(Epoch 24, iter 200/787) Average loss so far: 2.757\n",
      "(Epoch 24, iter 250/787) Average loss so far: 2.718\n",
      "(Epoch 24, iter 300/787) Average loss so far: 2.734\n",
      "(Epoch 24, iter 350/787) Average loss so far: 2.749\n",
      "(Epoch 24, iter 400/787) Average loss so far: 2.745\n",
      "(Epoch 24, iter 450/787) Average loss so far: 2.738\n",
      "(Epoch 24, iter 500/787) Average loss so far: 2.742\n",
      "(Epoch 24, iter 550/787) Average loss so far: 2.754\n",
      "(Epoch 24, iter 600/787) Average loss so far: 2.740\n",
      "(Epoch 24, iter 650/787) Average loss so far: 2.746\n",
      "(Epoch 24, iter 700/787) Average loss so far: 2.731\n",
      "(Epoch 24, iter 750/787) Average loss so far: 2.722\n",
      "Average epoch loss: 2.738\n",
      "This epoch took 8.16293386220932 mins. Time remaining: 0.0 hrs 40.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1331892013549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.39it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 597.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05338881169928626, METEOR score: 0.20659685260841154\n",
      "Starting epoch 26/30, enc lr scheduler: [7.631742512670285e-05], dec lr scheduler: [7.631742512670285e-05]\n",
      "(Epoch 25, iter 50/787) Average loss so far: 2.725\n",
      "(Epoch 25, iter 100/787) Average loss so far: 2.720\n",
      "(Epoch 25, iter 150/787) Average loss so far: 2.750\n",
      "(Epoch 25, iter 200/787) Average loss so far: 2.731\n",
      "(Epoch 25, iter 250/787) Average loss so far: 2.725\n",
      "(Epoch 25, iter 300/787) Average loss so far: 2.717\n",
      "(Epoch 25, iter 350/787) Average loss so far: 2.742\n",
      "(Epoch 25, iter 400/787) Average loss so far: 2.735\n",
      "(Epoch 25, iter 450/787) Average loss so far: 2.736\n",
      "(Epoch 25, iter 500/787) Average loss so far: 2.735\n",
      "(Epoch 25, iter 550/787) Average loss so far: 2.738\n",
      "(Epoch 25, iter 600/787) Average loss so far: 2.737\n",
      "(Epoch 25, iter 650/787) Average loss so far: 2.732\n",
      "(Epoch 25, iter 700/787) Average loss so far: 2.749\n",
      "(Epoch 25, iter 750/787) Average loss so far: 2.738\n",
      "Average epoch loss: 2.734\n",
      "This epoch took 8.112463406721751 mins. Time remaining: 0.0 hrs 32.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1343512194497243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 591.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05337146516245549, METEOR score: 0.20767647224625604\n",
      "Starting epoch 27/30, enc lr scheduler: [5.279499846691252e-05], dec lr scheduler: [5.279499846691252e-05]\n",
      "(Epoch 26, iter 50/787) Average loss so far: 2.724\n",
      "(Epoch 26, iter 100/787) Average loss so far: 2.720\n",
      "(Epoch 26, iter 150/787) Average loss so far: 2.706\n",
      "(Epoch 26, iter 200/787) Average loss so far: 2.737\n",
      "(Epoch 26, iter 250/787) Average loss so far: 2.737\n",
      "(Epoch 26, iter 300/787) Average loss so far: 2.726\n",
      "(Epoch 26, iter 350/787) Average loss so far: 2.739\n",
      "(Epoch 26, iter 400/787) Average loss so far: 2.741\n",
      "(Epoch 26, iter 450/787) Average loss so far: 2.735\n",
      "(Epoch 26, iter 500/787) Average loss so far: 2.735\n",
      "(Epoch 26, iter 550/787) Average loss so far: 2.734\n",
      "(Epoch 26, iter 600/787) Average loss so far: 2.735\n",
      "(Epoch 26, iter 650/787) Average loss so far: 2.728\n",
      "(Epoch 26, iter 700/787) Average loss so far: 2.725\n",
      "(Epoch 26, iter 750/787) Average loss so far: 2.726\n",
      "Average epoch loss: 2.730\n",
      "This epoch took 8.101639938354491 mins. Time remaining: 0.0 hrs 24.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1328334467751637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 581.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05541456263767681, METEOR score: 0.21179274372666657\n",
      "Starting epoch 28/30, enc lr scheduler: [3.4227024433899005e-05], dec lr scheduler: [3.4227024433899005e-05]\n",
      "(Epoch 27, iter 50/787) Average loss so far: 2.747\n",
      "(Epoch 27, iter 100/787) Average loss so far: 2.725\n",
      "(Epoch 27, iter 150/787) Average loss so far: 2.725\n",
      "(Epoch 27, iter 200/787) Average loss so far: 2.721\n",
      "(Epoch 27, iter 250/787) Average loss so far: 2.731\n",
      "(Epoch 27, iter 300/787) Average loss so far: 2.723\n",
      "(Epoch 27, iter 350/787) Average loss so far: 2.726\n",
      "(Epoch 27, iter 400/787) Average loss so far: 2.718\n",
      "(Epoch 27, iter 450/787) Average loss so far: 2.734\n",
      "(Epoch 27, iter 500/787) Average loss so far: 2.741\n",
      "(Epoch 27, iter 550/787) Average loss so far: 2.731\n",
      "(Epoch 27, iter 600/787) Average loss so far: 2.729\n",
      "(Epoch 27, iter 650/787) Average loss so far: 2.714\n",
      "(Epoch 27, iter 700/787) Average loss so far: 2.731\n",
      "(Epoch 27, iter 750/787) Average loss so far: 2.726\n",
      "Average epoch loss: 2.728\n",
      "This epoch took 8.081586301326752 mins. Time remaining: 0.0 hrs 16.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1330018043518066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.40it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 605.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05391199400984629, METEOR score: 0.20699247679832458\n",
      "Starting epoch 29/30, enc lr scheduler: [2.0816937636766188e-05], dec lr scheduler: [2.0816937636766188e-05]\n",
      "(Epoch 28, iter 50/787) Average loss so far: 2.733\n",
      "(Epoch 28, iter 100/787) Average loss so far: 2.710\n",
      "(Epoch 28, iter 150/787) Average loss so far: 2.729\n",
      "(Epoch 28, iter 200/787) Average loss so far: 2.698\n",
      "(Epoch 28, iter 250/787) Average loss so far: 2.733\n",
      "(Epoch 28, iter 300/787) Average loss so far: 2.728\n",
      "(Epoch 28, iter 350/787) Average loss so far: 2.734\n",
      "(Epoch 28, iter 400/787) Average loss so far: 2.728\n",
      "(Epoch 28, iter 450/787) Average loss so far: 2.732\n",
      "(Epoch 28, iter 500/787) Average loss so far: 2.728\n",
      "(Epoch 28, iter 550/787) Average loss so far: 2.732\n",
      "(Epoch 28, iter 600/787) Average loss so far: 2.721\n",
      "(Epoch 28, iter 650/787) Average loss so far: 2.731\n",
      "(Epoch 28, iter 700/787) Average loss so far: 2.728\n",
      "(Epoch 28, iter 750/787) Average loss so far: 2.726\n",
      "Average epoch loss: 2.726\n",
      "This epoch took 7.988488773504893 mins. Time remaining: 0.0 hrs 7.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.132430451256888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.30it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 598.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05513984026373013, METEOR score: 0.2094436932678814\n",
      "Starting epoch 30/30, enc lr scheduler: [1.2711661792704668e-05], dec lr scheduler: [1.2711661792704668e-05]\n",
      "(Epoch 29, iter 50/787) Average loss so far: 2.732\n",
      "(Epoch 29, iter 100/787) Average loss so far: 2.722\n",
      "(Epoch 29, iter 150/787) Average loss so far: 2.715\n",
      "(Epoch 29, iter 200/787) Average loss so far: 2.739\n",
      "(Epoch 29, iter 250/787) Average loss so far: 2.727\n",
      "(Epoch 29, iter 300/787) Average loss so far: 2.729\n",
      "(Epoch 29, iter 350/787) Average loss so far: 2.730\n",
      "(Epoch 29, iter 400/787) Average loss so far: 2.714\n",
      "(Epoch 29, iter 450/787) Average loss so far: 2.725\n",
      "(Epoch 29, iter 500/787) Average loss so far: 2.711\n",
      "(Epoch 29, iter 550/787) Average loss so far: 2.733\n",
      "(Epoch 29, iter 600/787) Average loss so far: 2.737\n",
      "(Epoch 29, iter 650/787) Average loss so far: 2.723\n",
      "(Epoch 29, iter 700/787) Average loss so far: 2.724\n",
      "(Epoch 29, iter 750/787) Average loss so far: 2.724\n",
      "Average epoch loss: 2.725\n",
      "This epoch took 7.996612278620402 mins. Time remaining: 0.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1326404299054826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.39it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 595.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.055078340546709854, METEOR score: 0.20826842611097787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_lr=1e-3\n",
    "min_lr = 1e-5\n",
    "n_epochs = 30\n",
    "batch_size=128\n",
    "encoder_attn_optimizer = optim.Adam(encoder_attn.parameters(), lr=initial_lr)\n",
    "decoder_attn_optimizer = optim.Adam(decoder_attn.parameters(), lr=initial_lr)\n",
    "# enc_attn_scheduler = CosineAnnealingLR(encoder_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "# dec_attn_scheduler = CosineAnnealingLR(decoder_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "enc_attn_scheduler = CosineAnnealingLR(encoder_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "dec_attn_scheduler = CosineAnnealingLR(decoder_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "identifier=\"attn_adam_without_intermediate_tags_wd0_lr1e-3\"\n",
    "\n",
    "attn_epoch_losses, attn_val_epoch_losses, attn_log = train(\n",
    "    encoder_attn, decoder_attn, encoder_attn_optimizer, decoder_attn_optimizer, train_ds, \n",
    "    n_epochs=n_epochs, vocab=vocab, decoder_mode=\"attention\", batch_size=batch_size, \n",
    "    enc_lr_scheduler=enc_attn_scheduler, dec_lr_scheduler=dec_attn_scheduler, \n",
    "    dev_ds_val_loss = dev_ds_val_loss, dev_ds_val_met=dev_ds_val_met, identifier=identifier,\n",
    "    verbose_iter_interval=50)\n",
    "\n",
    "save_log(identifier, attn_log, encoder_attn_optimizer, decoder_attn_optimizer, \n",
    "         enc_attn_scheduler, dec_attn_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Extension 1 (GLoVE pretrained embeddings)\n",
    "\n",
    "Please download [pretrained embeddings](https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip) and extract the contents to the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrained_embedding_dict(emb_filepath, **kwargs):\n",
    "    ## build embedding dictionary\n",
    "    pretrained_embedding_dict = dict()\n",
    "    with open(emb_filepath, \"r\", **kwargs) as f:\n",
    "        for line in f:\n",
    "            wi, embi = line.rstrip().split(\" \", 1)\n",
    "            pretrained_embedding_dict[wi] = torch.from_numpy(np.fromstring(embi, sep=\" \"))\n",
    "    return pretrained_embedding_dict\n",
    "\n",
    "pretrained_embedding_dict = create_pretrained_embedding_dict(\"./glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rng()\n",
    "embedding_size=300\n",
    "encoder_pretrained_embed = EncoderRNN(\n",
    "    input_size=vocab.n_unique_words, embedding_size=embedding_size, hidden_size=HIDDEN_SIZE, \n",
    "    padding_value=vocab.word2index(PAD_WORD), pretrained_embedding_dict=pretrained_embedding_dict, \n",
    "    vocab=vocab).to(DEVICE)\n",
    "# in the training script, decoder is always fed a non-end token and thus never needs to generate padding\n",
    "# also it should never generate \"<UNKNOWN>\"\n",
    "decoder_pretrained_embed = AttnDecoderRNN(\n",
    "    embedding_size=embedding_size,hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-1,\n",
    "    padding_val=vocab.word2index(PAD_WORD), dropout=DROPOUT, global_max_ing_len=MAX_INGR_LEN,\n",
    "    pretrained_embedding_dict=pretrained_embedding_dict, vocab=vocab).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30, enc lr scheduler: [0.001], dec lr scheduler: [0.001]\n",
      "(Epoch 0, iter 50/787) Average loss so far: 6.968\n",
      "(Epoch 0, iter 100/787) Average loss so far: 6.040\n",
      "(Epoch 0, iter 150/787) Average loss so far: 5.995\n",
      "(Epoch 0, iter 200/787) Average loss so far: 5.955\n",
      "(Epoch 0, iter 250/787) Average loss so far: 5.910\n",
      "(Epoch 0, iter 300/787) Average loss so far: 5.859\n",
      "(Epoch 0, iter 350/787) Average loss so far: 5.839\n",
      "(Epoch 0, iter 400/787) Average loss so far: 5.759\n",
      "(Epoch 0, iter 450/787) Average loss so far: 5.627\n",
      "(Epoch 0, iter 500/787) Average loss so far: 5.404\n",
      "(Epoch 0, iter 550/787) Average loss so far: 5.209\n",
      "(Epoch 0, iter 600/787) Average loss so far: 5.001\n",
      "(Epoch 0, iter 650/787) Average loss so far: 4.851\n",
      "(Epoch 0, iter 700/787) Average loss so far: 4.692\n",
      "(Epoch 0, iter 750/787) Average loss so far: 4.582\n",
      "Average epoch loss: 5.528\n",
      "This epoch took 8.08877116839091 mins. Time remaining: 3.0 hrs 54.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 4.4685172353472025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.12s/it]\n",
      "100%|██████████| 793/793 [00:09<00:00, 87.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0031624657072353694, METEOR score: 0.0796926100408187\n",
      "Starting epoch 2/30, enc lr scheduler: [0.0009972883382072953], dec lr scheduler: [0.0009972883382072953]\n",
      "(Epoch 1, iter 50/787) Average loss so far: 4.410\n",
      "(Epoch 1, iter 100/787) Average loss so far: 4.295\n",
      "(Epoch 1, iter 150/787) Average loss so far: 4.269\n",
      "(Epoch 1, iter 200/787) Average loss so far: 4.187\n",
      "(Epoch 1, iter 250/787) Average loss so far: 4.128\n",
      "(Epoch 1, iter 300/787) Average loss so far: 4.080\n",
      "(Epoch 1, iter 350/787) Average loss so far: 4.027\n",
      "(Epoch 1, iter 400/787) Average loss so far: 3.997\n",
      "(Epoch 1, iter 450/787) Average loss so far: 3.949\n",
      "(Epoch 1, iter 500/787) Average loss so far: 3.910\n",
      "(Epoch 1, iter 550/787) Average loss so far: 3.871\n",
      "(Epoch 1, iter 600/787) Average loss so far: 3.844\n",
      "(Epoch 1, iter 650/787) Average loss so far: 3.814\n",
      "(Epoch 1, iter 700/787) Average loss so far: 3.778\n",
      "(Epoch 1, iter 750/787) Average loss so far: 3.759\n",
      "Average epoch loss: 4.009\n",
      "This epoch took 8.075345408916473 mins. Time remaining: 3.0 hrs 46.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.7725216320582797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.10it/s]\n",
      "100%|██████████| 793/793 [00:05<00:00, 144.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.008172939091770137, METEOR score: 0.1373603160673997\n",
      "Starting epoch 3/30, enc lr scheduler: [0.0009891830623632338], dec lr scheduler: [0.0009891830623632338]\n",
      "(Epoch 2, iter 50/787) Average loss so far: 3.698\n",
      "(Epoch 2, iter 100/787) Average loss so far: 3.680\n",
      "(Epoch 2, iter 150/787) Average loss so far: 3.658\n",
      "(Epoch 2, iter 200/787) Average loss so far: 3.622\n",
      "(Epoch 2, iter 250/787) Average loss so far: 3.602\n",
      "(Epoch 2, iter 300/787) Average loss so far: 3.609\n",
      "(Epoch 2, iter 350/787) Average loss so far: 3.561\n",
      "(Epoch 2, iter 400/787) Average loss so far: 3.547\n",
      "(Epoch 2, iter 450/787) Average loss so far: 3.528\n",
      "(Epoch 2, iter 500/787) Average loss so far: 3.528\n",
      "(Epoch 2, iter 550/787) Average loss so far: 3.529\n",
      "(Epoch 2, iter 600/787) Average loss so far: 3.514\n",
      "(Epoch 2, iter 650/787) Average loss so far: 3.481\n",
      "(Epoch 2, iter 700/787) Average loss so far: 3.483\n",
      "(Epoch 2, iter 750/787) Average loss so far: 3.445\n",
      "Average epoch loss: 3.560\n",
      "This epoch took 8.12299534479777 mins. Time remaining: 3.0 hrs 39.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.5144453048706055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.57it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 259.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.015654428117596996, METEOR score: 0.15914722051182856\n",
      "Starting epoch 4/30, enc lr scheduler: [0.0009757729755661011], dec lr scheduler: [0.0009757729755661011]\n",
      "(Epoch 3, iter 50/787) Average loss so far: 3.431\n",
      "(Epoch 3, iter 100/787) Average loss so far: 3.411\n",
      "(Epoch 3, iter 150/787) Average loss so far: 3.391\n",
      "(Epoch 3, iter 200/787) Average loss so far: 3.380\n",
      "(Epoch 3, iter 250/787) Average loss so far: 3.386\n",
      "(Epoch 3, iter 300/787) Average loss so far: 3.376\n",
      "(Epoch 3, iter 350/787) Average loss so far: 3.366\n",
      "(Epoch 3, iter 400/787) Average loss so far: 3.343\n",
      "(Epoch 3, iter 450/787) Average loss so far: 3.333\n",
      "(Epoch 3, iter 500/787) Average loss so far: 3.326\n",
      "(Epoch 3, iter 550/787) Average loss so far: 3.330\n",
      "(Epoch 3, iter 600/787) Average loss so far: 3.317\n",
      "(Epoch 3, iter 650/787) Average loss so far: 3.302\n",
      "(Epoch 3, iter 700/787) Average loss so far: 3.296\n",
      "(Epoch 3, iter 750/787) Average loss so far: 3.307\n",
      "Average epoch loss: 3.351\n",
      "This epoch took 8.083766424655915 mins. Time remaining: 3.0 hrs 30.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.3842404569898332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.81it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 321.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.021776681776078183, METEOR score: 0.1731301206546595\n",
      "Starting epoch 5/30, enc lr scheduler: [0.0009572050015330874], dec lr scheduler: [0.0009572050015330874]\n",
      "(Epoch 4, iter 50/787) Average loss so far: 3.269\n",
      "(Epoch 4, iter 100/787) Average loss so far: 3.256\n",
      "(Epoch 4, iter 150/787) Average loss so far: 3.247\n",
      "(Epoch 4, iter 200/787) Average loss so far: 3.260\n",
      "(Epoch 4, iter 250/787) Average loss so far: 3.232\n",
      "(Epoch 4, iter 300/787) Average loss so far: 3.226\n",
      "(Epoch 4, iter 350/787) Average loss so far: 3.227\n",
      "(Epoch 4, iter 400/787) Average loss so far: 3.210\n",
      "(Epoch 4, iter 450/787) Average loss so far: 3.223\n",
      "(Epoch 4, iter 500/787) Average loss so far: 3.208\n",
      "(Epoch 4, iter 550/787) Average loss so far: 3.213\n",
      "(Epoch 4, iter 600/787) Average loss so far: 3.201\n",
      "(Epoch 4, iter 650/787) Average loss so far: 3.194\n",
      "(Epoch 4, iter 700/787) Average loss so far: 3.198\n",
      "(Epoch 4, iter 750/787) Average loss so far: 3.187\n",
      "Average epoch loss: 3.221\n",
      "This epoch took 8.08472265402476 mins. Time remaining: 3.0 hrs 22.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.299443074635097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.91it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 371.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.029468622995135987, METEOR score: 0.18938801124897647\n",
      "Starting epoch 6/30, enc lr scheduler: [0.0009336825748732973], dec lr scheduler: [0.0009336825748732973]\n",
      "(Epoch 5, iter 50/787) Average loss so far: 3.146\n",
      "(Epoch 5, iter 100/787) Average loss so far: 3.159\n",
      "(Epoch 5, iter 150/787) Average loss so far: 3.138\n",
      "(Epoch 5, iter 200/787) Average loss so far: 3.145\n",
      "(Epoch 5, iter 250/787) Average loss so far: 3.128\n",
      "(Epoch 5, iter 300/787) Average loss so far: 3.140\n",
      "(Epoch 5, iter 350/787) Average loss so far: 3.138\n",
      "(Epoch 5, iter 400/787) Average loss so far: 3.138\n",
      "(Epoch 5, iter 450/787) Average loss so far: 3.124\n",
      "(Epoch 5, iter 500/787) Average loss so far: 3.125\n",
      "(Epoch 5, iter 550/787) Average loss so far: 3.129\n",
      "(Epoch 5, iter 600/787) Average loss so far: 3.115\n",
      "(Epoch 5, iter 650/787) Average loss so far: 3.108\n",
      "(Epoch 5, iter 700/787) Average loss so far: 3.107\n",
      "(Epoch 5, iter 750/787) Average loss so far: 3.096\n",
      "Average epoch loss: 3.128\n",
      "This epoch took 8.069037703673045 mins. Time remaining: 3.0 hrs 13.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.240325791495187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.98it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 407.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.03311247830068684, METEOR score: 0.1885298967343268\n",
      "Starting epoch 7/30, enc lr scheduler: [0.0009054634122155991], dec lr scheduler: [0.0009054634122155991]\n",
      "(Epoch 6, iter 50/787) Average loss so far: 3.083\n",
      "(Epoch 6, iter 100/787) Average loss so far: 3.079\n",
      "(Epoch 6, iter 150/787) Average loss so far: 3.076\n",
      "(Epoch 6, iter 200/787) Average loss so far: 3.064\n",
      "(Epoch 6, iter 250/787) Average loss so far: 3.057\n",
      "(Epoch 6, iter 300/787) Average loss so far: 3.059\n",
      "(Epoch 6, iter 350/787) Average loss so far: 3.053\n",
      "(Epoch 6, iter 400/787) Average loss so far: 3.059\n",
      "(Epoch 6, iter 450/787) Average loss so far: 3.061\n",
      "(Epoch 6, iter 500/787) Average loss so far: 3.048\n",
      "(Epoch 6, iter 550/787) Average loss so far: 3.040\n",
      "(Epoch 6, iter 600/787) Average loss so far: 3.061\n",
      "(Epoch 6, iter 650/787) Average loss so far: 3.037\n",
      "(Epoch 6, iter 700/787) Average loss so far: 3.044\n",
      "(Epoch 6, iter 750/787) Average loss so far: 3.034\n",
      "Average epoch loss: 3.056\n",
      "This epoch took 8.02225666443507 mins. Time remaining: 3.0 hrs 4.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.198171922138759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.87it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 363.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.029020290042606374, METEOR score: 0.18989639255673424\n",
      "Starting epoch 8/30, enc lr scheduler: [0.0008728566886113102], dec lr scheduler: [0.0008728566886113102]\n",
      "(Epoch 7, iter 50/787) Average loss so far: 3.021\n",
      "(Epoch 7, iter 100/787) Average loss so far: 3.015\n",
      "(Epoch 7, iter 150/787) Average loss so far: 3.023\n",
      "(Epoch 7, iter 200/787) Average loss so far: 3.006\n",
      "(Epoch 7, iter 250/787) Average loss so far: 3.001\n",
      "(Epoch 7, iter 300/787) Average loss so far: 3.006\n",
      "(Epoch 7, iter 350/787) Average loss so far: 3.002\n",
      "(Epoch 7, iter 400/787) Average loss so far: 2.992\n",
      "(Epoch 7, iter 450/787) Average loss so far: 3.000\n",
      "(Epoch 7, iter 500/787) Average loss so far: 2.984\n",
      "(Epoch 7, iter 550/787) Average loss so far: 2.998\n",
      "(Epoch 7, iter 600/787) Average loss so far: 2.974\n",
      "(Epoch 7, iter 650/787) Average loss so far: 2.990\n",
      "(Epoch 7, iter 700/787) Average loss so far: 2.993\n",
      "(Epoch 7, iter 750/787) Average loss so far: 2.989\n",
      "Average epoch loss: 2.999\n",
      "This epoch took 8.018091865380605 mins. Time remaining: 2.0 hrs 56.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1683931010110036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.00it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 458.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.040572019424333215, METEOR score: 0.20380746462583008\n",
      "Starting epoch 9/30, enc lr scheduler: [0.0008362196501476349], dec lr scheduler: [0.0008362196501476349]\n",
      "(Epoch 8, iter 50/787) Average loss so far: 2.965\n",
      "(Epoch 8, iter 100/787) Average loss so far: 2.963\n",
      "(Epoch 8, iter 150/787) Average loss so far: 2.964\n",
      "(Epoch 8, iter 200/787) Average loss so far: 2.969\n",
      "(Epoch 8, iter 250/787) Average loss so far: 2.949\n",
      "(Epoch 8, iter 300/787) Average loss so far: 2.951\n",
      "(Epoch 8, iter 350/787) Average loss so far: 2.958\n",
      "(Epoch 8, iter 400/787) Average loss so far: 2.944\n",
      "(Epoch 8, iter 450/787) Average loss so far: 2.949\n",
      "(Epoch 8, iter 500/787) Average loss so far: 2.945\n",
      "(Epoch 8, iter 550/787) Average loss so far: 2.958\n",
      "(Epoch 8, iter 600/787) Average loss so far: 2.933\n",
      "(Epoch 8, iter 650/787) Average loss so far: 2.937\n",
      "(Epoch 8, iter 700/787) Average loss so far: 2.957\n",
      "(Epoch 8, iter 750/787) Average loss so far: 2.939\n",
      "Average epoch loss: 2.951\n",
      "This epoch took 8.068367584546406 mins. Time remaining: 2.0 hrs 49.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.145275660923549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.00it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 420.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.035724116920881344, METEOR score: 0.1954857121917429\n",
      "Starting epoch 10/30, enc lr scheduler: [0.0007959536998847742], dec lr scheduler: [0.0007959536998847742]\n",
      "(Epoch 9, iter 50/787) Average loss so far: 2.933\n",
      "(Epoch 9, iter 100/787) Average loss so far: 2.911\n",
      "(Epoch 9, iter 150/787) Average loss so far: 2.903\n",
      "(Epoch 9, iter 200/787) Average loss so far: 2.910\n",
      "(Epoch 9, iter 250/787) Average loss so far: 2.920\n",
      "(Epoch 9, iter 300/787) Average loss so far: 2.914\n",
      "(Epoch 9, iter 350/787) Average loss so far: 2.922\n",
      "(Epoch 9, iter 400/787) Average loss so far: 2.912\n",
      "(Epoch 9, iter 450/787) Average loss so far: 2.927\n",
      "(Epoch 9, iter 500/787) Average loss so far: 2.903\n",
      "(Epoch 9, iter 550/787) Average loss so far: 2.909\n",
      "(Epoch 9, iter 600/787) Average loss so far: 2.892\n",
      "(Epoch 9, iter 650/787) Average loss so far: 2.910\n",
      "(Epoch 9, iter 700/787) Average loss so far: 2.914\n",
      "(Epoch 9, iter 750/787) Average loss so far: 2.891\n",
      "Average epoch loss: 2.911\n",
      "This epoch took 8.082320443789165 mins. Time remaining: 2.0 hrs 41.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.127824068069458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.11it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 480.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.039821027333439805, METEOR score: 0.1971742265366046\n",
      "Starting epoch 11/30, enc lr scheduler: [0.0007525], dec lr scheduler: [0.0007525]\n",
      "(Epoch 10, iter 50/787) Average loss so far: 2.885\n",
      "(Epoch 10, iter 100/787) Average loss so far: 2.880\n",
      "(Epoch 10, iter 150/787) Average loss so far: 2.865\n",
      "(Epoch 10, iter 200/787) Average loss so far: 2.880\n",
      "(Epoch 10, iter 250/787) Average loss so far: 2.870\n",
      "(Epoch 10, iter 300/787) Average loss so far: 2.883\n",
      "(Epoch 10, iter 350/787) Average loss so far: 2.875\n",
      "(Epoch 10, iter 400/787) Average loss so far: 2.885\n",
      "(Epoch 10, iter 450/787) Average loss so far: 2.871\n",
      "(Epoch 10, iter 500/787) Average loss so far: 2.883\n",
      "(Epoch 10, iter 550/787) Average loss so far: 2.876\n",
      "(Epoch 10, iter 600/787) Average loss so far: 2.870\n",
      "(Epoch 10, iter 650/787) Average loss so far: 2.877\n",
      "(Epoch 10, iter 700/787) Average loss so far: 2.873\n",
      "(Epoch 10, iter 750/787) Average loss so far: 2.885\n",
      "Average epoch loss: 2.877\n",
      "This epoch took 8.075558908780415 mins. Time remaining: 2.0 hrs 33.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.111717598778861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.07it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 485.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04188177528685199, METEOR score: 0.20008110559374\n",
      "Starting epoch 12/30, enc lr scheduler: [0.0007063346383225212], dec lr scheduler: [0.0007063346383225212]\n",
      "(Epoch 11, iter 50/787) Average loss so far: 2.845\n",
      "(Epoch 11, iter 100/787) Average loss so far: 2.858\n",
      "(Epoch 11, iter 150/787) Average loss so far: 2.841\n",
      "(Epoch 11, iter 200/787) Average loss so far: 2.848\n",
      "(Epoch 11, iter 250/787) Average loss so far: 2.858\n",
      "(Epoch 11, iter 300/787) Average loss so far: 2.844\n",
      "(Epoch 11, iter 350/787) Average loss so far: 2.851\n",
      "(Epoch 11, iter 400/787) Average loss so far: 2.857\n",
      "(Epoch 11, iter 450/787) Average loss so far: 2.842\n",
      "(Epoch 11, iter 500/787) Average loss so far: 2.851\n",
      "(Epoch 11, iter 550/787) Average loss so far: 2.847\n",
      "(Epoch 11, iter 600/787) Average loss so far: 2.832\n",
      "(Epoch 11, iter 650/787) Average loss so far: 2.844\n",
      "(Epoch 11, iter 700/787) Average loss so far: 2.852\n",
      "(Epoch 11, iter 750/787) Average loss so far: 2.860\n",
      "Average epoch loss: 2.848\n",
      "This epoch took 8.083603068192799 mins. Time remaining: 2.0 hrs 25.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0999631881713867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.11it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 503.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.044384897292243625, METEOR score: 0.20706484658028232\n",
      "Starting epoch 13/30, enc lr scheduler: [0.000657963412215599], dec lr scheduler: [0.000657963412215599]\n",
      "(Epoch 12, iter 50/787) Average loss so far: 2.819\n",
      "(Epoch 12, iter 100/787) Average loss so far: 2.815\n",
      "(Epoch 12, iter 150/787) Average loss so far: 2.809\n",
      "(Epoch 12, iter 200/787) Average loss so far: 2.823\n",
      "(Epoch 12, iter 250/787) Average loss so far: 2.823\n",
      "(Epoch 12, iter 300/787) Average loss so far: 2.830\n",
      "(Epoch 12, iter 350/787) Average loss so far: 2.808\n",
      "(Epoch 12, iter 400/787) Average loss so far: 2.828\n",
      "(Epoch 12, iter 450/787) Average loss so far: 2.822\n",
      "(Epoch 12, iter 500/787) Average loss so far: 2.823\n",
      "(Epoch 12, iter 550/787) Average loss so far: 2.818\n",
      "(Epoch 12, iter 600/787) Average loss so far: 2.833\n",
      "(Epoch 12, iter 650/787) Average loss so far: 2.837\n",
      "(Epoch 12, iter 700/787) Average loss so far: 2.817\n",
      "(Epoch 12, iter 750/787) Average loss so far: 2.824\n",
      "Average epoch loss: 2.821\n",
      "This epoch took 8.0355042497317 mins. Time remaining: 2.0 hrs 16.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.087609222957066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.05it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 459.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.041033156261249384, METEOR score: 0.20340139642244925\n",
      "Starting epoch 14/30, enc lr scheduler: [0.0006079162869547909], dec lr scheduler: [0.0006079162869547909]\n",
      "(Epoch 13, iter 50/787) Average loss so far: 2.810\n",
      "(Epoch 13, iter 100/787) Average loss so far: 2.799\n",
      "(Epoch 13, iter 150/787) Average loss so far: 2.801\n",
      "(Epoch 13, iter 200/787) Average loss so far: 2.796\n",
      "(Epoch 13, iter 250/787) Average loss so far: 2.825\n",
      "(Epoch 13, iter 300/787) Average loss so far: 2.793\n",
      "(Epoch 13, iter 350/787) Average loss so far: 2.795\n",
      "(Epoch 13, iter 400/787) Average loss so far: 2.803\n",
      "(Epoch 13, iter 450/787) Average loss so far: 2.799\n",
      "(Epoch 13, iter 500/787) Average loss so far: 2.798\n",
      "(Epoch 13, iter 550/787) Average loss so far: 2.785\n",
      "(Epoch 13, iter 600/787) Average loss so far: 2.788\n",
      "(Epoch 13, iter 650/787) Average loss so far: 2.808\n",
      "(Epoch 13, iter 700/787) Average loss so far: 2.801\n",
      "(Epoch 13, iter 750/787) Average loss so far: 2.792\n",
      "Average epoch loss: 2.799\n",
      "This epoch took 8.045028154055277 mins. Time remaining: 2.0 hrs 8.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.080646344593593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.14it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 515.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.046692676994029854, METEOR score: 0.20559286007764238\n",
      "Starting epoch 15/30, enc lr scheduler: [0.0005567415893174886], dec lr scheduler: [0.0005567415893174886]\n",
      "(Epoch 14, iter 50/787) Average loss so far: 2.781\n",
      "(Epoch 14, iter 100/787) Average loss so far: 2.776\n",
      "(Epoch 14, iter 150/787) Average loss so far: 2.767\n",
      "(Epoch 14, iter 200/787) Average loss so far: 2.774\n",
      "(Epoch 14, iter 250/787) Average loss so far: 2.769\n",
      "(Epoch 14, iter 300/787) Average loss so far: 2.789\n",
      "(Epoch 14, iter 350/787) Average loss so far: 2.760\n",
      "(Epoch 14, iter 400/787) Average loss so far: 2.791\n",
      "(Epoch 14, iter 450/787) Average loss so far: 2.784\n",
      "(Epoch 14, iter 500/787) Average loss so far: 2.793\n",
      "(Epoch 14, iter 550/787) Average loss so far: 2.776\n",
      "(Epoch 14, iter 600/787) Average loss so far: 2.781\n",
      "(Epoch 14, iter 650/787) Average loss so far: 2.773\n",
      "(Epoch 14, iter 700/787) Average loss so far: 2.780\n",
      "(Epoch 14, iter 750/787) Average loss so far: 2.788\n",
      "Average epoch loss: 2.779\n",
      "This epoch took 8.125079703330993 mins. Time remaining: 2.0 hrs 1.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0746142183031355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.15it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 521.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.046943470589521766, METEOR score: 0.20379152039697576\n",
      "Starting epoch 16/30, enc lr scheduler: [0.0005050000000000002], dec lr scheduler: [0.0005050000000000002]\n",
      "(Epoch 15, iter 50/787) Average loss so far: 2.756\n",
      "(Epoch 15, iter 100/787) Average loss so far: 2.753\n",
      "(Epoch 15, iter 150/787) Average loss so far: 2.763\n",
      "(Epoch 15, iter 200/787) Average loss so far: 2.755\n",
      "(Epoch 15, iter 250/787) Average loss so far: 2.757\n",
      "(Epoch 15, iter 300/787) Average loss so far: 2.760\n",
      "(Epoch 15, iter 350/787) Average loss so far: 2.764\n",
      "(Epoch 15, iter 400/787) Average loss so far: 2.747\n",
      "(Epoch 15, iter 450/787) Average loss so far: 2.753\n",
      "(Epoch 15, iter 500/787) Average loss so far: 2.772\n",
      "(Epoch 15, iter 550/787) Average loss so far: 2.772\n",
      "(Epoch 15, iter 600/787) Average loss so far: 2.770\n",
      "(Epoch 15, iter 650/787) Average loss so far: 2.764\n",
      "(Epoch 15, iter 700/787) Average loss so far: 2.764\n",
      "(Epoch 15, iter 750/787) Average loss so far: 2.762\n",
      "Average epoch loss: 2.760\n",
      "This epoch took 8.08417743841807 mins. Time remaining: 1.0 hrs 53.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0693612098693848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.08it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 496.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04693823811822118, METEOR score: 0.21012783449843356\n",
      "Starting epoch 17/30, enc lr scheduler: [0.0004532584106825117], dec lr scheduler: [0.0004532584106825117]\n",
      "(Epoch 16, iter 50/787) Average loss so far: 2.741\n",
      "(Epoch 16, iter 100/787) Average loss so far: 2.739\n",
      "(Epoch 16, iter 150/787) Average loss so far: 2.747\n",
      "(Epoch 16, iter 200/787) Average loss so far: 2.731\n",
      "(Epoch 16, iter 250/787) Average loss so far: 2.741\n",
      "(Epoch 16, iter 300/787) Average loss so far: 2.748\n",
      "(Epoch 16, iter 350/787) Average loss so far: 2.753\n",
      "(Epoch 16, iter 400/787) Average loss so far: 2.756\n",
      "(Epoch 16, iter 450/787) Average loss so far: 2.745\n",
      "(Epoch 16, iter 500/787) Average loss so far: 2.757\n",
      "(Epoch 16, iter 550/787) Average loss so far: 2.734\n",
      "(Epoch 16, iter 600/787) Average loss so far: 2.740\n",
      "(Epoch 16, iter 650/787) Average loss so far: 2.744\n",
      "(Epoch 16, iter 700/787) Average loss so far: 2.728\n",
      "(Epoch 16, iter 750/787) Average loss so far: 2.755\n",
      "Average epoch loss: 2.745\n",
      "This epoch took 8.109484219551087 mins. Time remaining: 1.0 hrs 45.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.065413134438651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.03it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 503.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.048756397533905496, METEOR score: 0.21361782160791687\n",
      "Starting epoch 18/30, enc lr scheduler: [0.00040208371304520916], dec lr scheduler: [0.00040208371304520916]\n",
      "(Epoch 17, iter 50/787) Average loss so far: 2.730\n",
      "(Epoch 17, iter 100/787) Average loss so far: 2.725\n",
      "(Epoch 17, iter 150/787) Average loss so far: 2.735\n",
      "(Epoch 17, iter 200/787) Average loss so far: 2.726\n",
      "(Epoch 17, iter 250/787) Average loss so far: 2.714\n",
      "(Epoch 17, iter 300/787) Average loss so far: 2.742\n",
      "(Epoch 17, iter 350/787) Average loss so far: 2.721\n",
      "(Epoch 17, iter 400/787) Average loss so far: 2.716\n",
      "(Epoch 17, iter 450/787) Average loss so far: 2.738\n",
      "(Epoch 17, iter 500/787) Average loss so far: 2.729\n",
      "(Epoch 17, iter 550/787) Average loss so far: 2.727\n",
      "(Epoch 17, iter 600/787) Average loss so far: 2.739\n",
      "(Epoch 17, iter 650/787) Average loss so far: 2.738\n",
      "(Epoch 17, iter 700/787) Average loss so far: 2.740\n",
      "(Epoch 17, iter 750/787) Average loss so far: 2.741\n",
      "Average epoch loss: 2.731\n",
      "This epoch took 8.125742689768474 mins. Time remaining: 1.0 hrs 37.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.061034543173654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.17it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 541.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05130481997908665, METEOR score: 0.21268616360288597\n",
      "Starting epoch 19/30, enc lr scheduler: [0.00035203658778440114], dec lr scheduler: [0.00035203658778440114]\n",
      "(Epoch 18, iter 50/787) Average loss so far: 2.706\n",
      "(Epoch 18, iter 100/787) Average loss so far: 2.712\n",
      "(Epoch 18, iter 150/787) Average loss so far: 2.709\n",
      "(Epoch 18, iter 200/787) Average loss so far: 2.718\n",
      "(Epoch 18, iter 250/787) Average loss so far: 2.717\n",
      "(Epoch 18, iter 300/787) Average loss so far: 2.702\n",
      "(Epoch 18, iter 350/787) Average loss so far: 2.721\n",
      "(Epoch 18, iter 400/787) Average loss so far: 2.737\n",
      "(Epoch 18, iter 450/787) Average loss so far: 2.725\n",
      "(Epoch 18, iter 500/787) Average loss so far: 2.715\n",
      "(Epoch 18, iter 550/787) Average loss so far: 2.726\n",
      "(Epoch 18, iter 600/787) Average loss so far: 2.708\n",
      "(Epoch 18, iter 650/787) Average loss so far: 2.715\n",
      "(Epoch 18, iter 700/787) Average loss so far: 2.727\n",
      "(Epoch 18, iter 750/787) Average loss so far: 2.723\n",
      "Average epoch loss: 2.718\n",
      "This epoch took 8.125829188028971 mins. Time remaining: 1.0 hrs 29.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0552920273372104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.28it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 586.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05395021872522183, METEOR score: 0.21410343910120513\n",
      "Starting epoch 20/30, enc lr scheduler: [0.00030366536167747904], dec lr scheduler: [0.00030366536167747904]\n",
      "(Epoch 19, iter 50/787) Average loss so far: 2.709\n",
      "(Epoch 19, iter 100/787) Average loss so far: 2.710\n",
      "(Epoch 19, iter 150/787) Average loss so far: 2.699\n",
      "(Epoch 19, iter 200/787) Average loss so far: 2.694\n",
      "(Epoch 19, iter 250/787) Average loss so far: 2.694\n",
      "(Epoch 19, iter 300/787) Average loss so far: 2.711\n",
      "(Epoch 19, iter 350/787) Average loss so far: 2.704\n",
      "(Epoch 19, iter 400/787) Average loss so far: 2.708\n",
      "(Epoch 19, iter 450/787) Average loss so far: 2.699\n",
      "(Epoch 19, iter 500/787) Average loss so far: 2.716\n",
      "(Epoch 19, iter 550/787) Average loss so far: 2.701\n",
      "(Epoch 19, iter 600/787) Average loss so far: 2.707\n",
      "(Epoch 19, iter 650/787) Average loss so far: 2.717\n",
      "(Epoch 19, iter 700/787) Average loss so far: 2.700\n",
      "(Epoch 19, iter 750/787) Average loss so far: 2.728\n",
      "Average epoch loss: 2.707\n",
      "This epoch took 8.068328471978505 mins. Time remaining: 1.0 hrs 20.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0541302817208424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.45it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 657.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05167331114826218, METEOR score: 0.2028060241888733\n",
      "Starting epoch 21/30, enc lr scheduler: [0.00025750000000000013], dec lr scheduler: [0.00025750000000000013]\n",
      "(Epoch 20, iter 50/787) Average loss so far: 2.700\n",
      "(Epoch 20, iter 100/787) Average loss so far: 2.687\n",
      "(Epoch 20, iter 150/787) Average loss so far: 2.699\n",
      "(Epoch 20, iter 200/787) Average loss so far: 2.703\n",
      "(Epoch 20, iter 250/787) Average loss so far: 2.706\n",
      "(Epoch 20, iter 300/787) Average loss so far: 2.704\n",
      "(Epoch 20, iter 350/787) Average loss so far: 2.679\n",
      "(Epoch 20, iter 400/787) Average loss so far: 2.706\n",
      "(Epoch 20, iter 450/787) Average loss so far: 2.690\n",
      "(Epoch 20, iter 500/787) Average loss so far: 2.689\n",
      "(Epoch 20, iter 550/787) Average loss so far: 2.693\n",
      "(Epoch 20, iter 600/787) Average loss so far: 2.709\n",
      "(Epoch 20, iter 650/787) Average loss so far: 2.693\n",
      "(Epoch 20, iter 700/787) Average loss so far: 2.706\n",
      "(Epoch 20, iter 750/787) Average loss so far: 2.695\n",
      "Average epoch loss: 2.698\n",
      "This epoch took 7.947717535495758 mins. Time remaining: 1.0 hrs 11.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0529042993273054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.36it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 604.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05473522071477695, METEOR score: 0.2107675382802335\n",
      "Starting epoch 22/30, enc lr scheduler: [0.00021404630011522585], dec lr scheduler: [0.00021404630011522585]\n",
      "(Epoch 21, iter 50/787) Average loss so far: 2.690\n",
      "(Epoch 21, iter 100/787) Average loss so far: 2.674\n",
      "(Epoch 21, iter 150/787) Average loss so far: 2.676\n",
      "(Epoch 21, iter 200/787) Average loss so far: 2.707\n",
      "(Epoch 21, iter 250/787) Average loss so far: 2.681\n",
      "(Epoch 21, iter 300/787) Average loss so far: 2.691\n",
      "(Epoch 21, iter 350/787) Average loss so far: 2.691\n",
      "(Epoch 21, iter 400/787) Average loss so far: 2.695\n",
      "(Epoch 21, iter 450/787) Average loss so far: 2.690\n",
      "(Epoch 21, iter 500/787) Average loss so far: 2.681\n",
      "(Epoch 21, iter 550/787) Average loss so far: 2.690\n",
      "(Epoch 21, iter 600/787) Average loss so far: 2.704\n",
      "(Epoch 21, iter 650/787) Average loss so far: 2.679\n",
      "(Epoch 21, iter 700/787) Average loss so far: 2.699\n",
      "(Epoch 21, iter 750/787) Average loss so far: 2.675\n",
      "Average epoch loss: 2.689\n",
      "This epoch took 7.528370042641957 mins. Time remaining: 1.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0493842533656528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.28it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 541.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05105392764669949, METEOR score: 0.2156661550691742\n",
      "Starting epoch 23/30, enc lr scheduler: [0.00017378034985236535], dec lr scheduler: [0.00017378034985236535]\n",
      "(Epoch 22, iter 50/787) Average loss so far: 2.676\n",
      "(Epoch 22, iter 100/787) Average loss so far: 2.671\n",
      "(Epoch 22, iter 150/787) Average loss so far: 2.682\n",
      "(Epoch 22, iter 200/787) Average loss so far: 2.685\n",
      "(Epoch 22, iter 250/787) Average loss so far: 2.676\n",
      "(Epoch 22, iter 300/787) Average loss so far: 2.687\n",
      "(Epoch 22, iter 350/787) Average loss so far: 2.687\n",
      "(Epoch 22, iter 400/787) Average loss so far: 2.676\n",
      "(Epoch 22, iter 450/787) Average loss so far: 2.688\n",
      "(Epoch 22, iter 500/787) Average loss so far: 2.678\n",
      "(Epoch 22, iter 550/787) Average loss so far: 2.694\n",
      "(Epoch 22, iter 600/787) Average loss so far: 2.698\n",
      "(Epoch 22, iter 650/787) Average loss so far: 2.673\n",
      "(Epoch 22, iter 700/787) Average loss so far: 2.676\n",
      "(Epoch 22, iter 750/787) Average loss so far: 2.681\n",
      "Average epoch loss: 2.682\n",
      "This epoch took 7.5065172235171 mins. Time remaining: 0.0 hrs 52.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0472822529929027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.37it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 605.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05496028256787088, METEOR score: 0.21032837797650386\n",
      "Starting epoch 24/30, enc lr scheduler: [0.00013714331138868998], dec lr scheduler: [0.00013714331138868998]\n",
      "(Epoch 23, iter 50/787) Average loss so far: 2.669\n",
      "(Epoch 23, iter 100/787) Average loss so far: 2.674\n",
      "(Epoch 23, iter 150/787) Average loss so far: 2.658\n",
      "(Epoch 23, iter 200/787) Average loss so far: 2.672\n",
      "(Epoch 23, iter 250/787) Average loss so far: 2.679\n",
      "(Epoch 23, iter 300/787) Average loss so far: 2.678\n",
      "(Epoch 23, iter 350/787) Average loss so far: 2.670\n",
      "(Epoch 23, iter 400/787) Average loss so far: 2.677\n",
      "(Epoch 23, iter 450/787) Average loss so far: 2.673\n",
      "(Epoch 23, iter 500/787) Average loss so far: 2.668\n",
      "(Epoch 23, iter 550/787) Average loss so far: 2.670\n",
      "(Epoch 23, iter 600/787) Average loss so far: 2.674\n",
      "(Epoch 23, iter 650/787) Average loss so far: 2.698\n",
      "(Epoch 23, iter 700/787) Average loss so far: 2.690\n",
      "(Epoch 23, iter 750/787) Average loss so far: 2.678\n",
      "Average epoch loss: 2.676\n",
      "This epoch took 7.4704957167307535 mins. Time remaining: 0.0 hrs 44.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0462141377585277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 610.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05558312256170381, METEOR score: 0.21142443556612248\n",
      "Starting epoch 25/30, enc lr scheduler: [0.00010453658778440108], dec lr scheduler: [0.00010453658778440108]\n",
      "(Epoch 24, iter 50/787) Average loss so far: 2.682\n",
      "(Epoch 24, iter 100/787) Average loss so far: 2.661\n",
      "(Epoch 24, iter 150/787) Average loss so far: 2.664\n",
      "(Epoch 24, iter 200/787) Average loss so far: 2.688\n",
      "(Epoch 24, iter 250/787) Average loss so far: 2.652\n",
      "(Epoch 24, iter 300/787) Average loss so far: 2.666\n",
      "(Epoch 24, iter 350/787) Average loss so far: 2.681\n",
      "(Epoch 24, iter 400/787) Average loss so far: 2.678\n",
      "(Epoch 24, iter 450/787) Average loss so far: 2.669\n",
      "(Epoch 24, iter 500/787) Average loss so far: 2.676\n",
      "(Epoch 24, iter 550/787) Average loss so far: 2.685\n",
      "(Epoch 24, iter 600/787) Average loss so far: 2.672\n",
      "(Epoch 24, iter 650/787) Average loss so far: 2.678\n",
      "(Epoch 24, iter 700/787) Average loss so far: 2.666\n",
      "(Epoch 24, iter 750/787) Average loss so far: 2.655\n",
      "Average epoch loss: 2.671\n",
      "This epoch took 7.541735696792602 mins. Time remaining: 0.0 hrs 37.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0450666631971086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.32it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 580.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.054168369543141096, METEOR score: 0.2190973874735378\n",
      "Starting epoch 26/30, enc lr scheduler: [7.631742512670285e-05], dec lr scheduler: [7.631742512670285e-05]\n",
      "(Epoch 25, iter 50/787) Average loss so far: 2.660\n",
      "(Epoch 25, iter 100/787) Average loss so far: 2.655\n",
      "(Epoch 25, iter 150/787) Average loss so far: 2.682\n",
      "(Epoch 25, iter 200/787) Average loss so far: 2.663\n",
      "(Epoch 25, iter 250/787) Average loss so far: 2.658\n",
      "(Epoch 25, iter 300/787) Average loss so far: 2.653\n",
      "(Epoch 25, iter 350/787) Average loss so far: 2.674\n",
      "(Epoch 25, iter 400/787) Average loss so far: 2.667\n",
      "(Epoch 25, iter 450/787) Average loss so far: 2.669\n",
      "(Epoch 25, iter 500/787) Average loss so far: 2.668\n",
      "(Epoch 25, iter 550/787) Average loss so far: 2.671\n",
      "(Epoch 25, iter 600/787) Average loss so far: 2.666\n",
      "(Epoch 25, iter 650/787) Average loss so far: 2.666\n",
      "(Epoch 25, iter 700/787) Average loss so far: 2.679\n",
      "(Epoch 25, iter 750/787) Average loss so far: 2.669\n",
      "Average epoch loss: 2.667\n",
      "This epoch took 7.473872991402944 mins. Time remaining: 0.0 hrs 29.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0444539955684116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.53it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 609.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05549097705999941, METEOR score: 0.2134507586141872\n",
      "Starting epoch 27/30, enc lr scheduler: [5.279499846691252e-05], dec lr scheduler: [5.279499846691252e-05]\n",
      "(Epoch 26, iter 50/787) Average loss so far: 2.655\n",
      "(Epoch 26, iter 100/787) Average loss so far: 2.655\n",
      "(Epoch 26, iter 150/787) Average loss so far: 2.641\n",
      "(Epoch 26, iter 200/787) Average loss so far: 2.668\n",
      "(Epoch 26, iter 250/787) Average loss so far: 2.671\n",
      "(Epoch 26, iter 300/787) Average loss so far: 2.661\n",
      "(Epoch 26, iter 350/787) Average loss so far: 2.672\n",
      "(Epoch 26, iter 400/787) Average loss so far: 2.673\n",
      "(Epoch 26, iter 450/787) Average loss so far: 2.667\n",
      "(Epoch 26, iter 500/787) Average loss so far: 2.671\n",
      "(Epoch 26, iter 550/787) Average loss so far: 2.665\n",
      "(Epoch 26, iter 600/787) Average loss so far: 2.668\n",
      "(Epoch 26, iter 650/787) Average loss so far: 2.661\n",
      "(Epoch 26, iter 700/787) Average loss so far: 2.657\n",
      "(Epoch 26, iter 750/787) Average loss so far: 2.660\n",
      "Average epoch loss: 2.663\n",
      "This epoch took 7.426502378781636 mins. Time remaining: 0.0 hrs 22.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0439279760633196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.39it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 605.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05676168975713699, METEOR score: 0.2139917855970703\n",
      "Starting epoch 28/30, enc lr scheduler: [3.4227024433899005e-05], dec lr scheduler: [3.4227024433899005e-05]\n",
      "(Epoch 27, iter 50/787) Average loss so far: 2.679\n",
      "(Epoch 27, iter 100/787) Average loss so far: 2.660\n",
      "(Epoch 27, iter 150/787) Average loss so far: 2.659\n",
      "(Epoch 27, iter 200/787) Average loss so far: 2.654\n",
      "(Epoch 27, iter 250/787) Average loss so far: 2.664\n",
      "(Epoch 27, iter 300/787) Average loss so far: 2.655\n",
      "(Epoch 27, iter 350/787) Average loss so far: 2.660\n",
      "(Epoch 27, iter 400/787) Average loss so far: 2.650\n",
      "(Epoch 27, iter 450/787) Average loss so far: 2.669\n",
      "(Epoch 27, iter 500/787) Average loss so far: 2.670\n",
      "(Epoch 27, iter 550/787) Average loss so far: 2.664\n",
      "(Epoch 27, iter 600/787) Average loss so far: 2.660\n",
      "(Epoch 27, iter 650/787) Average loss so far: 2.650\n",
      "(Epoch 27, iter 700/787) Average loss so far: 2.664\n",
      "(Epoch 27, iter 750/787) Average loss so far: 2.661\n",
      "Average epoch loss: 2.661\n",
      "This epoch took 7.4591632843017575 mins. Time remaining: 0.0 hrs 14.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0432401725224087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 595.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05472410622862404, METEOR score: 0.2129614425943201\n",
      "Starting epoch 29/30, enc lr scheduler: [2.0816937636766188e-05], dec lr scheduler: [2.0816937636766188e-05]\n",
      "(Epoch 28, iter 50/787) Average loss so far: 2.666\n",
      "(Epoch 28, iter 100/787) Average loss so far: 2.647\n",
      "(Epoch 28, iter 150/787) Average loss so far: 2.662\n",
      "(Epoch 28, iter 200/787) Average loss so far: 2.633\n",
      "(Epoch 28, iter 250/787) Average loss so far: 2.664\n",
      "(Epoch 28, iter 300/787) Average loss so far: 2.664\n",
      "(Epoch 28, iter 350/787) Average loss so far: 2.668\n",
      "(Epoch 28, iter 400/787) Average loss so far: 2.659\n",
      "(Epoch 28, iter 450/787) Average loss so far: 2.665\n",
      "(Epoch 28, iter 500/787) Average loss so far: 2.660\n",
      "(Epoch 28, iter 550/787) Average loss so far: 2.663\n",
      "(Epoch 28, iter 600/787) Average loss so far: 2.655\n",
      "(Epoch 28, iter 650/787) Average loss so far: 2.662\n",
      "(Epoch 28, iter 700/787) Average loss so far: 2.662\n",
      "(Epoch 28, iter 750/787) Average loss so far: 2.661\n",
      "Average epoch loss: 2.660\n",
      "This epoch took 7.44647292693456 mins. Time remaining: 0.0 hrs 7.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0424865995134627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.34it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 588.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.054989968499987295, METEOR score: 0.21584912823420402\n",
      "Starting epoch 30/30, enc lr scheduler: [1.2711661792704668e-05], dec lr scheduler: [1.2711661792704668e-05]\n",
      "(Epoch 29, iter 50/787) Average loss so far: 2.667\n",
      "(Epoch 29, iter 100/787) Average loss so far: 2.655\n",
      "(Epoch 29, iter 150/787) Average loss so far: 2.648\n",
      "(Epoch 29, iter 200/787) Average loss so far: 2.672\n",
      "(Epoch 29, iter 250/787) Average loss so far: 2.658\n",
      "(Epoch 29, iter 300/787) Average loss so far: 2.662\n",
      "(Epoch 29, iter 350/787) Average loss so far: 2.664\n",
      "(Epoch 29, iter 400/787) Average loss so far: 2.649\n",
      "(Epoch 29, iter 450/787) Average loss so far: 2.657\n",
      "(Epoch 29, iter 500/787) Average loss so far: 2.646\n",
      "(Epoch 29, iter 550/787) Average loss so far: 2.667\n",
      "(Epoch 29, iter 600/787) Average loss so far: 2.670\n",
      "(Epoch 29, iter 650/787) Average loss so far: 2.655\n",
      "(Epoch 29, iter 700/787) Average loss so far: 2.656\n",
      "(Epoch 29, iter 750/787) Average loss so far: 2.661\n",
      "Average epoch loss: 2.658\n",
      "This epoch took 7.4700422565142315 mins. Time remaining: 0.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0425445352281844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.39it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 619.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.057802547829115924, METEOR score: 0.21431412239195574\n"
     ]
    }
   ],
   "source": [
    "initial_lr=1e-3\n",
    "min_lr = 1e-5\n",
    "n_epochs = 30\n",
    "batch_size=128\n",
    "encoder_pretrained_embed_optimizer = optim.Adam(encoder_pretrained_embed.parameters(), lr=initial_lr)\n",
    "decoder_pretrained_embed_optimizer = optim.Adam(decoder_pretrained_embed.parameters(), lr=initial_lr)\n",
    "# enc_scheduler = CosineAnnealingLR(encoder_pretrained_embed_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "# dec_scheduler = CosineAnnealingLR(decoder_pretrained_embed_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "enc_pretrained_embed_scheduler = CosineAnnealingLR(encoder_pretrained_embed_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "dec_pretrained_embed_scheduler = CosineAnnealingLR(decoder_pretrained_embed_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "identifier=\"pretrained_emb_attn_adam_without_intermediate_tags_wd0_lr1e-3\"\n",
    "\n",
    "pre_epoch_losses, pre_val_epoch_losses, pre_log = train(\n",
    "    encoder_pretrained_embed, decoder_pretrained_embed, encoder_pretrained_embed_optimizer, decoder_pretrained_embed_optimizer, \n",
    "    train_ds, n_epochs=n_epochs, vocab=vocab, decoder_mode=\"attention\", batch_size=batch_size, \n",
    "    enc_lr_scheduler=enc_pretrained_embed_scheduler, dec_lr_scheduler=dec_pretrained_embed_scheduler, \n",
    "    dev_ds_val_loss = dev_ds_val_loss, dev_ds_val_met=dev_ds_val_met, identifier=identifier,\n",
    "    verbose_iter_interval=50)\n",
    "\n",
    "save_log(identifier, pre_log, encoder_pretrained_embed_optimizer, decoder_pretrained_embed_optimizer, \n",
    "         enc_pretrained_embed_scheduler, dec_pretrained_embed_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Extension 2 (Multi-Layer Encoder-Decoder + Neurologic Decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Neurologic Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_for_k(x, k, dim=1):\n",
    "    dims = [1]*x.ndim\n",
    "    dims[dim] = k\n",
    "    return x.repeat(dims)\n",
    "\n",
    "def detect_negative_constraint(num_ks, curr_decoder_outs_shape, all_decoder_outs, neg_constraints):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        num_ks (int): number of hypothesis which have not ended\n",
    "        curr_decoder_outs_shape: shape of current decoder output [k, |V|-1]\n",
    "        all_decoder_outs (list): [k, |generation|]\n",
    "        neg_constraints (List[List[int]]): list of negative constraints, nested list because constraints can be multi-word\n",
    "    \"\"\"\n",
    "\n",
    "    # >1 if neg constraint satisfied, 0 otherwise\n",
    "    # >1 makes sense if multiple negative constraints are satisfied (yielding larger penalty)\n",
    "    neg_constraint_satisfied = torch.zeros(curr_decoder_outs_shape, device=DEVICE) # [k, |V|-1]\n",
    "\n",
    "    for ki in range(num_ks):\n",
    "        for neg_cons in neg_constraints:\n",
    "            neg_constraint_exists = True\n",
    "            neg_idx = neg_cons[-1]\n",
    "\n",
    "            if (len(neg_cons) - 1) > len(all_decoder_outs[ki]):\n",
    "                continue # i.e. neg_constraint_exists=False\n",
    "\n",
    "            # to check if a negative constraint is satisfied (irreversible unsatisfaction) \n",
    "            # so need to check from back to front (only relevant for multi-word constraints)\n",
    "            for word_idx, constraint_word in enumerate(neg_cons[:-1][::-1]):\n",
    "                # if mismatch, then neg constraint is not satisfied\n",
    "                if all_decoder_outs[ki][-(word_idx+1)] != constraint_word:\n",
    "                    neg_constraint_exists = False\n",
    "                    break\n",
    "\n",
    "            neg_constraint_satisfied[ki][neg_idx] += neg_constraint_exists\n",
    "    return neg_constraint_satisfied\n",
    "\n",
    "def detect_low_likelihood(alpha, likelihood):\n",
    "    \"\"\"Detect likelihoods < top-alpha\n",
    "\n",
    "    Args:\n",
    "        alpha (_type_): _description_\n",
    "        likelihood (_type_): [k, |V|-1]\n",
    "    \"\"\"\n",
    "    # get the minimum value to be included within the top-alpha\n",
    "    likelihood_penalty_thresh = likelihood.flatten().topk(alpha).values.min()\n",
    "\n",
    "    return likelihood < likelihood_penalty_thresh\n",
    "\n",
    "def update_irreversible_satisfaction(num_ks, k_irreversible_satisfaction, all_decoder_outs, pos_constraints,\n",
    "                                   out_size):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        num_ks (int): number of hypothesis which have not ended\n",
    "        beta (_type_): top-beta number of irreversible satisfactions to keep\n",
    "        k_irreversible_satisfaction (_type_): number of irreversible satisfactions per hypothesis; [k]\n",
    "        all_decoder_outs (_type_): list of previous generations for each hypothesis [k, |generation|]\n",
    "        pos_constraints (List[List[List[int]]]): 3D list of shape [max_k, num positive constraints, length of positive constraint]\n",
    "        out_size: dimension of generations |Vocab|-1\n",
    "    \"\"\"\n",
    "    # [k, |V|-1]\n",
    "    k_irreversible_satisfaction_now = k_irreversible_satisfaction[:, None].repeat(1, out_size)\n",
    "    pos_constraints_satisfied = torch.full_like(k_irreversible_satisfaction_now, -1)\n",
    "\n",
    "    for ki in range(num_ks):\n",
    "        for pos_cons_idx, pos_cons in enumerate(pos_constraints[ki]):\n",
    "            pos_constraint_exist = True\n",
    "            \n",
    "            ## similar to detecting irreversible unsatisfaction, \n",
    "            # we check from last (current) to first (previous generated text)\n",
    "            pos_idx = pos_cons[-1]\n",
    "\n",
    "            if (len(pos_cons) - 1) > len(all_decoder_outs[ki]):\n",
    "                continue # i.e. pos_constraint_exist=False\n",
    "\n",
    "            # checkds from 2nd last to first (only relevant for multi-word constraints)\n",
    "            for word_idx, constraint_word in enumerate(pos_cons[:-1][::-1]): \n",
    "                if all_decoder_outs[ki][-(word_idx+1)] != constraint_word:\n",
    "                    pos_constraint_exist = False\n",
    "                    break\n",
    "\n",
    "            if pos_constraint_exist:\n",
    "                k_irreversible_satisfaction_now[ki][pos_idx] += 1\n",
    "                pos_constraints_satisfied[ki][pos_idx] = pos_cons_idx\n",
    "                \n",
    "    return k_irreversible_satisfaction_now, pos_constraints_satisfied\n",
    "\n",
    "def detect_low_irreversible_satisfactions(k_irreversible_satisfactions_now, # [k, |V|-1]\n",
    "                                          beta):\n",
    "    # get the minimum number of satisfied clauses to be included within the top-beta\n",
    "    # need to use unique because many candidates can have the same number of satisfied clauses\n",
    "    unique_num_irreversible_satisfactions = k_irreversible_satisfactions_now.flatten().unique()\n",
    "    satisfaction_penalty_thresh = unique_num_irreversible_satisfactions[-min(beta, len(unique_num_irreversible_satisfactions))].item()\n",
    "    return k_irreversible_satisfactions_now < satisfaction_penalty_thresh\n",
    "\n",
    "def get_proportion_completion_reward(num_ks,\n",
    "                                     scores, # [k, |V|-1]\n",
    "                                     pos_constraints, # List[List[List[int]]]; [k, num constraints, len constraint]\n",
    "                                     all_decoder_outs, # List [k, |generation|]\n",
    "                                     lam=0.75\n",
    "                                     ):\n",
    "    reward = torch.zeros_like(scores)\n",
    "\n",
    "    for ki in range(num_ks):\n",
    "        for pos_cons in pos_constraints[ki]:\n",
    "            ## just like in the paper, we also reward partial completion (reversible satisfaction)\n",
    "            # to do this we need to do constraint prefix comparison for lengths i=0...|constraint|\n",
    "            # because if a constraint is: [0, 1, 2, 3], a partial completion could be [0], [0,1], [0,1,2]\n",
    "            # with full completion: [0,1,2,3]\n",
    "            for word_idx, constraint_word in enumerate(pos_cons):\n",
    "                if word_idx > len(all_decoder_outs[ki]):\n",
    "                    break\n",
    "                if word_idx == 0 or all_decoder_outs[ki][-word_idx:] == pos_cons[:word_idx]:\n",
    "                    reward[ki][constraint_word] = max((word_idx+1) / len(pos_cons), reward[ki][constraint_word])\n",
    "    \n",
    "    return lam * reward\n",
    "\n",
    "def neurologic_decoding(decoder, decoder_hidden, decoder_cell, encoder_houts,\n",
    "                            ingredients, max_recipe_len,\n",
    "                            pos_constraints, neg_constraints, k, alpha, beta,\n",
    "                            neg_constraint_penalty, likelihood_penalty, low_irr_satisfaction_penalty, lam,\n",
    "                            decoder_mode=\"attention\"):\n",
    "    \"\"\"Neurological decoding for a particular sample in batch.\n",
    "\n",
    "    Args:\n",
    "        decoder (_type_): _description_\n",
    "        decoder_hidden (_type_): [1, N=1, H]\n",
    "        decoder_cell (_type_): [1, N=1, H]\n",
    "        encoder_houts (_type_): [N=1, L_i, H]\n",
    "        ingredients (_type_): [N=1, L_i]\n",
    "        max_recipe_len (_type_): _description_\n",
    "        pos_constraints (List[List[int]]): list of positive constraints, nested list because constraints can be multi-word \n",
    "                                           IMPORTANT: these are expected to be transformed to index using vocab\n",
    "        neg_constraints (List[List[int]]): list of negative constraints, nested list because constraints can be multi-word\n",
    "                                           IMPORTANT: these are expected to be transformed to index using vocab\n",
    "        k (_type_): number of hypothesis per sample\n",
    "        alpha (_type_): top-alpha likelihood which are not pruned\n",
    "        beta (_type_): top-beta number of satisfied clauses which are not pruned\n",
    "        neg_constraint_penalty (_type_): penalty for including negative constraint\n",
    "        likelihood_penalty (_type_): penalty for not being in top-alpha likelihood\n",
    "        low_irr_satisfaction_penalty (_type_): penalty for not being in top-beta no. of satisfied clauses\n",
    "        lam (_type_): lambda to add constraint progress to score\n",
    "        decoder_mode (str, optional): _description_. Defaults to \"basic\".\n",
    "    \"\"\"\n",
    "    assert decoder_mode == \"attention\", \"best model is attention, should be using attention!\"\n",
    "\n",
    "    K = torch.tensor([0]).to(DEVICE) # start with 1 hypothesis\n",
    "    \n",
    "    all_decoder_outs = [[SPECIAL_TAGS[REC_START]] for _ in range(k)] # stores decoder outputs for each hypothesis; [max_K]\n",
    "\n",
    "    decoder_input = torch.full([1], SPECIAL_TAGS[REC_START], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # stores the running likelihoods for the k hypotheses\n",
    "    k_likelihoods = torch.zeros([k], dtype=torch.float, device=DEVICE) # [max_K]\n",
    "\n",
    "    # number of irreversible satisfactions so far for each hypothesis\n",
    "    k_irreversible_satisfaction = torch.zeros_like(decoder_input) # [k]\n",
    "\n",
    "    # lists *remaining* positive constraints for each hypotheses\n",
    "    # once a positive constraint has been fully satisfied (irreversible satisfaction), it is removed\n",
    "    # 3D list of shape [max_k, num positive constraints, length of positive constraint]\n",
    "    # pos_constraints_i = [pos_constraints for _ in range(k)]\n",
    "    pos_constraints_i = [pos_constraints]\n",
    "\n",
    "    ## initialize inputs as the same for all ks because all of them have the same ingredients\n",
    "    # encoder_houts_i = repeat_for_k(encoder_houts, k, dim=0) # [N=max_K, L_i, H]\n",
    "    # decoder_hidden_i = repeat_for_k(decoder_hidden, k, dim=1) # [1, N=max_K, H]\n",
    "    # decoder_cell_i = repeat_for_k(decoder_cell, k, dim=1) # [1, N=max_K, H]\n",
    "    # ingredients_i = repeat_for_k(ingredients, k, dim=0) # [N=max_K, L_i]\n",
    "    encoder_houts_i = encoder_houts\n",
    "    decoder_hidden_i = decoder_hidden\n",
    "    decoder_cell_i = decoder_cell\n",
    "    ingredients_i = ingredients\n",
    "\n",
    "    for recipe_i in range(max_recipe_len - 1): # generations are bounded by max length (-1 because of EOS)\n",
    "        ## precondition: K is the list of hypotheses which have not ended\n",
    "\n",
    "        num_ks = len(K) # some hypotheses can finish early so need to udpate this every iter\n",
    "        valid_all_decoder_outs = [all_decoder_outs[i] for i in K]\n",
    "\n",
    "        ## attention\n",
    "        # decoder_out: log probs [k, |Vocab|-1]\n",
    "        decoder_out, decoder_hidden_i, decoder_cell_i, attn_weights_i = decoder(\n",
    "            decoder_input, decoder_hidden_i, decoder_cell_i, encoder_houts_i, ingredients_i\n",
    "        )\n",
    "\n",
    "        # sum all log probs with running log probs\n",
    "        # [k, |V|-1] + [k, 1] = [k, |V|-1]\n",
    "        likelihood_i = decoder_out + k_likelihoods[K].unsqueeze(-1)\n",
    "\n",
    "        scores = decoder_out.clone() # used for selection (can no longer be interpreted as probabilities so we preserve likelihoods)\n",
    "\n",
    "        ############# PRUNING #############\n",
    "\n",
    "        # detect generations which will cause irreversible unsatisfaction; [k, |V|-1]\n",
    "        neg_constraint_satisfied = detect_negative_constraint(\n",
    "            num_ks, likelihood_i.shape, valid_all_decoder_outs, neg_constraints)\n",
    "        \n",
    "        # detect generations with low likelihood; [k, |V|-1]\n",
    "        low_likelihoods = detect_low_likelihood(alpha, likelihood_i)\n",
    "\n",
    "        # get potential total irreversible satisfaction (including already satisfied clauses) for each candidate\n",
    "        # k_irreversible_satisfaction_now: [k, |V|-1]\n",
    "        # pos_constraints_satisfied: [k, |V|-1]\n",
    "        k_irreversible_satisfaction_now, pos_constraints_satisfied = update_irreversible_satisfaction(\n",
    "            num_ks, k_irreversible_satisfaction, valid_all_decoder_outs, pos_constraints_i, \n",
    "            out_size=likelihood_i.size(-1))\n",
    "        \n",
    "        # detect generations with < top-beta number of irreversibly satisfied clauses; [k, |V|-1]\n",
    "        low_irreversible_satisfaction = detect_low_irreversible_satisfactions(\n",
    "            k_irreversible_satisfaction_now, beta)\n",
    "        \n",
    "        # perform soft pruning, i.e. penalizing instead of filtering out (see report)\n",
    "        penalties = neg_constraint_satisfied * neg_constraint_penalty + \\\n",
    "                    low_likelihoods * likelihood_penalty + \\\n",
    "                    low_irreversible_satisfaction * low_irr_satisfaction_penalty\n",
    "        \n",
    "        scores -= penalties\n",
    "        \n",
    "        ############# SELECTION #############\n",
    "\n",
    "        # get rewards for partial/full completion\n",
    "        rewards = get_proportion_completion_reward(num_ks, scores, pos_constraints_i, valid_all_decoder_outs, lam=lam)\n",
    "\n",
    "        scores += rewards # [k, |V|-1]\n",
    "\n",
    "        # select top-k based on scores across all candidates\n",
    "        topk_scores, topk_inds = scores.flatten().topk(num_ks if recipe_i > 0 else k)\n",
    "        k_origin = torch.div(topk_inds, scores.size(-1), rounding_mode=\"floor\")\n",
    "        k_origin_global = K[k_origin] # get global k\n",
    "        word_idx = topk_inds % scores.size(-1) # k top words\n",
    "\n",
    "        prev_all_decoder_outs = deepcopy(all_decoder_outs)\n",
    "        for wi, (ki, k_glob) in enumerate(zip((K if recipe_i > 0 else range(3)), k_origin_global)):\n",
    "            all_decoder_outs[ki] = prev_all_decoder_outs[k_glob] + [word_idx[wi].item()]\n",
    "            # all_decoder_outs[k_glob].append(word_idx[k_glob].item())\n",
    "\n",
    "        k_likelihoods[K if recipe_i > 0 else range(k)] = likelihood_i[k_origin, word_idx] # [k]\n",
    "\n",
    "        pos_constraints_chosen = [pos_constraints_i[ki] for ki in k_origin]\n",
    "\n",
    "        for i, (ki, wi) in enumerate(zip(k_origin, word_idx)):\n",
    "            # remove irreversibly satisfied constraint\n",
    "            pos_constraints_chosen[i] = [c for cidx, c in enumerate(pos_constraints_chosen[i])\n",
    "                                         if cidx != pos_constraints_satisfied[ki, wi]]\n",
    "        pos_constraints_i = pos_constraints_chosen\n",
    "\n",
    "        ############# PREPARE FOR NEXT ITERATION #############\n",
    "\n",
    "        ## check if any of the hypotheses has ended (update K)\n",
    "        not_eor = word_idx != SPECIAL_TAGS[REC_END]\n",
    "        K = torch.arange(k, device=DEVICE)[K][not_eor] if recipe_i > 0 \\\n",
    "            else torch.arange(k, device=DEVICE)[not_eor]\n",
    "        # K=K[not_eor] if recipe_i > 0 else torch.arange(k)[not_eor]\n",
    "        # K=torch.arange(len(K) if recipe_i > 0 else k)[not_eor]\n",
    "\n",
    "        if len(K) < 1:\n",
    "            break\n",
    "\n",
    "        ## postcondition: K is the list of hypotheses which have not ended\n",
    "\n",
    "        ## determine inputs for next iter\n",
    "\n",
    "        k_irreversible_satisfaction = k_irreversible_satisfaction_now[k_origin[not_eor], word_idx[not_eor]] # [k]\n",
    "        decoder_input = word_idx[not_eor] # [k]\n",
    "\n",
    "        ## all the same so no need to index using K\n",
    "        if recipe_i == 0:\n",
    "            encoder_houts_i = repeat_for_k(encoder_houts, len(K), dim=0)\n",
    "            ingredients_i = repeat_for_k(ingredients, len(K), dim=0)\n",
    "        else:\n",
    "            encoder_houts_i = encoder_houts_i[:len(K)] # [N=k, L_i, H]\n",
    "            ingredients_i = ingredients_i[:len(K)]\n",
    "\n",
    "        ## different based on k\n",
    "        decoder_hidden_i = decoder_hidden_i[:, k_origin[not_eor]]\n",
    "        decoder_cell_i = decoder_cell_i[:, k_origin[not_eor]]\n",
    "        pos_constraints_i = [pos_constraints_i[i] for i in not_eor.nonzero().flatten()]\n",
    "    else:\n",
    "        for ki in K.tolist():\n",
    "            all_decoder_outs[ki].append(SPECIAL_TAGS[REC_END])\n",
    "\n",
    "    k_likelihoods_normalized = k_likelihoods / torch.tensor([len(o) for o in all_decoder_outs],\n",
    "                                                            device=k_likelihoods.device)\n",
    "\n",
    "    return all_decoder_outs, k_likelihoods_normalized\n",
    "\n",
    "def eval_neuro_decoding_iter(ingredients, ing_lens, encoder, decoder, vocab, pos_constraints, neg_constraints,\n",
    "                              max_recipe_len=MAX_RECIPE_LEN,\n",
    "                              **kwargs):\n",
    "    assert encoder.training is False and decoder.training is False\n",
    "\n",
    "    enc_out, enc_out_lens, enc_h_final, enc_c_final = encoder(ingredients, ing_lens)\n",
    "    \n",
    "    # initialize decoder hidden state as final encoder hidden state\n",
    "    decoder_hidden = enc_h_final\n",
    "    decoder_cell = enc_c_final\n",
    "\n",
    "    # all_decoder_outs (List[List[int]]): list of k hypotheses\n",
    "    # k_likelihoods_normalized (tensor): has overall likelihood of each hypotheses shape [k]\n",
    "    all_decoder_outs, k_likelihoods_normalized = neurologic_decoding(decoder, decoder_hidden, decoder_cell, enc_out,\n",
    "                                                                     ingredients, max_recipe_len, pos_constraints,\n",
    "                                                                     neg_constraints, **kwargs)\n",
    "    \n",
    "    max_i = k_likelihoods_normalized.argmax()\n",
    "    final_decoder_out = all_decoder_outs[max_i]\n",
    "\n",
    "    final_decoder_out_txt = [vocab.index2word[w] for w in final_decoder_out]\n",
    "\n",
    "    return final_decoder_out_txt\n",
    "\n",
    "def build_constraints_dict(all_ingredients_list, vocab):\n",
    "    constraints_dict = {}\n",
    "    valid_ingredients_list = deepcopy(all_ingredients_list)\n",
    "    invalid_ingredients = []\n",
    "    for ingredient in valid_ingredients_list:\n",
    "        invalid_ingredient=False\n",
    "        ingredient_idx_form = []\n",
    "\n",
    "        for word in ingredient.split():\n",
    "            if not vocab.word_exist_in_vocab(word):\n",
    "                invalid_ingredient = True\n",
    "                break\n",
    "            ingredient_idx_form.append(vocab.word2index(word))\n",
    "        if not invalid_ingredient:\n",
    "            constraints_dict[ingredient] = ingredient_idx_form\n",
    "        else:\n",
    "            # valid_ingredients_list.remove(ingredient)\n",
    "            invalid_ingredients.append(ingredient)\n",
    "    return constraints_dict, invalid_ingredients\n",
    "\n",
    "def eval_neuro_decoding(encoder, decoder, dataset, vocab, all_ingredients_list, \n",
    "                        max_recipe_len=MAX_RECIPE_LEN, **kwargs):\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "                                              collate_fn=pad_collate(vocab, train=False))\n",
    "    \n",
    "    all_decoder_outs = [] # (List[List[str]]): List of len `N`, each element is the generated sequence for that sample\n",
    "    all_gt_recipes = [] # (List[List[str]])\n",
    "    all_ingredients = []\n",
    "\n",
    "    constraints_dict, invalid_ingredients = build_constraints_dict(all_ingredients_list, vocab)\n",
    "\n",
    "    valid_ingredients_list = [i for i in all_ingredients_list if i not in invalid_ingredients]\n",
    "\n",
    "    all_ingredients_regex = get_ingredients_regex(valid_ingredients_list)\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ingredients, recipes, ing_lens, _ in tqdm(dataloader):\n",
    "            pos_constraints, neg_constraints, ingredients_text = create_pos_neg_constraints(\n",
    "                ingredients, vocab, all_ingredients_regex, constraints_dict)\n",
    "            final_decoder_out_txt = eval_neuro_decoding_iter(\n",
    "                ingredients, ing_lens, encoder, decoder, vocab, pos_constraints, neg_constraints,\n",
    "                max_recipe_len, **kwargs\n",
    "            )\n",
    "            all_decoder_outs += [final_decoder_out_txt]\n",
    "            all_gt_recipes += recipes\n",
    "            all_ingredients += [ingredients_text]\n",
    "\n",
    "    return all_decoder_outs, all_gt_recipes, all_ingredients\n",
    "\n",
    "def create_pos_neg_constraints(ingredients_idxs, # expecting batch size 1\n",
    "                               vocab,\n",
    "                               all_ingredients_regex,\n",
    "                               constraints_dict):\n",
    "    \n",
    "    ingredients_text = \" \".join([vocab.index2word[i] for i in ingredients_idxs[0].tolist()])\n",
    "    input_ingredients = find_ingredients_in_text(ingredients_text, all_ingredients_regex)\n",
    "    input_ingrs_partial = ' '.join(input_ingredients).split()\n",
    "    pos_constraints = [constraints_dict[ing] for ing in sorted(list(input_ingredients), key=len)]\n",
    "    neg_constraints = []\n",
    "    for constraint in constraints_dict.keys():\n",
    "        if constraint in pos_constraints:\n",
    "            continue\n",
    "        valid_negative_constraint=True\n",
    "        for word in constraint.split():\n",
    "            if word in input_ingrs_partial:\n",
    "                valid_negative_constraint = False\n",
    "                break\n",
    "        if valid_negative_constraint:\n",
    "            neg_constraints.append(constraints_dict[constraint])\n",
    "    return pos_constraints, neg_constraints, ingredients_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rng()\n",
    "embedding_size=300\n",
    "num_layers=3\n",
    "encoder_multilayer_attn = EncoderRNN(vocab.n_unique_words, embedding_size=embedding_size, hidden_size=HIDDEN_SIZE, \n",
    "                          padding_value=vocab.word2index(PAD_WORD), num_lstm_layers=num_layers).to(DEVICE)\n",
    "# in the training script, decoder is always fed a non-end token and thus never needs to generate padding\n",
    "# also it should never generate \"<UNKNOWN>\"\n",
    "# decoder = DecoderRNN(embedding_size=embedding_size,hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-2).to(DEVICE)\n",
    "decoder_multilayer_attn = AttnDecoderRNN(embedding_size, hidden_size=HIDDEN_SIZE, output_size=vocab.n_unique_words-1, \n",
    "                              padding_val=vocab.word2index(PAD_WORD), dropout=DROPOUT, num_lstm_layers=num_layers).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30, enc lr scheduler: [0.001], dec lr scheduler: [0.001]\n",
      "(Epoch 0, iter 50/787) Average loss so far: 6.988\n",
      "(Epoch 0, iter 100/787) Average loss so far: 6.058\n",
      "(Epoch 0, iter 150/787) Average loss so far: 6.035\n",
      "(Epoch 0, iter 200/787) Average loss so far: 6.032\n",
      "(Epoch 0, iter 250/787) Average loss so far: 6.019\n",
      "(Epoch 0, iter 300/787) Average loss so far: 6.011\n",
      "(Epoch 0, iter 350/787) Average loss so far: 6.015\n",
      "(Epoch 0, iter 400/787) Average loss so far: 6.006\n",
      "(Epoch 0, iter 450/787) Average loss so far: 6.002\n",
      "(Epoch 0, iter 500/787) Average loss so far: 5.990\n",
      "(Epoch 0, iter 550/787) Average loss so far: 5.972\n",
      "(Epoch 0, iter 600/787) Average loss so far: 5.961\n",
      "(Epoch 0, iter 650/787) Average loss so far: 5.934\n",
      "(Epoch 0, iter 700/787) Average loss so far: 5.930\n",
      "(Epoch 0, iter 750/787) Average loss so far: 5.931\n",
      "Average epoch loss: 6.053\n",
      "This epoch took 8.784394307931263 mins. Time remaining: 4.0 hrs 14.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 5.933405944279262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:08<00:00,  1.15s/it]\n",
      "/home/junn/miniconda3/envs/nlp/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 793/793 [00:06<00:00, 114.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 5.8211892454135815e-80, METEOR score: 0.034986121334209475\n",
      "Starting epoch 2/30, enc lr scheduler: [0.0009972883382072953], dec lr scheduler: [0.0009972883382072953]\n",
      "(Epoch 1, iter 50/787) Average loss so far: 5.916\n",
      "(Epoch 1, iter 100/787) Average loss so far: 5.902\n",
      "(Epoch 1, iter 150/787) Average loss so far: 5.896\n",
      "(Epoch 1, iter 200/787) Average loss so far: 5.880\n",
      "(Epoch 1, iter 250/787) Average loss so far: 5.882\n",
      "(Epoch 1, iter 300/787) Average loss so far: 5.891\n",
      "(Epoch 1, iter 350/787) Average loss so far: 5.881\n",
      "(Epoch 1, iter 400/787) Average loss so far: 5.874\n",
      "(Epoch 1, iter 450/787) Average loss so far: 5.868\n",
      "(Epoch 1, iter 500/787) Average loss so far: 5.830\n",
      "(Epoch 1, iter 550/787) Average loss so far: 5.730\n",
      "(Epoch 1, iter 600/787) Average loss so far: 5.635\n",
      "(Epoch 1, iter 650/787) Average loss so far: 5.547\n",
      "(Epoch 1, iter 700/787) Average loss so far: 5.400\n",
      "(Epoch 1, iter 750/787) Average loss so far: 5.205\n",
      "Average epoch loss: 5.724\n",
      "This epoch took 8.680376549561819 mins. Time remaining: 4.0 hrs 3.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 5.041280337742397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n",
      "100%|██████████| 793/793 [00:06<00:00, 114.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.003278639860407049, METEOR score: 0.08561562097555378\n",
      "Starting epoch 3/30, enc lr scheduler: [0.0009891830623632338], dec lr scheduler: [0.0009891830623632338]\n",
      "(Epoch 2, iter 50/787) Average loss so far: 4.912\n",
      "(Epoch 2, iter 100/787) Average loss so far: 4.751\n",
      "(Epoch 2, iter 150/787) Average loss so far: 4.599\n",
      "(Epoch 2, iter 200/787) Average loss so far: 4.489\n",
      "(Epoch 2, iter 250/787) Average loss so far: 4.364\n",
      "(Epoch 2, iter 300/787) Average loss so far: 4.268\n",
      "(Epoch 2, iter 350/787) Average loss so far: 4.199\n",
      "(Epoch 2, iter 400/787) Average loss so far: 4.150\n",
      "(Epoch 2, iter 450/787) Average loss so far: 4.090\n",
      "(Epoch 2, iter 500/787) Average loss so far: 4.023\n",
      "(Epoch 2, iter 550/787) Average loss so far: 3.958\n",
      "(Epoch 2, iter 600/787) Average loss so far: 3.944\n",
      "(Epoch 2, iter 650/787) Average loss so far: 3.891\n",
      "(Epoch 2, iter 700/787) Average loss so far: 3.854\n",
      "(Epoch 2, iter 750/787) Average loss so far: 3.827\n",
      "Average epoch loss: 4.201\n",
      "This epoch took 8.660929580529531 mins. Time remaining: 3.0 hrs 53.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.8312723296029225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
      "100%|██████████| 793/793 [00:05<00:00, 150.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.009649228203172842, METEOR score: 0.15070114988789704\n",
      "Starting epoch 4/30, enc lr scheduler: [0.0009757729755661011], dec lr scheduler: [0.0009757729755661011]\n",
      "(Epoch 3, iter 50/787) Average loss so far: 3.738\n",
      "(Epoch 3, iter 100/787) Average loss so far: 3.721\n",
      "(Epoch 3, iter 150/787) Average loss so far: 3.697\n",
      "(Epoch 3, iter 200/787) Average loss so far: 3.681\n",
      "(Epoch 3, iter 250/787) Average loss so far: 3.687\n",
      "(Epoch 3, iter 300/787) Average loss so far: 3.624\n",
      "(Epoch 3, iter 350/787) Average loss so far: 3.616\n",
      "(Epoch 3, iter 400/787) Average loss so far: 3.585\n",
      "(Epoch 3, iter 450/787) Average loss so far: 3.555\n",
      "(Epoch 3, iter 500/787) Average loss so far: 3.548\n",
      "(Epoch 3, iter 550/787) Average loss so far: 3.543\n",
      "(Epoch 3, iter 600/787) Average loss so far: 3.546\n",
      "(Epoch 3, iter 650/787) Average loss so far: 3.513\n",
      "(Epoch 3, iter 700/787) Average loss so far: 3.485\n",
      "(Epoch 3, iter 750/787) Average loss so far: 3.485\n",
      "Average epoch loss: 3.596\n",
      "This epoch took 8.700705035527546 mins. Time remaining: 3.0 hrs 46.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.5433250835963657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.49it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 237.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.01680922041802637, METEOR score: 0.17252114463959134\n",
      "Starting epoch 5/30, enc lr scheduler: [0.0009572050015330874], dec lr scheduler: [0.0009572050015330874]\n",
      "(Epoch 4, iter 50/787) Average loss so far: 3.437\n",
      "(Epoch 4, iter 100/787) Average loss so far: 3.421\n",
      "(Epoch 4, iter 150/787) Average loss so far: 3.419\n",
      "(Epoch 4, iter 200/787) Average loss so far: 3.411\n",
      "(Epoch 4, iter 250/787) Average loss so far: 3.377\n",
      "(Epoch 4, iter 300/787) Average loss so far: 3.361\n",
      "(Epoch 4, iter 350/787) Average loss so far: 3.362\n",
      "(Epoch 4, iter 400/787) Average loss so far: 3.337\n",
      "(Epoch 4, iter 450/787) Average loss so far: 3.360\n",
      "(Epoch 4, iter 500/787) Average loss so far: 3.334\n",
      "(Epoch 4, iter 550/787) Average loss so far: 3.319\n",
      "(Epoch 4, iter 600/787) Average loss so far: 3.328\n",
      "(Epoch 4, iter 650/787) Average loss so far: 3.312\n",
      "(Epoch 4, iter 700/787) Average loss so far: 3.283\n",
      "(Epoch 4, iter 750/787) Average loss so far: 3.285\n",
      "Average epoch loss: 3.354\n",
      "This epoch took 8.66706737279892 mins. Time remaining: 3.0 hrs 36.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.3929422923496793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.69it/s]\n",
      "100%|██████████| 793/793 [00:02<00:00, 300.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.02410393818638161, METEOR score: 0.18903294738920962\n",
      "Starting epoch 6/30, enc lr scheduler: [0.0009336825748732973], dec lr scheduler: [0.0009336825748732973]\n",
      "(Epoch 5, iter 50/787) Average loss so far: 3.268\n",
      "(Epoch 5, iter 100/787) Average loss so far: 3.238\n",
      "(Epoch 5, iter 150/787) Average loss so far: 3.226\n",
      "(Epoch 5, iter 200/787) Average loss so far: 3.217\n",
      "(Epoch 5, iter 250/787) Average loss so far: 3.211\n",
      "(Epoch 5, iter 300/787) Average loss so far: 3.213\n",
      "(Epoch 5, iter 350/787) Average loss so far: 3.203\n",
      "(Epoch 5, iter 400/787) Average loss so far: 3.193\n",
      "(Epoch 5, iter 450/787) Average loss so far: 3.200\n",
      "(Epoch 5, iter 500/787) Average loss so far: 3.213\n",
      "(Epoch 5, iter 550/787) Average loss so far: 3.187\n",
      "(Epoch 5, iter 600/787) Average loss so far: 3.182\n",
      "(Epoch 5, iter 650/787) Average loss so far: 3.167\n",
      "(Epoch 5, iter 700/787) Average loss so far: 3.176\n",
      "(Epoch 5, iter 750/787) Average loss so far: 3.172\n",
      "Average epoch loss: 3.202\n",
      "This epoch took 8.660624651114146 mins. Time remaining: 3.0 hrs 27.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.2941173825945174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\n",
      "100%|██████████| 793/793 [00:03<00:00, 240.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.01932799321202002, METEOR score: 0.18168938969894916\n",
      "Starting epoch 7/30, enc lr scheduler: [0.0009054634122155991], dec lr scheduler: [0.0009054634122155991]\n",
      "(Epoch 6, iter 50/787) Average loss so far: 3.107\n",
      "(Epoch 6, iter 100/787) Average loss so far: 3.130\n",
      "(Epoch 6, iter 150/787) Average loss so far: 3.095\n",
      "(Epoch 6, iter 200/787) Average loss so far: 3.118\n",
      "(Epoch 6, iter 250/787) Average loss so far: 3.103\n",
      "(Epoch 6, iter 300/787) Average loss so far: 3.102\n",
      "(Epoch 6, iter 350/787) Average loss so far: 3.094\n",
      "(Epoch 6, iter 400/787) Average loss so far: 3.105\n",
      "(Epoch 6, iter 450/787) Average loss so far: 3.091\n",
      "(Epoch 6, iter 500/787) Average loss so far: 3.089\n",
      "(Epoch 6, iter 550/787) Average loss so far: 3.082\n",
      "(Epoch 6, iter 600/787) Average loss so far: 3.077\n",
      "(Epoch 6, iter 650/787) Average loss so far: 3.076\n",
      "(Epoch 6, iter 700/787) Average loss so far: 3.068\n",
      "(Epoch 6, iter 750/787) Average loss so far: 3.063\n",
      "Average epoch loss: 3.091\n",
      "This epoch took 8.661432000001271 mins. Time remaining: 3.0 hrs 19.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.220607246671404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.91it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 416.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.034996658118198035, METEOR score: 0.19608702213958482\n",
      "Starting epoch 8/30, enc lr scheduler: [0.0008728566886113102], dec lr scheduler: [0.0008728566886113102]\n",
      "(Epoch 7, iter 50/787) Average loss so far: 3.020\n",
      "(Epoch 7, iter 100/787) Average loss so far: 3.023\n",
      "(Epoch 7, iter 150/787) Average loss so far: 3.018\n",
      "(Epoch 7, iter 200/787) Average loss so far: 3.026\n",
      "(Epoch 7, iter 250/787) Average loss so far: 3.011\n",
      "(Epoch 7, iter 300/787) Average loss so far: 3.009\n",
      "(Epoch 7, iter 350/787) Average loss so far: 3.006\n",
      "(Epoch 7, iter 400/787) Average loss so far: 3.008\n",
      "(Epoch 7, iter 450/787) Average loss so far: 3.012\n",
      "(Epoch 7, iter 500/787) Average loss so far: 3.002\n",
      "(Epoch 7, iter 550/787) Average loss so far: 3.000\n",
      "(Epoch 7, iter 600/787) Average loss so far: 2.995\n",
      "(Epoch 7, iter 650/787) Average loss so far: 2.978\n",
      "(Epoch 7, iter 700/787) Average loss so far: 2.987\n",
      "(Epoch 7, iter 750/787) Average loss so far: 2.994\n",
      "Average epoch loss: 3.005\n",
      "This epoch took 8.668269244829814 mins. Time remaining: 3.0 hrs 10.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.1842188835144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.98it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 460.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04036306790727657, METEOR score: 0.20022729874967282\n",
      "Starting epoch 9/30, enc lr scheduler: [0.0008362196501476349], dec lr scheduler: [0.0008362196501476349]\n",
      "(Epoch 8, iter 50/787) Average loss so far: 2.934\n",
      "(Epoch 8, iter 100/787) Average loss so far: 2.937\n",
      "(Epoch 8, iter 150/787) Average loss so far: 2.937\n",
      "(Epoch 8, iter 200/787) Average loss so far: 2.949\n",
      "(Epoch 8, iter 250/787) Average loss so far: 2.949\n",
      "(Epoch 8, iter 300/787) Average loss so far: 2.938\n",
      "(Epoch 8, iter 350/787) Average loss so far: 2.934\n",
      "(Epoch 8, iter 400/787) Average loss so far: 2.917\n",
      "(Epoch 8, iter 450/787) Average loss so far: 2.927\n",
      "(Epoch 8, iter 500/787) Average loss so far: 2.950\n",
      "(Epoch 8, iter 550/787) Average loss so far: 2.952\n",
      "(Epoch 8, iter 600/787) Average loss so far: 2.941\n",
      "(Epoch 8, iter 650/787) Average loss so far: 2.934\n",
      "(Epoch 8, iter 700/787) Average loss so far: 2.926\n",
      "(Epoch 8, iter 750/787) Average loss so far: 2.933\n",
      "Average epoch loss: 2.936\n",
      "This epoch took 8.682707707087198 mins. Time remaining: 3.0 hrs 2.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.14445652280535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.11it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 543.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04614282375504496, METEOR score: 0.19953643331690282\n",
      "Starting epoch 10/30, enc lr scheduler: [0.0007959536998847742], dec lr scheduler: [0.0007959536998847742]\n",
      "(Epoch 9, iter 50/787) Average loss so far: 2.881\n",
      "(Epoch 9, iter 100/787) Average loss so far: 2.873\n",
      "(Epoch 9, iter 150/787) Average loss so far: 2.894\n",
      "(Epoch 9, iter 200/787) Average loss so far: 2.899\n",
      "(Epoch 9, iter 250/787) Average loss so far: 2.899\n",
      "(Epoch 9, iter 300/787) Average loss so far: 2.882\n",
      "(Epoch 9, iter 350/787) Average loss so far: 2.858\n",
      "(Epoch 9, iter 400/787) Average loss so far: 2.883\n",
      "(Epoch 9, iter 450/787) Average loss so far: 2.864\n",
      "(Epoch 9, iter 500/787) Average loss so far: 2.867\n",
      "(Epoch 9, iter 550/787) Average loss so far: 2.876\n",
      "(Epoch 9, iter 600/787) Average loss so far: 2.872\n",
      "(Epoch 9, iter 650/787) Average loss so far: 2.900\n",
      "(Epoch 9, iter 700/787) Average loss so far: 2.871\n",
      "(Epoch 9, iter 750/787) Average loss so far: 2.870\n",
      "Average epoch loss: 2.879\n",
      "This epoch took 8.667925226688386 mins. Time remaining: 2.0 hrs 53.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.120482785361154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.12it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 558.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.047825885570907486, METEOR score: 0.205678013742886\n",
      "Starting epoch 11/30, enc lr scheduler: [0.0007525], dec lr scheduler: [0.0007525]\n",
      "(Epoch 10, iter 50/787) Average loss so far: 2.819\n",
      "(Epoch 10, iter 100/787) Average loss so far: 2.829\n",
      "(Epoch 10, iter 150/787) Average loss so far: 2.827\n",
      "(Epoch 10, iter 200/787) Average loss so far: 2.831\n",
      "(Epoch 10, iter 250/787) Average loss so far: 2.829\n",
      "(Epoch 10, iter 300/787) Average loss so far: 2.839\n",
      "(Epoch 10, iter 350/787) Average loss so far: 2.841\n",
      "(Epoch 10, iter 400/787) Average loss so far: 2.835\n",
      "(Epoch 10, iter 450/787) Average loss so far: 2.823\n",
      "(Epoch 10, iter 500/787) Average loss so far: 2.816\n",
      "(Epoch 10, iter 550/787) Average loss so far: 2.818\n",
      "(Epoch 10, iter 600/787) Average loss so far: 2.836\n",
      "(Epoch 10, iter 650/787) Average loss so far: 2.844\n",
      "(Epoch 10, iter 700/787) Average loss so far: 2.833\n",
      "(Epoch 10, iter 750/787) Average loss so far: 2.826\n",
      "Average epoch loss: 2.829\n",
      "This epoch took 8.670869362354278 mins. Time remaining: 2.0 hrs 44.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.101747683116368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.34it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 617.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.051791655004959615, METEOR score: 0.20470572480986682\n",
      "Starting epoch 12/30, enc lr scheduler: [0.0007063346383225212], dec lr scheduler: [0.0007063346383225212]\n",
      "(Epoch 11, iter 50/787) Average loss so far: 2.805\n",
      "(Epoch 11, iter 100/787) Average loss so far: 2.796\n",
      "(Epoch 11, iter 150/787) Average loss so far: 2.791\n",
      "(Epoch 11, iter 200/787) Average loss so far: 2.791\n",
      "(Epoch 11, iter 250/787) Average loss so far: 2.781\n",
      "(Epoch 11, iter 300/787) Average loss so far: 2.795\n",
      "(Epoch 11, iter 350/787) Average loss so far: 2.779\n",
      "(Epoch 11, iter 400/787) Average loss so far: 2.771\n",
      "(Epoch 11, iter 450/787) Average loss so far: 2.784\n",
      "(Epoch 11, iter 500/787) Average loss so far: 2.782\n",
      "(Epoch 11, iter 550/787) Average loss so far: 2.787\n",
      "(Epoch 11, iter 600/787) Average loss so far: 2.787\n",
      "(Epoch 11, iter 650/787) Average loss so far: 2.784\n",
      "(Epoch 11, iter 700/787) Average loss so far: 2.785\n",
      "(Epoch 11, iter 750/787) Average loss so far: 2.784\n",
      "Average epoch loss: 2.786\n",
      "This epoch took 8.654789272944132 mins. Time remaining: 2.0 hrs 35.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.090313128062657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.36it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 648.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05567891393706685, METEOR score: 0.21062660135719127\n",
      "Starting epoch 13/30, enc lr scheduler: [0.000657963412215599], dec lr scheduler: [0.000657963412215599]\n",
      "(Epoch 12, iter 50/787) Average loss so far: 2.742\n",
      "(Epoch 12, iter 100/787) Average loss so far: 2.729\n",
      "(Epoch 12, iter 150/787) Average loss so far: 2.754\n",
      "(Epoch 12, iter 200/787) Average loss so far: 2.751\n",
      "(Epoch 12, iter 250/787) Average loss so far: 2.738\n",
      "(Epoch 12, iter 300/787) Average loss so far: 2.758\n",
      "(Epoch 12, iter 350/787) Average loss so far: 2.751\n",
      "(Epoch 12, iter 400/787) Average loss so far: 2.749\n",
      "(Epoch 12, iter 450/787) Average loss so far: 2.746\n",
      "(Epoch 12, iter 500/787) Average loss so far: 2.754\n",
      "(Epoch 12, iter 550/787) Average loss so far: 2.743\n",
      "(Epoch 12, iter 600/787) Average loss so far: 2.757\n",
      "(Epoch 12, iter 650/787) Average loss so far: 2.753\n",
      "(Epoch 12, iter 700/787) Average loss so far: 2.768\n",
      "(Epoch 12, iter 750/787) Average loss so far: 2.748\n",
      "Average epoch loss: 2.749\n",
      "This epoch took 8.67595762014389 mins. Time remaining: 2.0 hrs 27.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.078939846583775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.16it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 640.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05447397472432387, METEOR score: 0.20767725983235402\n",
      "Starting epoch 14/30, enc lr scheduler: [0.0006079162869547909], dec lr scheduler: [0.0006079162869547909]\n",
      "(Epoch 13, iter 50/787) Average loss so far: 2.712\n",
      "(Epoch 13, iter 100/787) Average loss so far: 2.701\n",
      "(Epoch 13, iter 150/787) Average loss so far: 2.727\n",
      "(Epoch 13, iter 200/787) Average loss so far: 2.724\n",
      "(Epoch 13, iter 250/787) Average loss so far: 2.723\n",
      "(Epoch 13, iter 300/787) Average loss so far: 2.716\n",
      "(Epoch 13, iter 350/787) Average loss so far: 2.729\n",
      "(Epoch 13, iter 400/787) Average loss so far: 2.720\n",
      "(Epoch 13, iter 450/787) Average loss so far: 2.703\n",
      "(Epoch 13, iter 500/787) Average loss so far: 2.726\n",
      "(Epoch 13, iter 550/787) Average loss so far: 2.717\n",
      "(Epoch 13, iter 600/787) Average loss so far: 2.694\n",
      "(Epoch 13, iter 650/787) Average loss so far: 2.711\n",
      "(Epoch 13, iter 700/787) Average loss so far: 2.699\n",
      "(Epoch 13, iter 750/787) Average loss so far: 2.720\n",
      "Average epoch loss: 2.715\n",
      "This epoch took 8.702299817403157 mins. Time remaining: 2.0 hrs 19.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0758470467158725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.31it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 655.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05610531776640169, METEOR score: 0.2134749913995397\n",
      "Starting epoch 15/30, enc lr scheduler: [0.0005567415893174886], dec lr scheduler: [0.0005567415893174886]\n",
      "(Epoch 14, iter 50/787) Average loss so far: 2.683\n",
      "(Epoch 14, iter 100/787) Average loss so far: 2.684\n",
      "(Epoch 14, iter 150/787) Average loss so far: 2.682\n",
      "(Epoch 14, iter 200/787) Average loss so far: 2.683\n",
      "(Epoch 14, iter 250/787) Average loss so far: 2.675\n",
      "(Epoch 14, iter 300/787) Average loss so far: 2.713\n",
      "(Epoch 14, iter 350/787) Average loss so far: 2.683\n",
      "(Epoch 14, iter 400/787) Average loss so far: 2.698\n",
      "(Epoch 14, iter 450/787) Average loss so far: 2.701\n",
      "(Epoch 14, iter 500/787) Average loss so far: 2.686\n",
      "(Epoch 14, iter 550/787) Average loss so far: 2.683\n",
      "(Epoch 14, iter 600/787) Average loss so far: 2.664\n",
      "(Epoch 14, iter 650/787) Average loss so far: 2.689\n",
      "(Epoch 14, iter 700/787) Average loss so far: 2.686\n",
      "(Epoch 14, iter 750/787) Average loss so far: 2.683\n",
      "Average epoch loss: 2.686\n",
      "This epoch took 8.699237219492595 mins. Time remaining: 2.0 hrs 10.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.067518813269479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.48it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 718.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05618418002695732, METEOR score: 0.2173668475571425\n",
      "Starting epoch 16/30, enc lr scheduler: [0.0005050000000000002], dec lr scheduler: [0.0005050000000000002]\n",
      "(Epoch 15, iter 50/787) Average loss so far: 2.676\n",
      "(Epoch 15, iter 100/787) Average loss so far: 2.648\n",
      "(Epoch 15, iter 150/787) Average loss so far: 2.659\n",
      "(Epoch 15, iter 200/787) Average loss so far: 2.662\n",
      "(Epoch 15, iter 250/787) Average loss so far: 2.662\n",
      "(Epoch 15, iter 300/787) Average loss so far: 2.658\n",
      "(Epoch 15, iter 350/787) Average loss so far: 2.671\n",
      "(Epoch 15, iter 400/787) Average loss so far: 2.657\n",
      "(Epoch 15, iter 450/787) Average loss so far: 2.644\n",
      "(Epoch 15, iter 500/787) Average loss so far: 2.656\n",
      "(Epoch 15, iter 550/787) Average loss so far: 2.664\n",
      "(Epoch 15, iter 600/787) Average loss so far: 2.657\n",
      "(Epoch 15, iter 650/787) Average loss so far: 2.666\n",
      "(Epoch 15, iter 700/787) Average loss so far: 2.645\n",
      "(Epoch 15, iter 750/787) Average loss so far: 2.655\n",
      "Average epoch loss: 2.659\n",
      "This epoch took 8.666933755079905 mins. Time remaining: 2.0 hrs 1.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0657551969800676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.42it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 717.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05615294677876267, METEOR score: 0.2133591944674418\n",
      "Starting epoch 17/30, enc lr scheduler: [0.0004532584106825117], dec lr scheduler: [0.0004532584106825117]\n",
      "(Epoch 16, iter 50/787) Average loss so far: 2.639\n",
      "(Epoch 16, iter 100/787) Average loss so far: 2.630\n",
      "(Epoch 16, iter 150/787) Average loss so far: 2.627\n",
      "(Epoch 16, iter 200/787) Average loss so far: 2.626\n",
      "(Epoch 16, iter 250/787) Average loss so far: 2.629\n",
      "(Epoch 16, iter 300/787) Average loss so far: 2.650\n",
      "(Epoch 16, iter 350/787) Average loss so far: 2.658\n",
      "(Epoch 16, iter 400/787) Average loss so far: 2.633\n",
      "(Epoch 16, iter 450/787) Average loss so far: 2.648\n",
      "(Epoch 16, iter 500/787) Average loss so far: 2.617\n",
      "(Epoch 16, iter 550/787) Average loss so far: 2.637\n",
      "(Epoch 16, iter 600/787) Average loss so far: 2.631\n",
      "(Epoch 16, iter 650/787) Average loss so far: 2.639\n",
      "(Epoch 16, iter 700/787) Average loss so far: 2.638\n",
      "(Epoch 16, iter 750/787) Average loss so far: 2.647\n",
      "Average epoch loss: 2.636\n",
      "This epoch took 8.688865876197815 mins. Time remaining: 1.0 hrs 52.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0647445065634593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.72it/s]\n",
      "100%|██████████| 793/793 [00:00<00:00, 797.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05162445812511413, METEOR score: 0.2073657691543935\n",
      "Starting epoch 18/30, enc lr scheduler: [0.00040208371304520916], dec lr scheduler: [0.00040208371304520916]\n",
      "(Epoch 17, iter 50/787) Average loss so far: 2.605\n",
      "(Epoch 17, iter 100/787) Average loss so far: 2.604\n",
      "(Epoch 17, iter 150/787) Average loss so far: 2.611\n",
      "(Epoch 17, iter 200/787) Average loss so far: 2.609\n",
      "(Epoch 17, iter 250/787) Average loss so far: 2.625\n",
      "(Epoch 17, iter 300/787) Average loss so far: 2.628\n",
      "(Epoch 17, iter 350/787) Average loss so far: 2.601\n",
      "(Epoch 17, iter 400/787) Average loss so far: 2.615\n",
      "(Epoch 17, iter 450/787) Average loss so far: 2.599\n",
      "(Epoch 17, iter 500/787) Average loss so far: 2.617\n",
      "(Epoch 17, iter 550/787) Average loss so far: 2.613\n",
      "(Epoch 17, iter 600/787) Average loss so far: 2.625\n",
      "(Epoch 17, iter 650/787) Average loss so far: 2.611\n",
      "(Epoch 17, iter 700/787) Average loss so far: 2.633\n",
      "(Epoch 17, iter 750/787) Average loss so far: 2.617\n",
      "Average epoch loss: 2.615\n",
      "This epoch took 8.66599006652832 mins. Time remaining: 1.0 hrs 43.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.062435899462019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.50it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 737.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05444598116058762, METEOR score: 0.21361483967861572\n",
      "Starting epoch 19/30, enc lr scheduler: [0.00035203658778440114], dec lr scheduler: [0.00035203658778440114]\n",
      "(Epoch 18, iter 50/787) Average loss so far: 2.583\n",
      "(Epoch 18, iter 100/787) Average loss so far: 2.577\n",
      "(Epoch 18, iter 150/787) Average loss so far: 2.597\n",
      "(Epoch 18, iter 200/787) Average loss so far: 2.593\n",
      "(Epoch 18, iter 250/787) Average loss so far: 2.596\n",
      "(Epoch 18, iter 300/787) Average loss so far: 2.615\n",
      "(Epoch 18, iter 350/787) Average loss so far: 2.590\n",
      "(Epoch 18, iter 400/787) Average loss so far: 2.584\n",
      "(Epoch 18, iter 450/787) Average loss so far: 2.598\n",
      "(Epoch 18, iter 500/787) Average loss so far: 2.606\n",
      "(Epoch 18, iter 550/787) Average loss so far: 2.591\n",
      "(Epoch 18, iter 600/787) Average loss so far: 2.604\n",
      "(Epoch 18, iter 650/787) Average loss so far: 2.588\n",
      "(Epoch 18, iter 700/787) Average loss so far: 2.603\n",
      "(Epoch 18, iter 750/787) Average loss so far: 2.613\n",
      "Average epoch loss: 2.596\n",
      "This epoch took 8.652748115857442 mins. Time remaining: 1.0 hrs 35.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0591438157217845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.38it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 758.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05424589140761788, METEOR score: 0.21430080632880433\n",
      "Starting epoch 20/30, enc lr scheduler: [0.00030366536167747904], dec lr scheduler: [0.00030366536167747904]\n",
      "(Epoch 19, iter 50/787) Average loss so far: 2.582\n",
      "(Epoch 19, iter 100/787) Average loss so far: 2.569\n",
      "(Epoch 19, iter 150/787) Average loss so far: 2.571\n",
      "(Epoch 19, iter 200/787) Average loss so far: 2.587\n",
      "(Epoch 19, iter 250/787) Average loss so far: 2.571\n",
      "(Epoch 19, iter 300/787) Average loss so far: 2.579\n",
      "(Epoch 19, iter 350/787) Average loss so far: 2.584\n",
      "(Epoch 19, iter 400/787) Average loss so far: 2.580\n",
      "(Epoch 19, iter 450/787) Average loss so far: 2.582\n",
      "(Epoch 19, iter 500/787) Average loss so far: 2.583\n",
      "(Epoch 19, iter 550/787) Average loss so far: 2.581\n",
      "(Epoch 19, iter 600/787) Average loss so far: 2.582\n",
      "(Epoch 19, iter 650/787) Average loss so far: 2.563\n",
      "(Epoch 19, iter 700/787) Average loss so far: 2.587\n",
      "(Epoch 19, iter 750/787) Average loss so far: 2.584\n",
      "Average epoch loss: 2.580\n",
      "This epoch took 8.676026181379955 mins. Time remaining: 1.0 hrs 26.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0615645817347934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.65it/s]\n",
      "100%|██████████| 793/793 [00:00<00:00, 795.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05251383464691767, METEOR score: 0.2116644609179294\n",
      "Starting epoch 21/30, enc lr scheduler: [0.00025750000000000013], dec lr scheduler: [0.00025750000000000013]\n",
      "(Epoch 20, iter 50/787) Average loss so far: 2.563\n",
      "(Epoch 20, iter 100/787) Average loss so far: 2.560\n",
      "(Epoch 20, iter 150/787) Average loss so far: 2.569\n",
      "(Epoch 20, iter 200/787) Average loss so far: 2.559\n",
      "(Epoch 20, iter 250/787) Average loss so far: 2.561\n",
      "(Epoch 20, iter 300/787) Average loss so far: 2.551\n",
      "(Epoch 20, iter 350/787) Average loss so far: 2.561\n",
      "(Epoch 20, iter 400/787) Average loss so far: 2.556\n",
      "(Epoch 20, iter 450/787) Average loss so far: 2.571\n",
      "(Epoch 20, iter 500/787) Average loss so far: 2.571\n",
      "(Epoch 20, iter 550/787) Average loss so far: 2.564\n",
      "(Epoch 20, iter 600/787) Average loss so far: 2.581\n",
      "(Epoch 20, iter 650/787) Average loss so far: 2.567\n",
      "(Epoch 20, iter 700/787) Average loss so far: 2.577\n",
      "(Epoch 20, iter 750/787) Average loss so far: 2.566\n",
      "Average epoch loss: 2.565\n",
      "This epoch took 8.658537669976551 mins. Time remaining: 1.0 hrs 17.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0620672702789307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.73it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 774.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05325391809008416, METEOR score: 0.21406562669861987\n",
      "Starting epoch 22/30, enc lr scheduler: [0.00021404630011522585], dec lr scheduler: [0.00021404630011522585]\n",
      "(Epoch 21, iter 50/787) Average loss so far: 2.539\n",
      "(Epoch 21, iter 100/787) Average loss so far: 2.549\n",
      "(Epoch 21, iter 150/787) Average loss so far: 2.547\n",
      "(Epoch 21, iter 200/787) Average loss so far: 2.550\n",
      "(Epoch 21, iter 250/787) Average loss so far: 2.555\n",
      "(Epoch 21, iter 300/787) Average loss so far: 2.554\n",
      "(Epoch 21, iter 350/787) Average loss so far: 2.556\n",
      "(Epoch 21, iter 400/787) Average loss so far: 2.543\n",
      "(Epoch 21, iter 450/787) Average loss so far: 2.542\n",
      "(Epoch 21, iter 500/787) Average loss so far: 2.563\n",
      "(Epoch 21, iter 550/787) Average loss so far: 2.551\n",
      "(Epoch 21, iter 600/787) Average loss so far: 2.551\n",
      "(Epoch 21, iter 650/787) Average loss so far: 2.552\n",
      "(Epoch 21, iter 700/787) Average loss so far: 2.554\n",
      "(Epoch 21, iter 750/787) Average loss so far: 2.568\n",
      "Average epoch loss: 2.552\n",
      "This epoch took 8.670958431561788 mins. Time remaining: 1.0 hrs 9.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0650003296988353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.71it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 792.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05365965581686292, METEOR score: 0.21241248063528498\n",
      "Starting epoch 23/30, enc lr scheduler: [0.00017378034985236535], dec lr scheduler: [0.00017378034985236535]\n",
      "(Epoch 22, iter 50/787) Average loss so far: 2.535\n",
      "(Epoch 22, iter 100/787) Average loss so far: 2.549\n",
      "(Epoch 22, iter 150/787) Average loss so far: 2.538\n",
      "(Epoch 22, iter 200/787) Average loss so far: 2.552\n",
      "(Epoch 22, iter 250/787) Average loss so far: 2.555\n",
      "(Epoch 22, iter 300/787) Average loss so far: 2.536\n",
      "(Epoch 22, iter 350/787) Average loss so far: 2.558\n",
      "(Epoch 22, iter 400/787) Average loss so far: 2.551\n",
      "(Epoch 22, iter 450/787) Average loss so far: 2.554\n",
      "(Epoch 22, iter 500/787) Average loss so far: 2.525\n",
      "(Epoch 22, iter 550/787) Average loss so far: 2.539\n",
      "(Epoch 22, iter 600/787) Average loss so far: 2.538\n",
      "(Epoch 22, iter 650/787) Average loss so far: 2.521\n",
      "(Epoch 22, iter 700/787) Average loss so far: 2.532\n",
      "(Epoch 22, iter 750/787) Average loss so far: 2.527\n",
      "Average epoch loss: 2.541\n",
      "This epoch took 8.694250969092051 mins. Time remaining: 1.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.064901147569929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.53it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 751.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05429019863071828, METEOR score: 0.2108751834143225\n",
      "Starting epoch 24/30, enc lr scheduler: [0.00013714331138868998], dec lr scheduler: [0.00013714331138868998]\n",
      "(Epoch 23, iter 50/787) Average loss so far: 2.534\n",
      "(Epoch 23, iter 100/787) Average loss so far: 2.524\n",
      "(Epoch 23, iter 150/787) Average loss so far: 2.534\n",
      "(Epoch 23, iter 200/787) Average loss so far: 2.544\n",
      "(Epoch 23, iter 250/787) Average loss so far: 2.528\n",
      "(Epoch 23, iter 300/787) Average loss so far: 2.532\n",
      "(Epoch 23, iter 350/787) Average loss so far: 2.524\n",
      "(Epoch 23, iter 400/787) Average loss so far: 2.545\n",
      "(Epoch 23, iter 450/787) Average loss so far: 2.529\n",
      "(Epoch 23, iter 500/787) Average loss so far: 2.531\n",
      "(Epoch 23, iter 550/787) Average loss so far: 2.525\n",
      "(Epoch 23, iter 600/787) Average loss so far: 2.529\n",
      "(Epoch 23, iter 650/787) Average loss so far: 2.528\n",
      "(Epoch 23, iter 700/787) Average loss so far: 2.537\n",
      "(Epoch 23, iter 750/787) Average loss so far: 2.539\n",
      "Average epoch loss: 2.532\n",
      "This epoch took 8.65880027214686 mins. Time remaining: 0.0 hrs 51.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0661655834742954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.60it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 733.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05508513737660636, METEOR score: 0.21475239961444473\n",
      "Starting epoch 25/30, enc lr scheduler: [0.00010453658778440108], dec lr scheduler: [0.00010453658778440108]\n",
      "(Epoch 24, iter 50/787) Average loss so far: 2.527\n",
      "(Epoch 24, iter 100/787) Average loss so far: 2.526\n",
      "(Epoch 24, iter 150/787) Average loss so far: 2.524\n",
      "(Epoch 24, iter 200/787) Average loss so far: 2.541\n",
      "(Epoch 24, iter 250/787) Average loss so far: 2.518\n",
      "(Epoch 24, iter 300/787) Average loss so far: 2.529\n",
      "(Epoch 24, iter 350/787) Average loss so far: 2.522\n",
      "(Epoch 24, iter 400/787) Average loss so far: 2.517\n",
      "(Epoch 24, iter 450/787) Average loss so far: 2.510\n",
      "(Epoch 24, iter 500/787) Average loss so far: 2.528\n",
      "(Epoch 24, iter 550/787) Average loss so far: 2.537\n",
      "(Epoch 24, iter 600/787) Average loss so far: 2.520\n",
      "(Epoch 24, iter 650/787) Average loss so far: 2.530\n",
      "(Epoch 24, iter 700/787) Average loss so far: 2.523\n",
      "(Epoch 24, iter 750/787) Average loss so far: 2.518\n",
      "Average epoch loss: 2.524\n",
      "This epoch took 8.660960761706034 mins. Time remaining: 0.0 hrs 43.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.06569732938494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.73it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 781.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05240369931105146, METEOR score: 0.21010115919574035\n",
      "Starting epoch 26/30, enc lr scheduler: [7.631742512670285e-05], dec lr scheduler: [7.631742512670285e-05]\n",
      "(Epoch 25, iter 50/787) Average loss so far: 2.519\n",
      "(Epoch 25, iter 100/787) Average loss so far: 2.513\n",
      "(Epoch 25, iter 150/787) Average loss so far: 2.532\n",
      "(Epoch 25, iter 200/787) Average loss so far: 2.528\n",
      "(Epoch 25, iter 250/787) Average loss so far: 2.509\n",
      "(Epoch 25, iter 300/787) Average loss so far: 2.518\n",
      "(Epoch 25, iter 350/787) Average loss so far: 2.528\n",
      "(Epoch 25, iter 400/787) Average loss so far: 2.508\n",
      "(Epoch 25, iter 450/787) Average loss so far: 2.514\n",
      "(Epoch 25, iter 500/787) Average loss so far: 2.526\n",
      "(Epoch 25, iter 550/787) Average loss so far: 2.500\n",
      "(Epoch 25, iter 600/787) Average loss so far: 2.517\n",
      "(Epoch 25, iter 650/787) Average loss so far: 2.523\n",
      "(Epoch 25, iter 700/787) Average loss so far: 2.510\n",
      "(Epoch 25, iter 750/787) Average loss so far: 2.519\n",
      "Average epoch loss: 2.518\n",
      "This epoch took 8.69899574915568 mins. Time remaining: 0.0 hrs 34.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.066434485571725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.52it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 770.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.053463804062823625, METEOR score: 0.21029893221004417\n",
      "Starting epoch 27/30, enc lr scheduler: [5.279499846691252e-05], dec lr scheduler: [5.279499846691252e-05]\n",
      "(Epoch 26, iter 50/787) Average loss so far: 2.511\n",
      "(Epoch 26, iter 100/787) Average loss so far: 2.507\n",
      "(Epoch 26, iter 150/787) Average loss so far: 2.510\n",
      "(Epoch 26, iter 200/787) Average loss so far: 2.510\n",
      "(Epoch 26, iter 250/787) Average loss so far: 2.525\n",
      "(Epoch 26, iter 300/787) Average loss so far: 2.518\n",
      "(Epoch 26, iter 350/787) Average loss so far: 2.520\n",
      "(Epoch 26, iter 400/787) Average loss so far: 2.511\n",
      "(Epoch 26, iter 450/787) Average loss so far: 2.507\n",
      "(Epoch 26, iter 500/787) Average loss so far: 2.520\n",
      "(Epoch 26, iter 550/787) Average loss so far: 2.494\n",
      "(Epoch 26, iter 600/787) Average loss so far: 2.519\n",
      "(Epoch 26, iter 650/787) Average loss so far: 2.506\n",
      "(Epoch 26, iter 700/787) Average loss so far: 2.524\n",
      "(Epoch 26, iter 750/787) Average loss so far: 2.526\n",
      "Average epoch loss: 2.513\n",
      "This epoch took 8.690738725662232 mins. Time remaining: 0.0 hrs 26.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0676874773842946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.45it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 761.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05483833839420476, METEOR score: 0.21259949218767468\n",
      "Starting epoch 28/30, enc lr scheduler: [3.4227024433899005e-05], dec lr scheduler: [3.4227024433899005e-05]\n",
      "(Epoch 27, iter 50/787) Average loss so far: 2.514\n",
      "(Epoch 27, iter 100/787) Average loss so far: 2.506\n",
      "(Epoch 27, iter 150/787) Average loss so far: 2.513\n",
      "(Epoch 27, iter 200/787) Average loss so far: 2.510\n",
      "(Epoch 27, iter 250/787) Average loss so far: 2.520\n",
      "(Epoch 27, iter 300/787) Average loss so far: 2.524\n",
      "(Epoch 27, iter 350/787) Average loss so far: 2.502\n",
      "(Epoch 27, iter 400/787) Average loss so far: 2.503\n",
      "(Epoch 27, iter 450/787) Average loss so far: 2.507\n",
      "(Epoch 27, iter 500/787) Average loss so far: 2.508\n",
      "(Epoch 27, iter 550/787) Average loss so far: 2.498\n",
      "(Epoch 27, iter 600/787) Average loss so far: 2.507\n",
      "(Epoch 27, iter 650/787) Average loss so far: 2.519\n",
      "(Epoch 27, iter 700/787) Average loss so far: 2.508\n",
      "(Epoch 27, iter 750/787) Average loss so far: 2.507\n",
      "Average epoch loss: 2.510\n",
      "This epoch took 8.739509677886963 mins. Time remaining: 0.0 hrs 17.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.068269661494664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.37it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 730.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05357286007825388, METEOR score: 0.21187169877005785\n",
      "Starting epoch 29/30, enc lr scheduler: [2.0816937636766188e-05], dec lr scheduler: [2.0816937636766188e-05]\n",
      "(Epoch 28, iter 50/787) Average loss so far: 2.503\n",
      "(Epoch 28, iter 100/787) Average loss so far: 2.517\n",
      "(Epoch 28, iter 150/787) Average loss so far: 2.502\n",
      "(Epoch 28, iter 200/787) Average loss so far: 2.504\n",
      "(Epoch 28, iter 250/787) Average loss so far: 2.514\n",
      "(Epoch 28, iter 300/787) Average loss so far: 2.506\n",
      "(Epoch 28, iter 350/787) Average loss so far: 2.518\n",
      "(Epoch 28, iter 400/787) Average loss so far: 2.496\n",
      "(Epoch 28, iter 450/787) Average loss so far: 2.508\n",
      "(Epoch 28, iter 500/787) Average loss so far: 2.511\n",
      "(Epoch 28, iter 550/787) Average loss so far: 2.514\n",
      "(Epoch 28, iter 600/787) Average loss so far: 2.509\n",
      "(Epoch 28, iter 650/787) Average loss so far: 2.483\n",
      "(Epoch 28, iter 700/787) Average loss so far: 2.515\n",
      "(Epoch 28, iter 750/787) Average loss so far: 2.511\n",
      "Average epoch loss: 2.507\n",
      "This epoch took 8.664481910069783 mins. Time remaining: 0.0 hrs 8.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0683638708932057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.39it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 760.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.053924556203878635, METEOR score: 0.2136804902885653\n",
      "Starting epoch 30/30, enc lr scheduler: [1.2711661792704668e-05], dec lr scheduler: [1.2711661792704668e-05]\n",
      "(Epoch 29, iter 50/787) Average loss so far: 2.496\n",
      "(Epoch 29, iter 100/787) Average loss so far: 2.494\n",
      "(Epoch 29, iter 150/787) Average loss so far: 2.521\n",
      "(Epoch 29, iter 200/787) Average loss so far: 2.511\n",
      "(Epoch 29, iter 250/787) Average loss so far: 2.510\n",
      "(Epoch 29, iter 300/787) Average loss so far: 2.511\n",
      "(Epoch 29, iter 350/787) Average loss so far: 2.505\n",
      "(Epoch 29, iter 400/787) Average loss so far: 2.493\n",
      "(Epoch 29, iter 450/787) Average loss so far: 2.497\n",
      "(Epoch 29, iter 500/787) Average loss so far: 2.521\n",
      "(Epoch 29, iter 550/787) Average loss so far: 2.491\n",
      "(Epoch 29, iter 600/787) Average loss so far: 2.503\n",
      "(Epoch 29, iter 650/787) Average loss so far: 2.506\n",
      "(Epoch 29, iter 700/787) Average loss so far: 2.509\n",
      "(Epoch 29, iter 750/787) Average loss so far: 2.515\n",
      "Average epoch loss: 2.506\n",
      "This epoch took 8.694341178735097 mins. Time remaining: 0.0 hrs 0.0 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 3.0682195595332553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.51it/s]\n",
      "100%|██████████| 793/793 [00:01<00:00, 777.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.05360497700665978, METEOR score: 0.21295206921320584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_lr=1e-3\n",
    "min_lr = 1e-5\n",
    "n_epochs = 30\n",
    "batch_size=128\n",
    "encoder_multilayer_attn_optimizer = optim.Adam(encoder_multilayer_attn.parameters(), lr=initial_lr)\n",
    "decoder_multilayer_attn_optimizer = optim.Adam(decoder_multilayer_attn.parameters(), lr=initial_lr)\n",
    "enc_multilayer_attn_scheduler = CosineAnnealingLR(encoder_multilayer_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "dec_multilayer_attn_scheduler = CosineAnnealingLR(decoder_multilayer_attn_optimizer, T_max=n_epochs, eta_min=min_lr)\n",
    "identifier=\"multilayer_attn_adam_without_intermediate_tags_wd0_lr1e-3\"\n",
    "\n",
    "multilayer_attn_epoch_losses, multilayer_attn_val_epoch_losses, multilayer_attn_log = train(\n",
    "    encoder_multilayer_attn, decoder_multilayer_attn, encoder_multilayer_attn_optimizer, decoder_multilayer_attn_optimizer, train_ds, \n",
    "    n_epochs=n_epochs, vocab=vocab, decoder_mode=\"attention\", batch_size=batch_size, \n",
    "    enc_lr_scheduler=enc_multilayer_attn_scheduler, dec_lr_scheduler=dec_multilayer_attn_scheduler, \n",
    "    dev_ds_val_loss = dev_ds_val_loss, dev_ds_val_met=dev_ds_val_met, identifier=identifier,\n",
    "    verbose_iter_interval=50)\n",
    "\n",
    "save_log(identifier, multilayer_attn_log, encoder_multilayer_attn_optimizer, decoder_multilayer_attn_optimizer, \n",
    "         enc_multilayer_attn_scheduler, dec_multilayer_attn_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_input_num_extra_ingredients_m(ingr_txt, recipe_txt, all_ings_regex, verbose=False):\n",
    "    \"\"\"get proportion of input ingredients and number of extra ingredients in recipe (`txt`).\n",
    "\n",
    "    Args:\n",
    "        ingr_txt (str): ingredients text\n",
    "        recipe_txt (str): recipe text\n",
    "        all_ings_regex (str): regex to match all valid ingredients\n",
    "        input_ingredients_iter (List or Set): iterable of unique ingredients list\n",
    "    \"\"\"\n",
    "    # get set of input ingredients\n",
    "    input_ingredients = find_ingredients_in_text(ingr_txt, all_ings_regex)\n",
    "    # # get regex to match only input ingredients\n",
    "    # input_ingredients_regex = get_ingredients_regex(input_ingredients)\n",
    "\n",
    "    all_ings_in_text = [i.strip('<>') for i in set(re.findall(\"<[A-Za-z ]+>\", recipe_txt))]\n",
    "    input_ings_in_text = []\n",
    "    extra_ings_in_text = []\n",
    "    for ing in all_ings_in_text:\n",
    "        if ing in input_ingredients:\n",
    "            input_ings_in_text.append(ing)\n",
    "        else:\n",
    "            extra_ings_in_text.append(ing)\n",
    "    if verbose:\n",
    "        print(f\"=====Input ingredients in text=====\\n{input_ings_in_text}\")\n",
    "        print(f\"\\n=====All ingredients in text===== \\n{all_ings_in_text}\")\n",
    "\n",
    "    prop_input_ings = len(input_ings_in_text) / len(input_ingredients)\n",
    "    num_extra_ings = len(extra_ings_in_text)\n",
    "    return prop_input_ings, num_extra_ings\n",
    "\n",
    "def get_included_extra_ingrs_single(ingredients_i: str, recipe_i: str, \n",
    "                                    all_ingredients_regex:str, invalid_ingredients_regex:str,\n",
    "                                     partial_match=False):\n",
    "    ## get all ingredients in input ingredients\n",
    "    input_ingrs = find_ingredients_in_text(ingredients_i, all_ingredients_regex, enforce_unique=True)\n",
    "\n",
    "    # some data samples have ingredients which are not recognized by the regex\n",
    "    if len(input_ingrs) < 1:\n",
    "        return None, None\n",
    "    \n",
    "    ## get all ingredients in recipe\n",
    "    all_recipe_ingrs = find_ingredients_in_text(recipe_i, all_ingredients_regex, enforce_unique=False)\n",
    "    # get all invalid ingredients in recipe (start of sentence, etc.)\n",
    "    invalid_recipe_ingrs = find_ingredients_in_text(recipe_i, invalid_ingredients_regex, enforce_unique=False)\n",
    "\n",
    "    # remove a single instance of the invalid ingredient\n",
    "    for i in range(len(invalid_recipe_ingrs)):\n",
    "        if type(invalid_recipe_ingrs[i]) == tuple:\n",
    "            invalid_w = invalid_recipe_ingrs[i][-1]\n",
    "        else:\n",
    "            invalid_w = invalid_recipe_ingrs[i]\n",
    "        all_recipe_ingrs.remove(invalid_w)\n",
    "\n",
    "    valid_recipe_ingrs = set(all_recipe_ingrs) # remove duplicates\n",
    "\n",
    "    included_ingrs = 0\n",
    "    for recipe_ingr in valid_recipe_ingrs:\n",
    "        ## whole match\n",
    "        if recipe_ingr in input_ingrs:\n",
    "            included_ingrs += 1\n",
    "            continue\n",
    "        ## partial match\n",
    "        if partial_match:\n",
    "            indiv_ingr_parts = \" \".join(input_ingrs).split()\n",
    "            if recipe_ingr in indiv_ingr_parts:\n",
    "                included_ingrs += 1\n",
    "                continue\n",
    "    num_extra_ingrs = len(valid_recipe_ingrs) - included_ingrs\n",
    "\n",
    "    prop_included_ingrs = min(1, included_ingrs/len(input_ingrs))\n",
    "\n",
    "    return prop_included_ingrs, num_extra_ingrs\n",
    "\n",
    "def get_prop_input_num_extra_ingredients(all_ingredients, all_recipes, \n",
    "                                         all_ingredients_regex, invalid_ingredients_regex, partial_match=True):\n",
    "    prop_included_ingrs_all = []\n",
    "    num_extra_ingrs_all = []\n",
    "    for ingredients_i, recipe_i in tqdm(zip(all_ingredients, all_recipes)):\n",
    "        prop_included_ingrs, num_extra_ingrs = get_included_extra_ingrs_single(\n",
    "            ingredients_i, recipe_i, all_ingredients_regex, invalid_ingredients_regex, partial_match)\n",
    "        if prop_included_ingrs is not None:\n",
    "            prop_included_ingrs_all.append(prop_included_ingrs)\n",
    "            num_extra_ingrs_all.append(num_extra_ingrs)\n",
    "    avg_prop_included_ingrs = sum(prop_included_ingrs_all) / len(prop_included_ingrs_all)\n",
    "    avg_num_extra_ingrs = sum(num_extra_ingrs_all) / len(num_extra_ingrs_all)\n",
    "    return avg_prop_included_ingrs, avg_num_extra_ingrs\n",
    "\n",
    "def convert_eval_out_to_get_ingredient_metrics(all_generated_recipes, all_gt_ingredients, vocab,\n",
    "                                               all_ingredients_lst, skip_ing_processing=False):\n",
    "    if skip_ing_processing:\n",
    "        ingredient_txts = all_gt_ingredients\n",
    "    else:\n",
    "        ingredient_txts = []\n",
    "        for ingredients in all_gt_ingredients:\n",
    "            ing_text = \" \".join([vocab.index2word[i] for i in ingredients\n",
    "                            if i != vocab.word2index(PAD_WORD)])\n",
    "            ingredient_txts += [ing_text]\n",
    "    generated_recipes_concat = [\" \".join(l) for l in all_generated_recipes]\n",
    "    all_ingredient_regex = get_ingredients_regex(all_ingredients_lst)\n",
    "    invalid_ingredient_regex = get_invalid_ingredients_regex(all_ingredients_lst)\n",
    "    avg_prop_included_ingrs, avg_num_extra_ingrs = get_prop_input_num_extra_ingredients(\n",
    "        ingredient_txts, generated_recipes_concat, all_ingredient_regex, invalid_ingredient_regex)\n",
    "    print(f\"Avg. % given ingredients: {avg_prop_included_ingrs*100:.3f}%\\n\"\n",
    "          f\"Avg. number of extra ingredients: {avg_num_extra_ingrs:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ingredients_lst = get_all_ingredients(\"./ingredient_set.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(encoder, decoder, \"adam_without_intermediate_tags_with_val_wd0_lr1e-3_ep_24\")\n",
    "all_decoder_outs, all_gt_recipes, all_gt_ingredients = eval(\n",
    "    encoder, decoder, test_ds, vocab, batch_size=128, decoder_mode=\"basic\",\n",
    "    max_recipe_len=MAX_RECIPE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_bleu(all_gt_recipes, all_decoder_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_meteor(all_gt_recipes, all_decoder_outs, split_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_eval_out_to_get_ingredient_metrics(all_decoder_outs, all_gt_ingredients,\n",
    "                                           vocab, all_ingredients_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(encoder_attn, decoder_attn, \"attn_adam_without_intermediate_tags_wd0_lr1e-3_ep_26\")\n",
    "all_decoder_outs, all_gt_recipes, all_gt_ingredients = eval(\n",
    "    encoder_attn, decoder_attn, test_ds, vocab, batch_size=128, decoder_mode=\"attention\",\n",
    "    max_recipe_len=MAX_RECIPE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04949963728618708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_bleu(all_gt_recipes, all_decoder_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 629.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20855536635420194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_meteor(all_gt_recipes, all_decoder_outs, split_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774it [00:00, 1011.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. % given ingredients: 33.453%\n",
      "Avg. number of extra ingredients: 2.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_eval_out_to_get_ingredient_metrics(all_decoder_outs, all_gt_ingredients,\n",
    "                                           vocab, all_ingredients_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(encoder_pretrained_embed, decoder_pretrained_embed, \n",
    "           \"pretrained_emb_attn_adam_without_intermediate_tags_wd0_lr1e-3_ep_29\")\n",
    "all_decoder_outs, all_gt_recipes, all_gt_ingredients = eval(\n",
    "    encoder_pretrained_embed, decoder_pretrained_embed, test_ds, vocab, batch_size=128, \n",
    "    decoder_mode=\"attention\", max_recipe_len=MAX_RECIPE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05519142942964554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_bleu(all_gt_recipes, all_decoder_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 576.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2100281888663272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_meteor(all_gt_recipes, all_decoder_outs, split_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774it [00:00, 1022.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. % given ingredients: 31.074%\n",
      "Avg. number of extra ingredients: 2.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_eval_out_to_get_ingredient_metrics(all_decoder_outs, all_gt_ingredients,\n",
    "                                           vocab, all_ingredients_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2\n",
    "\n",
    "#### Without Neurologic Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(encoder_multilayer_attn, decoder_multilayer_attn, \"multilayer_attn_adam_without_intermediate_tags_wd0_lr1e-3_ep_14\")\n",
    "all_decoder_outs_multi, all_gt_recipes_multi, all_gt_ingredients_multi = eval(\n",
    "    encoder_multilayer_attn, decoder_multilayer_attn, test_ds, vocab, batch_size=128, decoder_mode=\"attention\",\n",
    "    max_recipe_len=MAX_RECIPE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053654397203939004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_bleu(all_decoder_outs_multi, all_gt_recipes_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 709.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21415571426435778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_meteor(all_gt_recipes_multi, all_decoder_outs_multi, split_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774it [00:00, 1157.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. % given ingredients: 32.267%\n",
      "Avg. number of extra ingredients: 2.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_eval_out_to_get_ingredient_metrics(all_decoder_outs_multi, all_gt_ingredients_multi,\n",
    "                                           vocab, all_ingredients_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Neurologic Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! WARNING: this code takes around 20-30 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [16:36<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "alpha=50 # likelihood\n",
    "beta = 2 # num constraints satisfied\n",
    "neg_constraint_penalty, likelihood_penalty, low_irr_satisfaction_penalty = 10, 0.5, 0.5\n",
    "lam = 5.0\n",
    "\n",
    "all_decoder_outs, all_gt_recipes, all_gt_ings = eval_neuro_decoding(\n",
    "    encoder_multilayer_attn, decoder_multilayer_attn, test_ds, vocab, all_ingredients_lst, k=k, alpha=alpha, beta=beta, \n",
    "    neg_constraint_penalty=neg_constraint_penalty, likelihood_penalty=likelihood_penalty, \n",
    "    low_irr_satisfaction_penalty=low_irr_satisfaction_penalty, lam=lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05810241560787664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_bleu(all_gt_recipes, all_decoder_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 712.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23339527798724602"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_meteor(all_gt_recipes, all_decoder_outs, split_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774it [00:00, 1072.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. % given ingredients: 79.462%\n",
      "Avg. number of extra ingredients: 0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_eval_out_to_get_ingredient_metrics(all_decoder_outs, all_gt_ings,\n",
    "                                           vocab, all_ingredients_lst, skip_ing_processing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ings = get_all_ingredients(\"./ingredient_set.json\")\n",
    "all_ings_regex = get_ingredients_regex(all_ings)\n",
    "metric_sample_ings, metric_sample_gold_recipe, metric_sample_generated_recipe = \\\n",
    "    load_metric_sample(\"./metric_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Input ingredients in text=====\n",
      "['lemon juice', 'orange juice', 'water', 'sugar', 'strawberries']\n",
      "\n",
      "=====All ingredients in text===== \n",
      "['lemon juice', 'orange juice', 'water', 'cantaloupe', 'vanilla ice cream', 'sugar', 'strawberries']\n",
      "\n",
      "proportion of input ingredients: 1.0\n",
      "number of extra ingredients: 2\n"
     ]
    }
   ],
   "source": [
    "prop_inp_ings, n_extra_ings = get_prop_input_num_extra_ingredients_m(\n",
    "    metric_sample_ings, metric_sample_generated_recipe, all_ings_regex, verbose=True)\n",
    "print(f\"\\nproportion of input ingredients: {prop_inp_ings}\\nnumber of extra ingredients: {n_extra_ings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 458.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.2757364975156813, METEOR score: 0.5479209577754892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calc_bleu([metric_sample_gold_recipe], [metric_sample_generated_recipe], split_gt=True, split_gen=True)\n",
    "meteor_score = calc_meteor([metric_sample_gold_recipe], [metric_sample_generated_recipe], split_gt=True, split_gen=True)\n",
    "print(f\"BLEU score: {bleu_score}, METEOR score: {meteor_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_sample_orig = \"2 c sugar, 1/4 c lemon juice, 1 c water, 1/3 c orange juice, 8 c strawberries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform relevant preprocessing steps (note: these operations are taken from `preprocess_data` and is the same preprocessing done on the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_sample = re.sub(\"([^0-9a-zA-Z.'\\\"/ ])\", r\" \\1 \", ingredients_sample_orig)\n",
    "ingredients_sample = '<INGREDIENT_START> ' + ingredients_sample + ' <INGREDIENT_END>'\n",
    "ingredients_sample = re.sub('[ ]{2,}', \" \", ingredients_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<INGREDIENT_START> 2 c sugar , 1/4 c lemon juice , 1 c water , 1/3 c orange juice , 8 c strawberries <INGREDIENT_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredients_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_sample_idxs = torch.tensor([vocab.word2index(w) for w in ingredients_sample.split(\" \")],\n",
    "                                       dtype=torch.long, device=DEVICE)\n",
    "# convert to batch form with batch size 1 as model is expecting batched input\n",
    "ingredients_sample_idxs = ingredients_sample_idxs[None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   22,   12,   16,   78,   32,   12,  641,  900,   78,   17,   12,\n",
       "          311,   78,  235,   12,  791,  900,   78,  385,   12, 1218,    1]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredients_sample_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingr_lens = torch.tensor([len(x) for x in ingredients_sample_idxs], dtype=torch.long, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingr_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_res_basic = get_predictions_iter(ingredients_sample_idxs, ingr_lens, encoder, decoder,\n",
    "                                        vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RECIPE_START> combine sugar , cornstarch and water in a saucepan bring to a boil , stirring constantly boil for 1 minute remove from heat and stir in lemon juice and lemon juice pour into a large bowl and stir in the orange juice and lemon juice pour into a large bowl and stir in the orange juice and lemon juice pour into a large bowl and chill <RECIPE_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "' '.join(qual_res_basic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_res_attn = get_predictions_iter(ingredients_sample_idxs, ingr_lens, encoder_attn, decoder_attn,\n",
    "                                    vocab, decoder_mode=\"attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RECIPE_START> combine sugar , water , lemon juice and salt in a saucepan bring to a boil , stirring constantly boil for 5 minutes , stirring constantly remove from heat and stir in lemon juice and pour into a sterilized jars seal and store in refrigerator <RECIPE_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "' '.join(qual_res_attn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_res_attn_pre_embed = get_predictions_iter(\n",
    "    ingredients_sample_idxs, ingr_lens, encoder_pretrained_embed, decoder_pretrained_embed,\n",
    "    vocab, decoder_mode=\"attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RECIPE_START> combine sugar , water , and lemon juice in a saucepan bring to a boil over medium heat , stirring constantly , until sugar dissolves remove from heat and cool to room temperature add vanilla and mix well chill <RECIPE_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "' '.join(qual_res_attn_pre_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_dict, invalid_ingredients = build_constraints_dict(all_ingredients_lst, vocab)\n",
    "valid_ingredients_list = [i for i in all_ingredients_lst if i not in invalid_ingredients]\n",
    "valid_ingredients_regex = get_ingredients_regex(valid_ingredients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_constraints, neg_constraints, ingredients_text = create_pos_neg_constraints(\n",
    "    ingredients_sample_idxs, vocab, valid_ingredients_regex, constraints_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16], [311], [641, 900], [1218], [791, 900]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constraints_text = []\n",
    "for l in pos_constraints:\n",
    "    constraint_text = []\n",
    "    for idx in l:\n",
    "        constraint_text.append(vocab.index2word[idx])\n",
    "    all_constraints_text.append(' '.join(constraint_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sugar', 'water', 'lemon juice', 'strawberries', 'orange juice']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_constraints_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<INGREDIENT_START> 2 c sugar , 1/4 c lemon juice , 1 c water , 1/3 c orange juice , 8 c strawberries <INGREDIENT_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredients_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "alpha=50 # likelihood\n",
    "beta = 2 # num constraints satisfied\n",
    "neg_constraint_penalty, likelihood_penalty, low_irr_satisfaction_penalty = 10, 0.5, 0.5\n",
    "lam = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_decoder_out_txt = eval_neuro_decoding_iter(ingredients_sample_idxs, ingr_lens, encoder_multilayer_attn, decoder_multilayer_attn,\n",
    "                         vocab, pos_constraints, neg_constraints, max_recipe_len=600, k=k, alpha=alpha, beta=beta,\n",
    "                         neg_constraint_penalty=neg_constraint_penalty, likelihood_penalty=likelihood_penalty, \n",
    "                         low_irr_satisfaction_penalty=low_irr_satisfaction_penalty, lam=lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RECIPE_START> combine sugar and water in a saucepan and bring to a boil add orange juice , lemon juice , and sugar bring to a boil and boil for 5 minutes remove from heat and let cool slightly add strawberries and sugar and stir until dissolved pour into glasses , cover and chill <RECIPE_END>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "' '.join(final_decoder_out_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

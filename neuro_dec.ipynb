{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=0\n",
    "- start with SOS\n",
    "- decoder_out: [N, |Vocab|], with candidates: |Vocab|\n",
    "- discard all candidates \n",
    "- select top-k: [N, k]\n",
    "\n",
    "t=1\n",
    "- start with top k hypothesis: [N, k]\n",
    "- flatten to decoder_input: [N*k] (ensure that hidden and cell is replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "k=3\n",
    "H=2\n",
    "vocab_size= 10\n",
    "decoder_input = torch.randint(low=1, high=10, size=[N, k])\n",
    "decoder_hidden = torch.rand([1, N, H])\n",
    "decoder_cell = torch.rand([1, N, H])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten decoder input\n",
    "decoder_input_flat = decoder_input.flatten() # [N*k]\n",
    "\n",
    "# replicate hidden and cell for all k per N and flatten\n",
    " # [1, N, 1, H] -> [1, N, k, H] -> [1, N*k, H]\n",
    "decoder_hidden_flat = decoder_hidden[..., None, :].expand(-1, -1, k, -1).flatten(1, 2)\n",
    "decoder_cell_flat = decoder_cell[..., None, :].expand(-1, -1, k, -1).flatten(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = torch.rand([N*k, vocab_size])\n",
    "decoder_output=decoder_output.unflatten(0, [N, k]) # [N, k, |Vocab|]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_constraints = [0, 5, 9] # extra ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 0., 1., 1., 1., 0.]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discard_mask = torch.ones_like(decoder_output)\n",
    "discard_mask[:, :, neg_constraints] = 0\n",
    "discard_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10 # preserve top 10 likelihood (NOTE: in reality probably should be much higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8981, 0.8748, 0.8729, 0.8588, 0.8464, 0.8034, 0.7439, 0.7008, 0.6946,\n",
       "         0.6321],\n",
       "        [0.9818, 0.9199, 0.9032, 0.7661, 0.7591, 0.7459, 0.6528, 0.6097, 0.6004,\n",
       "         0.5518],\n",
       "        [0.9361, 0.9312, 0.9002, 0.8954, 0.8801, 0.8235, 0.8165, 0.7799, 0.7223,\n",
       "         0.7157],\n",
       "        [0.9277, 0.9043, 0.8776, 0.8353, 0.7703, 0.7264, 0.7006, 0.6453, 0.6336,\n",
       "         0.6155]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top alpha likelihoods per batch\n",
    "topalpha_likelihood = decoder_output.flatten(1, 2).topk(k=alpha, dim=1).values # [N, alpha]\n",
    "topalpha_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6321, 0.5518, 0.7157, 0.6155])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = topalpha_likelihood.min(-1).values # minimum values to be included within top alpha\n",
    "threshold # [N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0.0041,     0.2649,     0.0137,     0.6946,     0.8034,\n",
       "              0.5727,     0.0461,     0.7008,     0.6321,     0.0922],\n",
       "         [    0.4026,     0.8464,     0.6045,     0.2223,     0.7439,\n",
       "              0.8588,     0.4581,     0.0875,     0.1411,     0.0917],\n",
       "         [    0.6170,     0.0664,     0.3458,     0.8981,     0.8748,\n",
       "              0.1114,     0.5228,     0.3961,     0.8729,     0.4127]],\n",
       "\n",
       "        [[    0.7459,     0.5518,     0.0910,     0.0005,     0.5403,\n",
       "              0.2545,     0.6004,     0.6097,     0.3484,     0.5266],\n",
       "         [    0.6528,     0.9818,     0.4146,     0.7591,     0.2558,\n",
       "              0.3842,     0.4622,     0.1786,     0.3990,     0.2000],\n",
       "         [    0.9199,     0.5465,     0.2253,     0.4462,     0.2527,\n",
       "              0.0406,     0.7661,     0.9032,     0.0472,     0.5398]],\n",
       "\n",
       "        [[    0.6322,     0.1846,     0.4445,     0.8801,     0.6527,\n",
       "              0.2099,     0.8235,     0.7223,     0.7021,     0.8165],\n",
       "         [    0.0469,     0.2458,     0.2266,     0.9361,     0.6354,\n",
       "              0.5021,     0.7157,     0.6081,     0.9002,     0.6459],\n",
       "         [    0.4508,     0.9312,     0.7799,     0.8954,     0.2000,\n",
       "              0.6099,     0.1739,     0.1157,     0.5997,     0.6437]],\n",
       "\n",
       "        [[    0.1706,     0.1124,     0.9277,     0.1765,     0.4701,\n",
       "              0.3969,     0.2859,     0.5912,     0.9043,     0.6336],\n",
       "         [    0.6453,     0.8776,     0.4311,     0.4582,     0.5116,\n",
       "              0.3196,     0.0297,     0.2333,     0.2486,     0.2926],\n",
       "         [    0.4595,     0.4678,     0.7703,     0.0610,     0.6155,\n",
       "              0.5994,     0.7006,     0.7264,     0.8353,     0.1747]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltalphathreshold = decoder_output < threshold[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltalphathreshold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfied_clauses_so_far = torch.randint(1, 3, size=[N,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [2, 1, 1],\n",
       "        [2, 1, 2],\n",
       "        [1, 2, 2]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satisfied_clauses_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_constraints = [1, 2, 7] # input ingredients (indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       "         [1, 2, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       "         [1, 2, 2, 1, 1, 1, 1, 2, 1, 1]],\n",
       "\n",
       "        [[2, 3, 3, 2, 2, 2, 2, 3, 2, 2],\n",
       "         [1, 2, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       "         [1, 2, 2, 1, 1, 1, 1, 2, 1, 1]],\n",
       "\n",
       "        [[2, 3, 3, 2, 2, 2, 2, 3, 2, 2],\n",
       "         [1, 2, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       "         [2, 3, 3, 2, 2, 2, 2, 3, 2, 2]],\n",
       "\n",
       "        [[1, 2, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       "         [2, 3, 3, 2, 2, 2, 2, 3, 2, 2],\n",
       "         [2, 3, 3, 2, 2, 2, 2, 3, 2, 2]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_clauses_now = satisfied_clauses_so_far.unsqueeze(-1).expand(-1, -1, vocab_size).clone()\n",
    "# ! need to lookbehind for multi-word constraints\n",
    "# ! check the last word in each constraint, if it matches this word, check the last word generated by hypothesis k (keep going back until full match or mismatch)\n",
    "sat_clauses_now[:, :, pos_constraints] += 1 # add current satisfaction\n",
    "sat_clauses_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2 # preserve those that satisfy top 2 no, of constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sat_clauses_now.flatten(1, 2).sort(dim=-1).values\n",
    "# subtracting, so duplicate values will become 0\n",
    "# e.g., first row: [1, 2, 3, 0, 0, 4, 0]\n",
    "y[:, 1:] *= ((y[:, 1:] - y[:, :-1]) !=0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [3, 2],\n",
       "        [3, 2],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topbetaval = y.topk(beta).values\n",
    "topbetaval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 2])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_thresh = topbetaval.min(-1).values\n",
    "beta_thresh # [N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True, False, False,  True,  True,  True,  True, False,  True,  True],\n",
       "         [ True, False, False,  True,  True,  True,  True, False,  True,  True]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True, False, False,  True,  True,  True,  True, False,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[ True, False, False,  True,  True,  True,  True, False,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltbetathresh = sat_clauses_now < beta_thresh[:, None, None] # ! USE ACCUMULATED LIKELIHOOD\n",
    "ltbetathresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7284, -2.4676, -2.7188, -2.0379, -1.9291, -2.1598, -2.6864,\n",
       "          -2.0317, -2.1003, -2.6403],\n",
       "         [-2.3880, -1.9442, -2.1861, -2.5683, -2.0467, -1.9318, -2.3325,\n",
       "          -2.7031, -2.6495, -2.6989],\n",
       "         [-2.2386, -2.7891, -2.5098, -1.9574, -1.9807, -2.7441, -2.3327,\n",
       "          -2.4594, -1.9827, -2.4428]],\n",
       "\n",
       "        [[-2.0090, -2.2031, -2.6639, -2.7544, -2.2146, -2.5004, -2.1545,\n",
       "          -2.1452, -2.4065, -2.2283],\n",
       "         [-2.1503, -1.8213, -2.3885, -2.0439, -2.5473, -2.4189, -2.3408,\n",
       "          -2.6245, -2.4040, -2.6031],\n",
       "         [-1.8993, -2.2727, -2.5938, -2.3730, -2.5664, -2.7786, -2.0531,\n",
       "          -1.9160, -2.7720, -2.2794]],\n",
       "\n",
       "        [[-2.3031, -2.7507, -2.4908, -2.0552, -2.2827, -2.7254, -2.1118,\n",
       "          -2.2130, -2.2332, -2.1189],\n",
       "         [-2.8391, -2.6401, -2.6594, -1.9499, -2.2506, -2.3839, -2.1703,\n",
       "          -2.2779, -1.9858, -2.2401],\n",
       "         [-2.4304, -1.9500, -2.1013, -1.9859, -2.6812, -2.2713, -2.7074,\n",
       "          -2.7655, -2.2815, -2.2375]],\n",
       "\n",
       "        [[-2.6391, -2.6974, -1.8820, -2.6332, -2.3396, -2.4129, -2.5238,\n",
       "          -2.2185, -1.9055, -2.1762],\n",
       "         [-2.0885, -1.8562, -2.3027, -2.2756, -2.2222, -2.4142, -2.7041,\n",
       "          -2.5005, -2.4852, -2.4412],\n",
       "         [-2.4114, -2.4031, -2.1007, -2.8099, -2.2555, -2.2715, -2.1703,\n",
       "          -2.1446, -2.0357, -2.6962]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log probabilities\n",
    "score = nn.functional.log_softmax(decoder_output, -1).clone()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of filtering out, do soft prune, ie. heavily penalize the score \n",
    "# (because if we filter, it is possible to get <k per batch so can encounter errors)\n",
    "irreversible_satisfcation_penalty = 10\n",
    "low_likelihood_penalty = 2\n",
    "low_satisfied_clauses_penalty = 5\n",
    "score[discard_mask.bool()] -= irreversible_satisfcation_penalty\n",
    "score[ltalphathreshold] -= low_likelihood_penalty\n",
    "score[ltbetathresh] -= low_satisfied_clauses_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.7284, -14.4676, -14.7188, -12.0379, -11.9291,  -4.1598, -14.6864,\n",
       "          -12.0317, -12.1003,  -4.6403],\n",
       "         [ -4.3880, -11.9442, -14.1861, -14.5683, -12.0467,  -1.9318, -14.3325,\n",
       "          -14.7031, -14.6495,  -4.6989],\n",
       "         [ -4.2386, -14.7891, -14.5098, -11.9574, -11.9807,  -4.7441, -14.3327,\n",
       "          -14.4594, -11.9827,  -4.4428]],\n",
       "\n",
       "        [[ -2.0090, -12.2031, -14.6639, -14.7544, -14.2146,  -4.5004, -12.1545,\n",
       "          -12.1452, -14.4065,  -4.2283],\n",
       "         [ -7.1503, -11.8213, -14.3885, -17.0439, -19.5473,  -9.4189, -19.3408,\n",
       "          -14.6245, -19.4040,  -9.6031],\n",
       "         [ -6.8993, -14.2727, -14.5938, -19.3730, -19.5664,  -9.7786, -17.0531,\n",
       "          -11.9160, -19.7720,  -9.2794]],\n",
       "\n",
       "        [[ -4.3031, -14.7507, -14.4908, -12.0552, -14.2827,  -4.7254, -12.1118,\n",
       "          -12.2130, -14.2332,  -2.1189],\n",
       "         [ -9.8391, -14.6401, -14.6594, -16.9499, -19.2506,  -9.3839, -17.1703,\n",
       "          -14.2779, -16.9858,  -9.2401],\n",
       "         [ -4.4304, -11.9500, -12.1013, -11.9859, -14.6812,  -4.2713, -14.7074,\n",
       "          -14.7655, -14.2815,  -4.2375]],\n",
       "\n",
       "        [[ -9.6391, -14.6974, -11.8820, -19.6332, -19.3396,  -9.4129, -19.5238,\n",
       "          -14.2185, -16.9055,  -7.1762],\n",
       "         [ -2.0885, -11.8562, -14.3027, -14.2756, -14.2222,  -4.4142, -14.7041,\n",
       "          -14.5005, -14.4852,  -4.4412],\n",
       "         [ -4.4114, -14.4031, -12.1007, -14.8099, -12.2555,  -4.2715, -12.1703,\n",
       "          -12.1446, -12.0357,  -4.6962]]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "<!-- for now do grouping by number of clauses -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.7284, -14.4676, -14.7188, -12.0379, -11.9291,  -4.1598, -14.6864,\n",
       "          -12.0317, -12.1003,  -4.6403],\n",
       "         [ -4.3880, -11.9442, -14.1861, -14.5683, -12.0467,  -1.9318, -14.3325,\n",
       "          -14.7031, -14.6495,  -4.6989],\n",
       "         [ -4.2386, -14.7891, -14.5098, -11.9574, -11.9807,  -4.7441, -14.3327,\n",
       "          -14.4594, -11.9827,  -4.4428]],\n",
       "\n",
       "        [[ -2.0090, -12.2031, -14.6639, -14.7544, -14.2146,  -4.5004, -12.1545,\n",
       "          -12.1452, -14.4065,  -4.2283],\n",
       "         [ -7.1503, -11.8213, -14.3885, -17.0439, -19.5473,  -9.4189, -19.3408,\n",
       "          -14.6245, -19.4040,  -9.6031],\n",
       "         [ -6.8993, -14.2727, -14.5938, -19.3730, -19.5664,  -9.7786, -17.0531,\n",
       "          -11.9160, -19.7720,  -9.2794]],\n",
       "\n",
       "        [[ -4.3031, -14.7507, -14.4908, -12.0552, -14.2827,  -4.7254, -12.1118,\n",
       "          -12.2130, -14.2332,  -2.1189],\n",
       "         [ -9.8391, -14.6401, -14.6594, -16.9499, -19.2506,  -9.3839, -17.1703,\n",
       "          -14.2779, -16.9858,  -9.2401],\n",
       "         [ -4.4304, -11.9500, -12.1013, -11.9859, -14.6812,  -4.2713, -14.7074,\n",
       "          -14.7655, -14.2815,  -4.2375]],\n",
       "\n",
       "        [[ -9.6391, -14.6974, -11.8820, -19.6332, -19.3396,  -9.4129, -19.5238,\n",
       "          -14.2185, -16.9055,  -7.1762],\n",
       "         [ -2.0885, -11.8562, -14.3027, -14.2756, -14.2222,  -4.4142, -14.7041,\n",
       "          -14.5005, -14.4852,  -4.4412],\n",
       "         [ -4.4114, -14.4031, -12.1007, -14.8099, -12.2555,  -4.2715, -12.1703,\n",
       "          -12.1446, -12.0357,  -4.6962]]])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=20\n",
    "topgvals, topginds = score.flatten(-2, -1).topk(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.9318,  -4.1598,  -4.2386,  -4.3880,  -4.4428,  -4.6403,  -4.6989,\n",
       "          -4.7284,  -4.7441, -11.9291, -11.9442, -11.9574, -11.9807, -11.9827,\n",
       "         -12.0317, -12.0379, -12.0467, -12.1003, -14.1861, -14.3325],\n",
       "        [ -2.0090,  -4.2283,  -4.5004,  -6.8993,  -7.1503,  -9.2794,  -9.4189,\n",
       "          -9.6031,  -9.7786, -11.8213, -11.9160, -12.1452, -12.1545, -12.2031,\n",
       "         -14.2146, -14.2727, -14.3885, -14.4065, -14.5938, -14.6245],\n",
       "        [ -2.1189,  -4.2375,  -4.2713,  -4.3031,  -4.4304,  -4.7254,  -9.2401,\n",
       "          -9.3839,  -9.8391, -11.9500, -11.9859, -12.0552, -12.1013, -12.1118,\n",
       "         -12.2130, -14.2332, -14.2779, -14.2815, -14.2827, -14.4908],\n",
       "        [ -2.0885,  -4.2715,  -4.4114,  -4.4142,  -4.4412,  -4.6962,  -7.1762,\n",
       "          -9.4129,  -9.6391, -11.8562, -11.8820, -12.0357, -12.1007, -12.1446,\n",
       "         -12.1703, -12.2555, -14.2185, -14.2222, -14.2756, -14.3027]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topgvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15,  5, 20, 10, 29,  9, 19,  0, 25,  4, 11, 23, 24, 28,  7,  3, 14,  8,\n",
       "         12, 16],\n",
       "        [ 0,  9,  5, 20, 10, 29, 15, 19, 25, 11, 27,  7,  6,  1,  4, 21, 12,  8,\n",
       "         22, 17],\n",
       "        [ 9, 29, 25,  0, 20,  5, 19, 15, 10, 21, 23,  3, 22,  6,  7,  8, 17, 28,\n",
       "          4,  2],\n",
       "        [10, 25, 20, 15, 19, 29,  9,  5,  0, 11,  2, 28, 22, 27, 26, 24,  7, 14,\n",
       "         13, 12]])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topginds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=torch.arange(4).unsqueeze(-1).expand(-1, g)\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 2, 3, 0, 1, 0, 2, 0, 3, 3, 1, 1, 3, 3, 2, 1, 0, 2, 0, 3],\n",
       "        [0, 0, 0, 3, 1, 3, 2, 0, 3, 1, 2, 2, 0, 3, 2, 2, 1, 3, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topg_sat_clauses_now = sat_clauses_now.flatten(-2, -1)[bs, topginds]\n",
    "topg_sat_clauses_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topg_sat_clauses_now.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = topginds % vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 0, 0, 9, 9, 9, 0, 5, 4, 1, 3, 4, 8, 7, 3, 4, 8, 2, 6],\n",
       "        [0, 9, 5, 0, 0, 9, 5, 9, 5, 1, 7, 7, 6, 1, 4, 1, 2, 8, 2, 7],\n",
       "        [9, 9, 5, 0, 0, 5, 9, 5, 0, 1, 3, 3, 2, 6, 7, 8, 7, 8, 4, 2],\n",
       "        [0, 5, 0, 5, 9, 9, 9, 5, 0, 1, 2, 8, 2, 7, 6, 4, 7, 4, 3, 2]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], []]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = [[] for _ in range(N)]\n",
    "group_idxs = [[] for _ in range(N)]\n",
    "group_word_idxs = [[] for _ in range(N)]\n",
    "group_scores = [[] for _ in range(N)]\n",
    "group_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ni in range(N):\n",
    "    for vi in range(g):\n",
    "        group = topg_sat_clauses_now[ni,vi].item()\n",
    "        if topg_sat_clauses_now[ni, vi] not in groups[ni]:\n",
    "            groups[ni].append(group)\n",
    "            group_idxs[ni].append([vi])\n",
    "            group_word_idxs[ni].append([word_indices[ni, vi].item()])\n",
    "            group_scores[ni].append([topgvals[ni, vi].item()])\n",
    "        else:\n",
    "            gid = groups[ni].index(group)\n",
    "            group_idxs[ni][gid].append(vi)\n",
    "            group_word_idxs[ni][gid].append(word_indices[ni, vi].item())\n",
    "            group_scores[ni][gid].append(topgvals[ni, vi].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 1], [0, 2, 3, 1], [0, 3, 1, 2], [0, 1]]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 15, 16, 18, 19], [4, 13], [6, 12, 14, 17]],\n",
       " [[0, 3, 5, 7, 16, 18],\n",
       "  [1, 6, 14, 17],\n",
       "  [2, 8, 9, 12, 13, 19],\n",
       "  [4, 10, 11, 15]],\n",
       " [[0, 1, 2, 7, 12, 18],\n",
       "  [3, 5, 8, 13, 17],\n",
       "  [4, 9, 16, 19],\n",
       "  [6, 10, 11, 14, 15]],\n",
       " [[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19], [6, 11, 13]]]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 5, 0, 0, 9, 0, 5, 4, 1, 3, 3, 4, 2, 6], [9, 8], [9, 4, 7, 8]],\n",
       " [[0, 0, 9, 9, 2, 2], [9, 5, 4, 8], [5, 5, 1, 6, 1, 7], [0, 7, 7, 1]],\n",
       " [[9, 9, 5, 5, 2, 4], [0, 5, 0, 6, 8], [0, 1, 7, 2], [9, 3, 3, 7, 8]],\n",
       " [[0, 5, 0, 5, 9, 9, 5, 0, 1, 2, 2, 6, 4, 7, 4, 3, 2], [9, 8, 7]]]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_word_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.9317786693572998,\n",
       " -4.159816741943359,\n",
       " -4.23856782913208,\n",
       " -4.387991905212402,\n",
       " -4.640323638916016,\n",
       " -4.728414058685303,\n",
       " -4.744137763977051,\n",
       " -11.929056167602539,\n",
       " -11.944205284118652,\n",
       " -11.957398414611816,\n",
       " -12.037866592407227,\n",
       " -12.0466947555542,\n",
       " -14.186067581176758,\n",
       " -14.332537651062012]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_scores[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 1], [0, 2, 3, 1], [0, 3, 1, 2], [0, 1]]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 0, 0, 9, 0, 5, 4, 1, 3, 3, 4, 2, 6]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_word_idxs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 0], [1], [7, 9, 10], [2]],\n",
       " [[5, 0], [1], [7, 9, 10], [2]],\n",
       " [[5, 0], [1], [7, 9, 10], [2]],\n",
       " [[5, 0], [1], [7, 9, 10], [2]]]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints = [[[5, 0], [1], [7, 9, 10], [2]] for _ in range(N)]\n",
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-1.9317786693572998,\n",
       "   -4.159816741943359,\n",
       "   -4.23856782913208,\n",
       "   -4.387991905212402,\n",
       "   -4.640323638916016,\n",
       "   -4.728414058685303,\n",
       "   -4.744137763977051,\n",
       "   -11.929056167602539,\n",
       "   -11.944205284118652,\n",
       "   -11.957398414611816,\n",
       "   -12.037866592407227,\n",
       "   -12.0466947555542,\n",
       "   -14.186067581176758,\n",
       "   -14.332537651062012],\n",
       "  [-4.442814826965332, -11.982657432556152],\n",
       "  [-4.698945999145508,\n",
       "   -11.98073673248291,\n",
       "   -12.031679153442383,\n",
       "   -12.100347518920898]],\n",
       " [[-2.008964776992798,\n",
       "   -6.899304389953613,\n",
       "   -9.279380798339844,\n",
       "   -9.603067398071289,\n",
       "   -14.388473510742188,\n",
       "   -14.59383773803711],\n",
       "  [-4.228276252746582,\n",
       "   -9.418909072875977,\n",
       "   -14.214564323425293,\n",
       "   -14.406536102294922],\n",
       "  [-4.500431060791016,\n",
       "   -9.778593063354492,\n",
       "   -11.821250915527344,\n",
       "   -12.154487609863281,\n",
       "   -12.203121185302734,\n",
       "   -14.624506950378418],\n",
       "  [-7.150251388549805,\n",
       "   -11.91598892211914,\n",
       "   -12.14522933959961,\n",
       "   -14.272651672363281]],\n",
       " [[-2.1188576221466064,\n",
       "   -4.237539291381836,\n",
       "   -4.271327018737793,\n",
       "   -9.383874893188477,\n",
       "   -12.101276397705078,\n",
       "   -14.28268814086914],\n",
       "  [-4.303140163421631,\n",
       "   -4.725418567657471,\n",
       "   -9.839134216308594,\n",
       "   -12.111848831176758,\n",
       "   -14.281524658203125],\n",
       "  [-4.43039608001709,\n",
       "   -11.95003604888916,\n",
       "   -14.277863502502441,\n",
       "   -14.490809440612793],\n",
       "  [-9.240102767944336,\n",
       "   -11.985851287841797,\n",
       "   -12.055221557617188,\n",
       "   -12.213001251220703,\n",
       "   -14.233217239379883]],\n",
       " [[-2.0885391235351562,\n",
       "   -4.271548748016357,\n",
       "   -4.411426544189453,\n",
       "   -4.414190292358398,\n",
       "   -4.441176414489746,\n",
       "   -4.696215629577637,\n",
       "   -9.41290283203125,\n",
       "   -9.639120101928711,\n",
       "   -11.85620403289795,\n",
       "   -11.882024765014648,\n",
       "   -12.100652694702148,\n",
       "   -12.17030143737793,\n",
       "   -12.255486488342285,\n",
       "   -14.218513488769531,\n",
       "   -14.222204208374023,\n",
       "   -14.27562427520752,\n",
       "   -14.302722930908203],\n",
       "  [-7.176199913024902, -12.035665512084961, -12.144573211669922]]]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.5\n",
    "for ni in range(N):\n",
    "    for group_num in range(len(groups[ni])):\n",
    "        for wi, word_idx in enumerate(group_word_idxs[ni][group_num]):\n",
    "            max_completion = 0\n",
    "\n",
    "            for constraint in constraints[ni]:\n",
    "                if word_idx != constraint[0]:\n",
    "                    continue\n",
    "                completion = 1/len(constraint)\n",
    "                if completion > max_completion:\n",
    "                    max_completion = completion\n",
    "            \n",
    "            group_scores[ni][group_num][wi] += lam * max_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.6817786693572998,\n",
       " -3.9098167419433594,\n",
       " -4.23856782913208,\n",
       " -4.387991905212402,\n",
       " -4.640323638916016,\n",
       " -4.728414058685303,\n",
       " -4.494137763977051,\n",
       " -11.929056167602539,\n",
       " -11.444205284118652,\n",
       " -11.957398414611816,\n",
       " -12.037866592407227,\n",
       " -12.0466947555542,\n",
       " -13.686067581176758,\n",
       " -14.332537651062012]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 0], [3, 2, 1, 0], [3, 2, 1, 0], [1, 0]]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = [sorted(l, reverse=True) for l in groups]\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_next =  torch.empty([N, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    -0.0004,      0.0000,     -0.0004],\n",
       "        [     0.0000,      0.0000,      0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000]])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ni in range(N):\n",
    "    obtained = 0\n",
    "    while obtained < k:\n",
    "        for groupnum in order[ni]:\n",
    "            groupid = groups[ni].index(groupnum)\n",
    "            max_score_idx = np.argmax(group_scores[ni][groupid])\n",
    "            decoder_input_next[ni][obtained] = group_word_idxs[ni][groupid][max_score_idx]\n",
    "            obtained += 1\n",
    "            group_scores[ni][groupid].pop(max_score_idx)\n",
    "            group_word_idxs[ni][groupid].pop(max_score_idx)\n",
    "\n",
    "            if obtained >= k:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 9., 5.],\n",
       "        [5., 9., 0.],\n",
       "        [0., 9., 0.],\n",
       "        [9., 0., 7.]])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
